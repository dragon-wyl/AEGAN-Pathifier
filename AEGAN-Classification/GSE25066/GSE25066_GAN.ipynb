{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670cb20a-1209-43cd-b291-a612c2a33abb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pth_methods import *\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e06bb061-515b-4065-bd45-58031851b9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fd1de-6c7b-432f-a17a-49b1847c22b5",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f9ca2e-bc85-4fb1-8e8e-f8433849d2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('GSE25066_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd1b33e-7c31-4953-a24e-a14abbe2be7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 13237)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['group'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94af35c-cbbf-444b-8b55-9e35ae2a59e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389, 13237)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['group'] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87bac13-19ec-40ab-a9a2-8064cfac1077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = data[data['group'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce3b09d-c154-4754-a063-f32f8f67439d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group = df.pop('group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e28e195-5c4f-40df-ad68-9235344d6171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbf042-ba16-4523-8716-f7bff1266d9a",
   "metadata": {},
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06640ddd-516f-4f99-8e5f-779322523462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 分离训练集和测试集\n",
    "train_data = df.sample(frac=0.8, random_state=42)\n",
    "test_data = df.drop(train_data.index)\n",
    "\n",
    "# 转换为tensor\n",
    "train_tensor = torch.tensor(train_data.values, dtype=torch.float32).to(device)\n",
    "test_tensor = torch.tensor(test_data.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# 定义模型、损失函数和优化器\n",
    "input_dim = 13236\n",
    "encoding_dim = 512\n",
    "GSE25066_AutoEncoder_Model = Autoencoder(input_dim, encoding_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(GSE25066_AutoEncoder_Model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_tensor, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c70861f-e58b-46a2-b91d-1e5c8d991f1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 训练AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2271231a-7cbd-49f3-953f-275964437296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([79, 13236])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b7a62a9-37ab-403f-ad6c-83e7c6ae28cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "min_loss = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "790cc558-11a3-45b7-a30d-7c783718bbdf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000], Loss: 0.8694\n",
      "Epoch [2000], Loss: 0.8677\n",
      "Epoch [3000], Loss: 0.8718\n",
      "Epoch [4000], Loss: 0.8641\n",
      "Epoch [5000], Loss: 0.8665\n",
      "Epoch [6000], Loss: 0.8679\n",
      "Epoch [7000], Loss: 0.8660\n",
      "Epoch [8000], Loss: 0.8666\n",
      "Epoch [9000], Loss: 0.8665\n",
      "Epoch [10000], Loss: 0.8675\n",
      "Epoch [11000], Loss: 0.8660\n",
      "Epoch [12000], Loss: 0.8694\n",
      "Epoch [13000], Loss: 0.8666\n",
      "Epoch [14000], Loss: 0.8666\n",
      "Epoch [15000], Loss: 0.8695\n",
      "Epoch [16000], Loss: 0.8690\n",
      "Epoch [17000], Loss: 0.8706\n",
      "Epoch [18000], Loss: 0.8679\n",
      "Epoch [19000], Loss: 0.8666\n",
      "Epoch [20000], Loss: 0.8682\n",
      "Epoch [21000], Loss: 0.8681\n",
      "Epoch [22000], Loss: 0.8661\n",
      "Epoch [23000], Loss: 0.8673\n",
      "Epoch [24000], Loss: 0.8659\n",
      "Epoch [25000], Loss: 0.8715\n",
      "Epoch [26000], Loss: 0.8647\n",
      "Epoch [27000], Loss: 0.8670\n",
      "Epoch [28000], Loss: 0.8697\n",
      "Epoch [29000], Loss: 0.8688\n",
      "Epoch [30000], Loss: 0.8666\n",
      "Epoch [31000], Loss: 0.8679\n",
      "Epoch [32000], Loss: 0.8704\n",
      "Epoch [33000], Loss: 0.8682\n",
      "Epoch [34000], Loss: 0.8670\n",
      "Epoch [35000], Loss: 0.8664\n",
      "Epoch [36000], Loss: 0.8673\n",
      "Epoch [37000], Loss: 0.8673\n",
      "Epoch [38000], Loss: 0.8679\n",
      "Epoch [39000], Loss: 0.8671\n",
      "Epoch [40000], Loss: 0.8669\n",
      "Epoch [41000], Loss: 0.8653\n",
      "Epoch [42000], Loss: 0.8676\n",
      "Epoch [43000], Loss: 0.8655\n",
      "Epoch [44000], Loss: 0.8670\n",
      "Epoch [45000], Loss: 0.8683\n",
      "Epoch [46000], Loss: 0.8671\n",
      "Epoch [47000], Loss: 0.8675\n",
      "Epoch [48000], Loss: 0.8694\n",
      "Epoch [49000], Loss: 0.8665\n",
      "Epoch [50000], Loss: 0.8687\n",
      "Epoch [51000], Loss: 0.8663\n",
      "Epoch [52000], Loss: 0.8685\n",
      "Epoch [53000], Loss: 0.8678\n",
      "Epoch [54000], Loss: 0.8657\n",
      "Epoch [55000], Loss: 0.8678\n",
      "Epoch [56000], Loss: 0.8689\n",
      "Epoch [57000], Loss: 0.8699\n",
      "Epoch [58000], Loss: 0.8667\n",
      "Epoch [59000], Loss: 0.8695\n",
      "Epoch [60000], Loss: 0.8686\n",
      "Epoch [61000], Loss: 0.8668\n",
      "Epoch [62000], Loss: 0.8664\n",
      "Epoch [63000], Loss: 0.8673\n",
      "Epoch [64000], Loss: 0.8655\n",
      "Epoch [65000], Loss: 0.8686\n",
      "Epoch [66000], Loss: 0.8683\n",
      "Epoch [67000], Loss: 0.8680\n",
      "Epoch [68000], Loss: 0.8652\n",
      "Epoch [69000], Loss: 0.8684\n",
      "Epoch [70000], Loss: 0.8685\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2738978/689097559.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mae_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mae_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_now_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_now_loss = 10000\n",
    "num=0;\n",
    "while min_now_loss > min_loss:\n",
    "    num += 1\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs = data\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = GSE25066_AutoEncoder_Model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        ae_loss = running_loss / len(train_loader)\n",
    "        if (ae_loss < min_now_loss):\n",
    "            min_now_loss = ae_loss\n",
    "    if num % 1000 == 0: \n",
    "        print('Epoch [%d], Loss: %.4f' % (num, ae_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7443515-97d7-4e53-8ccc-f9f4986f2b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(GSE25066_AutoEncoder_Model.state_dict(), 'GSE25066_AE_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872957fd-43ef-4fe1-973a-8b4d5be66e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5db314c4-ff28-4f4b-9757-1ae282283c29",
   "metadata": {},
   "source": [
    "# 生成对抗网络模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86205b06-11bf-4a99-a90b-803200c8ef72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 8192, 4096, 2048, 1024, 512, 256, 128]\n",
      "[13236, 8192, 4096, 2048, 1024, 512, 256, 128]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "data = torch.tensor(df.values, dtype=torch.float32)\n",
    "data_loader = DataLoader(data, batch_size=32, shuffle=True)\n",
    "\n",
    "# 初始化模型\n",
    "generator = Generator(input_dim=100, output_dim=13236).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# 初始化优化器\n",
    "gen_optimizer = RMSprop(generator.parameters(), lr=0.0001)\n",
    "dis_optimizer = RMSprop(discriminator.parameters(), lr=0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4baae1-2511-46a1-8e1a-164e417a9cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    (9): LeakyReLU(negative_slope=0.2)\n",
       "    (10): Linear(in_features=4096, out_features=8192, bias=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2)\n",
       "    (12): Linear(in_features=8192, out_features=13236, bias=True)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585ef219-d3ba-4bfe-bc9c-3f50d072c627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=13236, out_features=8192, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Linear(in_features=8192, out_features=4096, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2)\n",
       "    (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2)\n",
       "    (6): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2)\n",
       "    (8): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (9): LeakyReLU(negative_slope=0.2)\n",
       "    (10): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2)\n",
       "    (12): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (13): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ddf6ab-3d80-4b2f-a614-f15b56bd3d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x13236 and 128x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdis_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/datacenter/imbalanced-exps/GSE25066-analysis/pth_methods.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(device, generator, discriminator, gen_optimizer, dis_optimizer, data_loader, epochs)\u001b[0m\n\u001b[1;32m    183\u001b[0m real_loss \u001b[38;5;241m=\u001b[39m discriminator(real_data)\n\u001b[1;32m    184\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(real_data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), real_data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 185\u001b[0m fake_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m fake_loss \u001b[38;5;241m=\u001b[39m discriminator(fake_data)\n\u001b[1;32m    187\u001b[0m dis_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmean(real_loss) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(fake_loss))\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/datacenter/imbalanced-exps/GSE25066-analysis/pth_methods.py:115\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x13236 and 128x256)"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "train(device, generator, discriminator, gen_optimizer, dis_optimizer, data_loader, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b81ac-a6f0-453b-933d-6a0cd3f8e1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
