2023-06-04 09:40:01,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 09:40:01,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 09:40:01,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 09:40:01,548:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-04 09:40:01,944:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-04 09:40:02,074:INFO:Initializing set_config()
2023-06-04 09:40:02,074:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75e8dacb20>, variable=seed, value=42, kwargs={})
2023-06-04 09:40:02,074:INFO:Global variable: seed updated to 42
2023-06-04 09:40:02,074:INFO:set_config() successfully completed......................................
2023-06-04 09:40:15,374:INFO:Initializing set_config()
2023-06-04 09:40:15,374:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, variable=seed, value=42, kwargs={})
2023-06-04 09:40:15,374:INFO:Global variable: seed updated to 42
2023-06-04 09:40:15,374:INFO:set_config() successfully completed......................................
2023-06-04 09:40:15,705:INFO:PyCaret ClassificationExperiment
2023-06-04 09:40:15,705:INFO:Logging name: clf-default-name
2023-06-04 09:40:15,705:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-04 09:40:15,705:INFO:version 3.0.2
2023-06-04 09:40:15,705:INFO:Initializing setup()
2023-06-04 09:40:15,705:INFO:self.USI: bfaf
2023-06-04 09:40:15,706:INFO:self._variable_keys: {'y_train', 'y', 'fix_imbalance', 'X_test', 'gpu_n_jobs_param', 'exp_name_log', 'USI', 'html_param', 'y_test', 'pipeline', 'exp_id', 'logging_param', 'fold_shuffle_param', 'X', 'X_train', '_available_plots', '_ml_usecase', 'data', 'is_multiclass', 'log_plots_param', 'fold_generator', 'idx', 'gpu_param', 'seed', 'memory', 'n_jobs_param', 'target_param', 'fold_groups_param'}
2023-06-04 09:40:15,706:INFO:Checking environment
2023-06-04 09:40:15,706:INFO:python_version: 3.9.16
2023-06-04 09:40:15,706:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-06-04 09:40:15,706:INFO:machine: x86_64
2023-06-04 09:40:15,706:INFO:platform: Linux-5.4.0-148-generic-x86_64-with-glibc2.31
2023-06-04 09:40:15,706:INFO:Memory: svmem(total=33556725760, available=24251711488, percent=27.7, used=8802660352, free=257470464, active=14470381568, inactive=16450220032, buffers=409468928, cached=24087126016, shared=23105536, slab=1690656768)
2023-06-04 09:40:15,708:INFO:Physical Core: 28
2023-06-04 09:40:15,708:INFO:Logical Core: 56
2023-06-04 09:40:15,708:INFO:Checking libraries
2023-06-04 09:40:15,708:INFO:System:
2023-06-04 09:40:15,708:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-06-04 09:40:15,708:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-06-04 09:40:15,708:INFO:   machine: Linux-5.4.0-148-generic-x86_64-with-glibc2.31
2023-06-04 09:40:15,708:INFO:PyCaret required dependencies:
2023-06-04 09:40:15,708:INFO:                 pip: 23.0.1
2023-06-04 09:40:15,708:INFO:          setuptools: 66.0.0
2023-06-04 09:40:15,708:INFO:             pycaret: 3.0.2
2023-06-04 09:40:15,708:INFO:             IPython: 8.13.2
2023-06-04 09:40:15,708:INFO:          ipywidgets: 8.0.6
2023-06-04 09:40:15,708:INFO:                tqdm: 4.65.0
2023-06-04 09:40:15,708:INFO:               numpy: 1.23.5
2023-06-04 09:40:15,708:INFO:              pandas: 1.5.3
2023-06-04 09:40:15,708:INFO:              jinja2: 3.1.2
2023-06-04 09:40:15,708:INFO:               scipy: 1.10.1
2023-06-04 09:40:15,708:INFO:              joblib: 1.2.0
2023-06-04 09:40:15,708:INFO:             sklearn: 1.2.2
2023-06-04 09:40:15,709:INFO:                pyod: 1.0.9
2023-06-04 09:40:15,709:INFO:            imblearn: 0.10.1
2023-06-04 09:40:15,709:INFO:   category_encoders: 2.6.1
2023-06-04 09:40:15,709:INFO:            lightgbm: 3.3.5
2023-06-04 09:40:15,709:INFO:               numba: 0.57.0
2023-06-04 09:40:15,709:INFO:            requests: 2.28.1
2023-06-04 09:40:15,709:INFO:          matplotlib: 3.7.1
2023-06-04 09:40:15,709:INFO:          scikitplot: 0.3.7
2023-06-04 09:40:15,709:INFO:         yellowbrick: 1.5
2023-06-04 09:40:15,709:INFO:              plotly: 5.14.1
2023-06-04 09:40:15,709:INFO:             kaleido: 0.2.1
2023-06-04 09:40:15,709:INFO:         statsmodels: 0.14.0
2023-06-04 09:40:15,709:INFO:              sktime: 0.17.0
2023-06-04 09:40:15,709:INFO:               tbats: 1.1.3
2023-06-04 09:40:15,709:INFO:            pmdarima: 2.0.3
2023-06-04 09:40:15,709:INFO:              psutil: 5.9.5
2023-06-04 09:40:15,709:INFO:PyCaret optional dependencies:
2023-06-04 09:40:15,728:INFO:                shap: Not installed
2023-06-04 09:40:15,728:INFO:           interpret: Not installed
2023-06-04 09:40:15,728:INFO:                umap: Not installed
2023-06-04 09:40:15,728:INFO:    pandas_profiling: Not installed
2023-06-04 09:40:15,728:INFO:  explainerdashboard: Not installed
2023-06-04 09:40:15,728:INFO:             autoviz: Not installed
2023-06-04 09:40:15,728:INFO:           fairlearn: Not installed
2023-06-04 09:40:15,728:INFO:             xgboost: Not installed
2023-06-04 09:40:15,728:INFO:            catboost: Not installed
2023-06-04 09:40:15,728:INFO:              kmodes: Not installed
2023-06-04 09:40:15,728:INFO:             mlxtend: Not installed
2023-06-04 09:40:15,728:INFO:       statsforecast: Not installed
2023-06-04 09:40:15,728:INFO:        tune_sklearn: Not installed
2023-06-04 09:40:15,728:INFO:                 ray: Not installed
2023-06-04 09:40:15,728:INFO:            hyperopt: Not installed
2023-06-04 09:40:15,728:INFO:              optuna: Not installed
2023-06-04 09:40:15,728:INFO:               skopt: Not installed
2023-06-04 09:40:15,728:INFO:              mlflow: Not installed
2023-06-04 09:40:15,728:INFO:              gradio: Not installed
2023-06-04 09:40:15,728:INFO:             fastapi: Not installed
2023-06-04 09:40:15,728:INFO:             uvicorn: Not installed
2023-06-04 09:40:15,729:INFO:              m2cgen: Not installed
2023-06-04 09:40:15,729:INFO:           evidently: Not installed
2023-06-04 09:40:15,729:INFO:               fugue: Not installed
2023-06-04 09:40:15,729:INFO:           streamlit: Not installed
2023-06-04 09:40:15,729:INFO:             prophet: Not installed
2023-06-04 09:40:15,729:INFO:None
2023-06-04 09:40:15,729:INFO:Set up data.
2023-06-04 09:40:19,201:INFO:Set up train/test split.
2023-06-04 09:40:19,347:INFO:Set up index.
2023-06-04 09:40:19,347:INFO:Set up folding strategy.
2023-06-04 09:40:19,347:INFO:Assigning column types.
2023-06-04 09:40:19,420:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-04 09:40:19,458:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 09:40:19,460:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:40:19,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 09:40:19,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:40:19,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,566:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-04 09:40:19,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:40:19,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,670:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:40:19,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,694:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-04 09:40:19,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,821:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,821:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:19,822:INFO:Preparing preprocessing pipeline...
2023-06-04 09:40:19,837:INFO:Set up simple imputation.
2023-06-04 09:40:19,848:INFO:Set up column name cleaning.
2023-06-04 09:40:20,511:INFO:Finished creating preprocessing pipeline.
2023-06-04 09:40:20,568:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-04 09:40:20,569:INFO:Creating final display dataframe.
2023-06-04 09:40:23,072:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (421, 11886)
4        Transformed data shape      (421, 11886)
5   Transformed train set shape      (378, 11886)
6    Transformed test set shape       (43, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              bfaf
2023-06-04 09:40:23,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:23,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:23,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:23,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:40:23,208:INFO:setup() successfully completed in 7.83s...............
2023-06-04 09:40:23,214:INFO:Initializing compare_models()
2023-06-04 09:40:23,215:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-04 09:40:23,215:INFO:Checking exceptions
2023-06-04 09:40:23,262:INFO:Preparing display monitor
2023-06-04 09:40:23,286:INFO:Initializing Logistic Regression
2023-06-04 09:40:23,286:INFO:Total runtime is 3.0597050984700522e-06 minutes
2023-06-04 09:40:23,289:INFO:SubProcess create_model() called ==================================
2023-06-04 09:40:23,290:INFO:Initializing create_model()
2023-06-04 09:40:23,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:40:23,290:INFO:Checking exceptions
2023-06-04 09:40:23,290:INFO:Importing libraries
2023-06-04 09:40:23,290:INFO:Copying training dataset
2023-06-04 09:40:23,354:INFO:Defining folds
2023-06-04 09:40:23,354:INFO:Declaring metric variables
2023-06-04 09:40:23,358:INFO:Importing untrained model
2023-06-04 09:40:23,361:INFO:Logistic Regression Imported successfully
2023-06-04 09:40:23,368:INFO:Starting cross validation
2023-06-04 09:40:23,405:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:40:33,384:INFO:Calculating mean and std
2023-06-04 09:40:33,389:INFO:Creating metrics dataframe
2023-06-04 09:40:33,717:INFO:Uploading results into container
2023-06-04 09:40:33,719:INFO:Uploading model into container now
2023-06-04 09:40:33,719:INFO:_master_model_container: 1
2023-06-04 09:40:33,720:INFO:_display_container: 2
2023-06-04 09:40:33,720:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 09:40:33,720:INFO:create_model() successfully completed......................................
2023-06-04 09:40:33,881:INFO:SubProcess create_model() end ==================================
2023-06-04 09:40:33,881:INFO:Creating metrics dataframe
2023-06-04 09:40:33,892:INFO:Initializing K Neighbors Classifier
2023-06-04 09:40:33,893:INFO:Total runtime is 0.1767869551976522 minutes
2023-06-04 09:40:33,897:INFO:SubProcess create_model() called ==================================
2023-06-04 09:40:33,898:INFO:Initializing create_model()
2023-06-04 09:40:33,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:40:33,898:INFO:Checking exceptions
2023-06-04 09:40:33,898:INFO:Importing libraries
2023-06-04 09:40:33,898:INFO:Copying training dataset
2023-06-04 09:40:33,965:INFO:Defining folds
2023-06-04 09:40:33,965:INFO:Declaring metric variables
2023-06-04 09:40:33,970:INFO:Importing untrained model
2023-06-04 09:40:33,974:INFO:K Neighbors Classifier Imported successfully
2023-06-04 09:40:33,981:INFO:Starting cross validation
2023-06-04 09:40:34,019:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:40:38,163:INFO:Calculating mean and std
2023-06-04 09:40:38,166:INFO:Creating metrics dataframe
2023-06-04 09:40:38,475:INFO:Uploading results into container
2023-06-04 09:40:38,476:INFO:Uploading model into container now
2023-06-04 09:40:38,476:INFO:_master_model_container: 2
2023-06-04 09:40:38,476:INFO:_display_container: 2
2023-06-04 09:40:38,477:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-04 09:40:38,477:INFO:create_model() successfully completed......................................
2023-06-04 09:40:38,604:INFO:SubProcess create_model() end ==================================
2023-06-04 09:40:38,604:INFO:Creating metrics dataframe
2023-06-04 09:40:38,615:INFO:Initializing Naive Bayes
2023-06-04 09:40:38,615:INFO:Total runtime is 0.2554916183153788 minutes
2023-06-04 09:40:38,618:INFO:SubProcess create_model() called ==================================
2023-06-04 09:40:38,619:INFO:Initializing create_model()
2023-06-04 09:40:38,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:40:38,619:INFO:Checking exceptions
2023-06-04 09:40:38,619:INFO:Importing libraries
2023-06-04 09:40:38,619:INFO:Copying training dataset
2023-06-04 09:40:38,682:INFO:Defining folds
2023-06-04 09:40:38,683:INFO:Declaring metric variables
2023-06-04 09:40:38,686:INFO:Importing untrained model
2023-06-04 09:40:38,690:INFO:Naive Bayes Imported successfully
2023-06-04 09:40:38,697:INFO:Starting cross validation
2023-06-04 09:40:38,734:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:40:42,876:INFO:Calculating mean and std
2023-06-04 09:40:42,878:INFO:Creating metrics dataframe
2023-06-04 09:40:43,188:INFO:Uploading results into container
2023-06-04 09:40:43,189:INFO:Uploading model into container now
2023-06-04 09:40:43,189:INFO:_master_model_container: 3
2023-06-04 09:40:43,189:INFO:_display_container: 2
2023-06-04 09:40:43,189:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-04 09:40:43,190:INFO:create_model() successfully completed......................................
2023-06-04 09:40:43,294:INFO:SubProcess create_model() end ==================================
2023-06-04 09:40:43,295:INFO:Creating metrics dataframe
2023-06-04 09:40:43,306:INFO:Initializing Decision Tree Classifier
2023-06-04 09:40:43,307:INFO:Total runtime is 0.33368565638860065 minutes
2023-06-04 09:40:43,310:INFO:SubProcess create_model() called ==================================
2023-06-04 09:40:43,311:INFO:Initializing create_model()
2023-06-04 09:40:43,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:40:43,311:INFO:Checking exceptions
2023-06-04 09:40:43,311:INFO:Importing libraries
2023-06-04 09:40:43,311:INFO:Copying training dataset
2023-06-04 09:40:43,372:INFO:Defining folds
2023-06-04 09:40:43,372:INFO:Declaring metric variables
2023-06-04 09:40:43,376:INFO:Importing untrained model
2023-06-04 09:40:43,381:INFO:Decision Tree Classifier Imported successfully
2023-06-04 09:40:43,389:INFO:Starting cross validation
2023-06-04 09:40:43,427:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:40:48,288:INFO:Calculating mean and std
2023-06-04 09:40:48,292:INFO:Creating metrics dataframe
2023-06-04 09:40:48,616:INFO:Uploading results into container
2023-06-04 09:40:48,617:INFO:Uploading model into container now
2023-06-04 09:40:48,618:INFO:_master_model_container: 4
2023-06-04 09:40:48,618:INFO:_display_container: 2
2023-06-04 09:40:48,619:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-06-04 09:40:48,619:INFO:create_model() successfully completed......................................
2023-06-04 09:40:48,759:INFO:SubProcess create_model() end ==================================
2023-06-04 09:40:48,759:INFO:Creating metrics dataframe
2023-06-04 09:40:48,771:INFO:Initializing SVM - Linear Kernel
2023-06-04 09:40:48,771:INFO:Total runtime is 0.4247642755508423 minutes
2023-06-04 09:40:48,775:INFO:SubProcess create_model() called ==================================
2023-06-04 09:40:48,775:INFO:Initializing create_model()
2023-06-04 09:40:48,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:40:48,775:INFO:Checking exceptions
2023-06-04 09:40:48,775:INFO:Importing libraries
2023-06-04 09:40:48,776:INFO:Copying training dataset
2023-06-04 09:40:48,838:INFO:Defining folds
2023-06-04 09:40:48,838:INFO:Declaring metric variables
2023-06-04 09:40:48,842:INFO:Importing untrained model
2023-06-04 09:40:48,847:INFO:SVM - Linear Kernel Imported successfully
2023-06-04 09:40:48,858:INFO:Starting cross validation
2023-06-04 09:40:48,909:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:40:52,212:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:40:52,228:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:40:52,235:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:40:52,279:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:40:52,281:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:40:52,297:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:40:52,299:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:40:52,307:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:40:52,485:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:40:52,835:INFO:Calculating mean and std
2023-06-04 09:40:52,838:INFO:Creating metrics dataframe
2023-06-04 09:40:53,155:INFO:Uploading results into container
2023-06-04 09:40:53,156:INFO:Uploading model into container now
2023-06-04 09:40:53,156:INFO:_master_model_container: 5
2023-06-04 09:40:53,156:INFO:_display_container: 2
2023-06-04 09:40:53,157:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-04 09:40:53,157:INFO:create_model() successfully completed......................................
2023-06-04 09:40:53,266:INFO:SubProcess create_model() end ==================================
2023-06-04 09:40:53,266:INFO:Creating metrics dataframe
2023-06-04 09:40:53,277:INFO:Initializing Ridge Classifier
2023-06-04 09:40:53,277:INFO:Total runtime is 0.499864399433136 minutes
2023-06-04 09:40:53,281:INFO:SubProcess create_model() called ==================================
2023-06-04 09:40:53,281:INFO:Initializing create_model()
2023-06-04 09:40:53,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:40:53,281:INFO:Checking exceptions
2023-06-04 09:40:53,281:INFO:Importing libraries
2023-06-04 09:40:53,281:INFO:Copying training dataset
2023-06-04 09:40:53,342:INFO:Defining folds
2023-06-04 09:40:53,342:INFO:Declaring metric variables
2023-06-04 09:40:53,346:INFO:Importing untrained model
2023-06-04 09:40:53,350:INFO:Ridge Classifier Imported successfully
2023-06-04 09:40:53,357:INFO:Starting cross validation
2023-06-04 09:40:53,394:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:40:56,482:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:40:56,506:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:40:56,513:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:40:56,546:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:40:56,554:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:40:56,574:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:40:56,575:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:40:56,614:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:40:57,199:INFO:Calculating mean and std
2023-06-04 09:40:57,202:INFO:Creating metrics dataframe
2023-06-04 09:40:57,290:INFO:Uploading results into container
2023-06-04 09:40:57,290:INFO:Uploading model into container now
2023-06-04 09:40:57,291:INFO:_master_model_container: 6
2023-06-04 09:40:57,291:INFO:_display_container: 2
2023-06-04 09:40:57,291:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-06-04 09:40:57,291:INFO:create_model() successfully completed......................................
2023-06-04 09:40:57,394:INFO:SubProcess create_model() end ==================================
2023-06-04 09:40:57,394:INFO:Creating metrics dataframe
2023-06-04 09:40:57,405:INFO:Initializing Random Forest Classifier
2023-06-04 09:40:57,405:INFO:Total runtime is 0.5686587651570638 minutes
2023-06-04 09:40:57,408:INFO:SubProcess create_model() called ==================================
2023-06-04 09:40:57,409:INFO:Initializing create_model()
2023-06-04 09:40:57,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:40:57,409:INFO:Checking exceptions
2023-06-04 09:40:57,409:INFO:Importing libraries
2023-06-04 09:40:57,409:INFO:Copying training dataset
2023-06-04 09:40:57,468:INFO:Defining folds
2023-06-04 09:40:57,469:INFO:Declaring metric variables
2023-06-04 09:40:57,472:INFO:Importing untrained model
2023-06-04 09:40:57,476:INFO:Random Forest Classifier Imported successfully
2023-06-04 09:40:57,483:INFO:Starting cross validation
2023-06-04 09:40:57,520:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:41:01,039:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:41:01,064:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:41:01,073:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:41:01,077:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:41:01,087:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:41:01,139:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:41:01,217:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:41:01,313:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:41:02,368:INFO:Calculating mean and std
2023-06-04 09:41:02,370:INFO:Creating metrics dataframe
2023-06-04 09:41:02,485:INFO:Uploading results into container
2023-06-04 09:41:02,486:INFO:Uploading model into container now
2023-06-04 09:41:02,486:INFO:_master_model_container: 7
2023-06-04 09:41:02,487:INFO:_display_container: 2
2023-06-04 09:41:02,487:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-06-04 09:41:02,488:INFO:create_model() successfully completed......................................
2023-06-04 09:41:02,599:INFO:SubProcess create_model() end ==================================
2023-06-04 09:41:02,599:INFO:Creating metrics dataframe
2023-06-04 09:41:02,611:INFO:Initializing Quadratic Discriminant Analysis
2023-06-04 09:41:02,611:INFO:Total runtime is 0.655431346098582 minutes
2023-06-04 09:41:02,615:INFO:SubProcess create_model() called ==================================
2023-06-04 09:41:02,616:INFO:Initializing create_model()
2023-06-04 09:41:02,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:41:02,616:INFO:Checking exceptions
2023-06-04 09:41:02,616:INFO:Importing libraries
2023-06-04 09:41:02,616:INFO:Copying training dataset
2023-06-04 09:41:02,675:INFO:Defining folds
2023-06-04 09:41:02,675:INFO:Declaring metric variables
2023-06-04 09:41:02,680:INFO:Importing untrained model
2023-06-04 09:41:02,684:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-04 09:41:02,691:INFO:Starting cross validation
2023-06-04 09:41:02,729:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:41:03,439:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:41:03,448:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:41:03,464:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:41:03,511:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:41:03,533:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:41:03,561:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:41:03,577:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:41:03,773:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:41:07,011:INFO:Calculating mean and std
2023-06-04 09:41:07,013:INFO:Creating metrics dataframe
2023-06-04 09:41:07,127:INFO:Uploading results into container
2023-06-04 09:41:07,128:INFO:Uploading model into container now
2023-06-04 09:41:07,128:INFO:_master_model_container: 8
2023-06-04 09:41:07,128:INFO:_display_container: 2
2023-06-04 09:41:07,129:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-04 09:41:07,129:INFO:create_model() successfully completed......................................
2023-06-04 09:41:07,235:INFO:SubProcess create_model() end ==================================
2023-06-04 09:41:07,235:INFO:Creating metrics dataframe
2023-06-04 09:41:07,247:INFO:Initializing Ada Boost Classifier
2023-06-04 09:41:07,247:INFO:Total runtime is 0.7326958537101746 minutes
2023-06-04 09:41:07,251:INFO:SubProcess create_model() called ==================================
2023-06-04 09:41:07,251:INFO:Initializing create_model()
2023-06-04 09:41:07,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:41:07,251:INFO:Checking exceptions
2023-06-04 09:41:07,251:INFO:Importing libraries
2023-06-04 09:41:07,251:INFO:Copying training dataset
2023-06-04 09:41:07,311:INFO:Defining folds
2023-06-04 09:41:07,311:INFO:Declaring metric variables
2023-06-04 09:41:07,315:INFO:Importing untrained model
2023-06-04 09:41:07,319:INFO:Ada Boost Classifier Imported successfully
2023-06-04 09:41:07,325:INFO:Starting cross validation
2023-06-04 09:41:07,363:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:41:30,003:INFO:Calculating mean and std
2023-06-04 09:41:30,006:INFO:Creating metrics dataframe
2023-06-04 09:41:30,122:INFO:Uploading results into container
2023-06-04 09:41:30,123:INFO:Uploading model into container now
2023-06-04 09:41:30,123:INFO:_master_model_container: 9
2023-06-04 09:41:30,124:INFO:_display_container: 2
2023-06-04 09:41:30,124:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-06-04 09:41:30,124:INFO:create_model() successfully completed......................................
2023-06-04 09:41:30,242:INFO:SubProcess create_model() end ==================================
2023-06-04 09:41:30,242:INFO:Creating metrics dataframe
2023-06-04 09:41:30,255:INFO:Initializing Gradient Boosting Classifier
2023-06-04 09:41:30,255:INFO:Total runtime is 1.116161342461904 minutes
2023-06-04 09:41:30,259:INFO:SubProcess create_model() called ==================================
2023-06-04 09:41:30,259:INFO:Initializing create_model()
2023-06-04 09:41:30,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:41:30,259:INFO:Checking exceptions
2023-06-04 09:41:30,259:INFO:Importing libraries
2023-06-04 09:41:30,259:INFO:Copying training dataset
2023-06-04 09:41:30,321:INFO:Defining folds
2023-06-04 09:41:30,321:INFO:Declaring metric variables
2023-06-04 09:41:30,325:INFO:Importing untrained model
2023-06-04 09:41:30,329:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 09:41:30,335:INFO:Starting cross validation
2023-06-04 09:41:30,373:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:42:39,384:INFO:Calculating mean and std
2023-06-04 09:42:39,388:INFO:Creating metrics dataframe
2023-06-04 09:42:39,737:INFO:Uploading results into container
2023-06-04 09:42:39,737:INFO:Uploading model into container now
2023-06-04 09:42:39,738:INFO:_master_model_container: 10
2023-06-04 09:42:39,738:INFO:_display_container: 2
2023-06-04 09:42:39,739:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 09:42:39,739:INFO:create_model() successfully completed......................................
2023-06-04 09:42:39,883:INFO:SubProcess create_model() end ==================================
2023-06-04 09:42:39,883:INFO:Creating metrics dataframe
2023-06-04 09:42:39,896:INFO:Initializing Linear Discriminant Analysis
2023-06-04 09:42:39,896:INFO:Total runtime is 2.2768389066060384 minutes
2023-06-04 09:42:39,899:INFO:SubProcess create_model() called ==================================
2023-06-04 09:42:39,900:INFO:Initializing create_model()
2023-06-04 09:42:39,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:42:39,900:INFO:Checking exceptions
2023-06-04 09:42:39,900:INFO:Importing libraries
2023-06-04 09:42:39,900:INFO:Copying training dataset
2023-06-04 09:42:39,962:INFO:Defining folds
2023-06-04 09:42:39,962:INFO:Declaring metric variables
2023-06-04 09:42:39,966:INFO:Importing untrained model
2023-06-04 09:42:39,969:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 09:42:39,976:INFO:Starting cross validation
2023-06-04 09:42:40,013:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:42:44,881:INFO:Calculating mean and std
2023-06-04 09:42:44,883:INFO:Creating metrics dataframe
2023-06-04 09:42:45,000:INFO:Uploading results into container
2023-06-04 09:42:45,000:INFO:Uploading model into container now
2023-06-04 09:42:45,001:INFO:_master_model_container: 11
2023-06-04 09:42:45,001:INFO:_display_container: 2
2023-06-04 09:42:45,001:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 09:42:45,001:INFO:create_model() successfully completed......................................
2023-06-04 09:42:45,119:INFO:SubProcess create_model() end ==================================
2023-06-04 09:42:45,120:INFO:Creating metrics dataframe
2023-06-04 09:42:45,133:INFO:Initializing Extra Trees Classifier
2023-06-04 09:42:45,133:INFO:Total runtime is 2.364120364189148 minutes
2023-06-04 09:42:45,136:INFO:SubProcess create_model() called ==================================
2023-06-04 09:42:45,136:INFO:Initializing create_model()
2023-06-04 09:42:45,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:42:45,137:INFO:Checking exceptions
2023-06-04 09:42:45,137:INFO:Importing libraries
2023-06-04 09:42:45,137:INFO:Copying training dataset
2023-06-04 09:42:45,198:INFO:Defining folds
2023-06-04 09:42:45,199:INFO:Declaring metric variables
2023-06-04 09:42:45,202:INFO:Importing untrained model
2023-06-04 09:42:45,206:INFO:Extra Trees Classifier Imported successfully
2023-06-04 09:42:45,213:INFO:Starting cross validation
2023-06-04 09:42:45,251:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:42:47,627:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:42:47,642:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:42:47,661:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:42:47,679:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:42:47,690:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:42:47,731:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:42:47,742:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:42:47,826:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:42:48,974:INFO:Calculating mean and std
2023-06-04 09:42:48,976:INFO:Creating metrics dataframe
2023-06-04 09:42:49,066:INFO:Uploading results into container
2023-06-04 09:42:49,067:INFO:Uploading model into container now
2023-06-04 09:42:49,067:INFO:_master_model_container: 12
2023-06-04 09:42:49,067:INFO:_display_container: 2
2023-06-04 09:42:49,067:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-06-04 09:42:49,067:INFO:create_model() successfully completed......................................
2023-06-04 09:42:49,169:INFO:SubProcess create_model() end ==================================
2023-06-04 09:42:49,170:INFO:Creating metrics dataframe
2023-06-04 09:42:49,182:INFO:Initializing Light Gradient Boosting Machine
2023-06-04 09:42:49,182:INFO:Total runtime is 2.431608859697978 minutes
2023-06-04 09:42:49,185:INFO:SubProcess create_model() called ==================================
2023-06-04 09:42:49,186:INFO:Initializing create_model()
2023-06-04 09:42:49,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:42:49,186:INFO:Checking exceptions
2023-06-04 09:42:49,186:INFO:Importing libraries
2023-06-04 09:42:49,186:INFO:Copying training dataset
2023-06-04 09:42:49,245:INFO:Defining folds
2023-06-04 09:42:49,245:INFO:Declaring metric variables
2023-06-04 09:42:49,249:INFO:Importing untrained model
2023-06-04 09:42:49,252:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-04 09:42:49,259:INFO:Starting cross validation
2023-06-04 09:42:49,297:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:43:45,274:INFO:Calculating mean and std
2023-06-04 09:43:45,278:INFO:Creating metrics dataframe
2023-06-04 09:43:45,632:INFO:Uploading results into container
2023-06-04 09:43:45,633:INFO:Uploading model into container now
2023-06-04 09:43:45,634:INFO:_master_model_container: 13
2023-06-04 09:43:45,634:INFO:_display_container: 2
2023-06-04 09:43:45,635:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-04 09:43:45,635:INFO:create_model() successfully completed......................................
2023-06-04 09:43:45,777:INFO:SubProcess create_model() end ==================================
2023-06-04 09:43:45,777:INFO:Creating metrics dataframe
2023-06-04 09:43:45,792:INFO:Initializing Dummy Classifier
2023-06-04 09:43:45,792:INFO:Total runtime is 3.3751114567120872 minutes
2023-06-04 09:43:45,796:INFO:SubProcess create_model() called ==================================
2023-06-04 09:43:45,796:INFO:Initializing create_model()
2023-06-04 09:43:45,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de010e80>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:43:45,796:INFO:Checking exceptions
2023-06-04 09:43:45,796:INFO:Importing libraries
2023-06-04 09:43:45,796:INFO:Copying training dataset
2023-06-04 09:43:45,861:INFO:Defining folds
2023-06-04 09:43:45,861:INFO:Declaring metric variables
2023-06-04 09:43:45,865:INFO:Importing untrained model
2023-06-04 09:43:45,869:INFO:Dummy Classifier Imported successfully
2023-06-04 09:43:45,877:INFO:Starting cross validation
2023-06-04 09:43:45,915:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:43:48,528:INFO:Calculating mean and std
2023-06-04 09:43:48,530:INFO:Creating metrics dataframe
2023-06-04 09:43:48,870:INFO:Uploading results into container
2023-06-04 09:43:48,870:INFO:Uploading model into container now
2023-06-04 09:43:48,871:INFO:_master_model_container: 14
2023-06-04 09:43:48,871:INFO:_display_container: 2
2023-06-04 09:43:48,871:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-06-04 09:43:48,871:INFO:create_model() successfully completed......................................
2023-06-04 09:43:48,975:INFO:SubProcess create_model() end ==================================
2023-06-04 09:43:48,976:INFO:Creating metrics dataframe
2023-06-04 09:43:49,000:INFO:Initializing create_model()
2023-06-04 09:43:49,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75dfb5f9d0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:43:49,000:INFO:Checking exceptions
2023-06-04 09:43:49,002:INFO:Importing libraries
2023-06-04 09:43:49,002:INFO:Copying training dataset
2023-06-04 09:43:49,070:INFO:Defining folds
2023-06-04 09:43:49,070:INFO:Declaring metric variables
2023-06-04 09:43:49,070:INFO:Importing untrained model
2023-06-04 09:43:49,070:INFO:Declaring custom model
2023-06-04 09:43:49,071:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 09:43:49,108:INFO:Cross validation set to False
2023-06-04 09:43:49,108:INFO:Fitting Model
2023-06-04 09:43:51,561:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 09:43:51,561:INFO:create_model() successfully completed......................................
2023-06-04 09:43:51,693:INFO:_master_model_container: 14
2023-06-04 09:43:51,693:INFO:_display_container: 2
2023-06-04 09:43:51,694:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 09:43:51,694:INFO:compare_models() successfully completed......................................
2023-06-04 09:44:32,218:INFO:Initializing set_config()
2023-06-04 09:44:32,219:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, variable=seed, value=42, kwargs={})
2023-06-04 09:44:32,220:INFO:Global variable: seed updated to 42
2023-06-04 09:44:32,220:INFO:set_config() successfully completed......................................
2023-06-04 09:44:32,349:INFO:PyCaret ClassificationExperiment
2023-06-04 09:44:32,349:INFO:Logging name: clf-default-name
2023-06-04 09:44:32,349:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-04 09:44:32,349:INFO:version 3.0.2
2023-06-04 09:44:32,349:INFO:Initializing setup()
2023-06-04 09:44:32,349:INFO:self.USI: 387b
2023-06-04 09:44:32,349:INFO:self._variable_keys: {'y_train', 'y', 'fix_imbalance', 'X_test', 'gpu_n_jobs_param', 'exp_name_log', 'USI', 'html_param', 'y_test', 'pipeline', 'exp_id', 'logging_param', 'fold_shuffle_param', 'X', 'X_train', '_available_plots', '_ml_usecase', 'data', 'is_multiclass', 'log_plots_param', 'fold_generator', 'idx', 'gpu_param', 'seed', 'memory', 'n_jobs_param', 'target_param', 'fold_groups_param'}
2023-06-04 09:44:32,349:INFO:Checking environment
2023-06-04 09:44:32,349:INFO:python_version: 3.9.16
2023-06-04 09:44:32,349:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-06-04 09:44:32,349:INFO:machine: x86_64
2023-06-04 09:44:32,350:INFO:platform: Linux-5.4.0-148-generic-x86_64-with-glibc2.31
2023-06-04 09:44:32,350:INFO:Memory: svmem(total=33556725760, available=14141358080, percent=57.9, used=18907439104, free=4791676928, active=20551524352, inactive=6099415040, buffers=376250368, cached=9481359360, shared=23322624, slab=1355206656)
2023-06-04 09:44:32,352:INFO:Physical Core: 28
2023-06-04 09:44:32,352:INFO:Logical Core: 56
2023-06-04 09:44:32,352:INFO:Checking libraries
2023-06-04 09:44:32,352:INFO:System:
2023-06-04 09:44:32,352:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-06-04 09:44:32,352:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-06-04 09:44:32,352:INFO:   machine: Linux-5.4.0-148-generic-x86_64-with-glibc2.31
2023-06-04 09:44:32,352:INFO:PyCaret required dependencies:
2023-06-04 09:44:32,353:INFO:                 pip: 23.0.1
2023-06-04 09:44:32,353:INFO:          setuptools: 66.0.0
2023-06-04 09:44:32,353:INFO:             pycaret: 3.0.2
2023-06-04 09:44:32,353:INFO:             IPython: 8.13.2
2023-06-04 09:44:32,353:INFO:          ipywidgets: 8.0.6
2023-06-04 09:44:32,353:INFO:                tqdm: 4.65.0
2023-06-04 09:44:32,353:INFO:               numpy: 1.23.5
2023-06-04 09:44:32,353:INFO:              pandas: 1.5.3
2023-06-04 09:44:32,353:INFO:              jinja2: 3.1.2
2023-06-04 09:44:32,353:INFO:               scipy: 1.10.1
2023-06-04 09:44:32,353:INFO:              joblib: 1.2.0
2023-06-04 09:44:32,353:INFO:             sklearn: 1.2.2
2023-06-04 09:44:32,353:INFO:                pyod: 1.0.9
2023-06-04 09:44:32,353:INFO:            imblearn: 0.10.1
2023-06-04 09:44:32,353:INFO:   category_encoders: 2.6.1
2023-06-04 09:44:32,353:INFO:            lightgbm: 3.3.5
2023-06-04 09:44:32,353:INFO:               numba: 0.57.0
2023-06-04 09:44:32,353:INFO:            requests: 2.28.1
2023-06-04 09:44:32,353:INFO:          matplotlib: 3.7.1
2023-06-04 09:44:32,353:INFO:          scikitplot: 0.3.7
2023-06-04 09:44:32,353:INFO:         yellowbrick: 1.5
2023-06-04 09:44:32,353:INFO:              plotly: 5.14.1
2023-06-04 09:44:32,353:INFO:             kaleido: 0.2.1
2023-06-04 09:44:32,353:INFO:         statsmodels: 0.14.0
2023-06-04 09:44:32,353:INFO:              sktime: 0.17.0
2023-06-04 09:44:32,353:INFO:               tbats: 1.1.3
2023-06-04 09:44:32,353:INFO:            pmdarima: 2.0.3
2023-06-04 09:44:32,353:INFO:              psutil: 5.9.5
2023-06-04 09:44:32,353:INFO:PyCaret optional dependencies:
2023-06-04 09:44:32,354:INFO:                shap: Not installed
2023-06-04 09:44:32,354:INFO:           interpret: Not installed
2023-06-04 09:44:32,354:INFO:                umap: Not installed
2023-06-04 09:44:32,354:INFO:    pandas_profiling: Not installed
2023-06-04 09:44:32,354:INFO:  explainerdashboard: Not installed
2023-06-04 09:44:32,354:INFO:             autoviz: Not installed
2023-06-04 09:44:32,354:INFO:           fairlearn: Not installed
2023-06-04 09:44:32,354:INFO:             xgboost: Not installed
2023-06-04 09:44:32,354:INFO:            catboost: Not installed
2023-06-04 09:44:32,354:INFO:              kmodes: Not installed
2023-06-04 09:44:32,354:INFO:             mlxtend: Not installed
2023-06-04 09:44:32,354:INFO:       statsforecast: Not installed
2023-06-04 09:44:32,354:INFO:        tune_sklearn: Not installed
2023-06-04 09:44:32,354:INFO:                 ray: Not installed
2023-06-04 09:44:32,354:INFO:            hyperopt: Not installed
2023-06-04 09:44:32,354:INFO:              optuna: Not installed
2023-06-04 09:44:32,354:INFO:               skopt: Not installed
2023-06-04 09:44:32,354:INFO:              mlflow: Not installed
2023-06-04 09:44:32,354:INFO:              gradio: Not installed
2023-06-04 09:44:32,354:INFO:             fastapi: Not installed
2023-06-04 09:44:32,354:INFO:             uvicorn: Not installed
2023-06-04 09:44:32,354:INFO:              m2cgen: Not installed
2023-06-04 09:44:32,354:INFO:           evidently: Not installed
2023-06-04 09:44:32,354:INFO:               fugue: Not installed
2023-06-04 09:44:32,354:INFO:           streamlit: Not installed
2023-06-04 09:44:32,354:INFO:             prophet: Not installed
2023-06-04 09:44:32,354:INFO:None
2023-06-04 09:44:32,354:INFO:Set up data.
2023-06-04 09:44:35,934:INFO:Set up train/test split.
2023-06-04 09:44:36,134:INFO:Set up index.
2023-06-04 09:44:36,134:INFO:Set up folding strategy.
2023-06-04 09:44:36,134:INFO:Assigning column types.
2023-06-04 09:44:36,256:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-04 09:44:36,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 09:44:36,295:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:44:36,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,358:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 09:44:36,359:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:44:36,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,383:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-04 09:44:36,422:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:44:36,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:44:36,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,509:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-04 09:44:36,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:36,637:INFO:Preparing preprocessing pipeline...
2023-06-04 09:44:36,658:INFO:Set up simple imputation.
2023-06-04 09:44:36,677:INFO:Set up column name cleaning.
2023-06-04 09:44:37,676:INFO:Finished creating preprocessing pipeline.
2023-06-04 09:44:37,735:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-04 09:44:37,735:INFO:Creating final display dataframe.
2023-06-04 09:44:40,425:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (742, 11886)
4        Transformed data shape      (742, 11886)
5   Transformed train set shape      (667, 11886)
6    Transformed test set shape       (75, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              387b
2023-06-04 09:44:40,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:40,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:40,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:40,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:44:40,561:INFO:setup() successfully completed in 8.34s...............
2023-06-04 09:44:44,686:INFO:Initializing compare_models()
2023-06-04 09:44:44,687:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-04 09:44:44,688:INFO:Checking exceptions
2023-06-04 09:44:44,804:INFO:Preparing display monitor
2023-06-04 09:44:44,826:INFO:Initializing Logistic Regression
2023-06-04 09:44:44,826:INFO:Total runtime is 3.0080477396647137e-06 minutes
2023-06-04 09:44:44,830:INFO:SubProcess create_model() called ==================================
2023-06-04 09:44:44,830:INFO:Initializing create_model()
2023-06-04 09:44:44,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:44:44,830:INFO:Checking exceptions
2023-06-04 09:44:44,830:INFO:Importing libraries
2023-06-04 09:44:44,830:INFO:Copying training dataset
2023-06-04 09:44:44,967:INFO:Defining folds
2023-06-04 09:44:44,967:INFO:Declaring metric variables
2023-06-04 09:44:44,971:INFO:Importing untrained model
2023-06-04 09:44:44,974:INFO:Logistic Regression Imported successfully
2023-06-04 09:44:44,981:INFO:Starting cross validation
2023-06-04 09:44:45,018:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:44:57,972:INFO:Calculating mean and std
2023-06-04 09:44:57,975:INFO:Creating metrics dataframe
2023-06-04 09:44:58,098:INFO:Uploading results into container
2023-06-04 09:44:58,099:INFO:Uploading model into container now
2023-06-04 09:44:58,100:INFO:_master_model_container: 1
2023-06-04 09:44:58,100:INFO:_display_container: 2
2023-06-04 09:44:58,100:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 09:44:58,100:INFO:create_model() successfully completed......................................
2023-06-04 09:44:58,254:INFO:SubProcess create_model() end ==================================
2023-06-04 09:44:58,254:INFO:Creating metrics dataframe
2023-06-04 09:44:58,265:INFO:Initializing K Neighbors Classifier
2023-06-04 09:44:58,265:INFO:Total runtime is 0.22397878567377727 minutes
2023-06-04 09:44:58,268:INFO:SubProcess create_model() called ==================================
2023-06-04 09:44:58,269:INFO:Initializing create_model()
2023-06-04 09:44:58,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:44:58,269:INFO:Checking exceptions
2023-06-04 09:44:58,269:INFO:Importing libraries
2023-06-04 09:44:58,269:INFO:Copying training dataset
2023-06-04 09:44:58,396:INFO:Defining folds
2023-06-04 09:44:58,396:INFO:Declaring metric variables
2023-06-04 09:44:58,400:INFO:Importing untrained model
2023-06-04 09:44:58,403:INFO:K Neighbors Classifier Imported successfully
2023-06-04 09:44:58,410:INFO:Starting cross validation
2023-06-04 09:44:58,448:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:45:01,639:INFO:Calculating mean and std
2023-06-04 09:45:01,641:INFO:Creating metrics dataframe
2023-06-04 09:45:02,001:INFO:Uploading results into container
2023-06-04 09:45:02,002:INFO:Uploading model into container now
2023-06-04 09:45:02,002:INFO:_master_model_container: 2
2023-06-04 09:45:02,003:INFO:_display_container: 2
2023-06-04 09:45:02,003:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-04 09:45:02,003:INFO:create_model() successfully completed......................................
2023-06-04 09:45:02,158:INFO:SubProcess create_model() end ==================================
2023-06-04 09:45:02,158:INFO:Creating metrics dataframe
2023-06-04 09:45:02,170:INFO:Initializing Naive Bayes
2023-06-04 09:45:02,170:INFO:Total runtime is 0.28905962308247884 minutes
2023-06-04 09:45:02,173:INFO:SubProcess create_model() called ==================================
2023-06-04 09:45:02,173:INFO:Initializing create_model()
2023-06-04 09:45:02,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:45:02,174:INFO:Checking exceptions
2023-06-04 09:45:02,174:INFO:Importing libraries
2023-06-04 09:45:02,174:INFO:Copying training dataset
2023-06-04 09:45:02,302:INFO:Defining folds
2023-06-04 09:45:02,302:INFO:Declaring metric variables
2023-06-04 09:45:02,306:INFO:Importing untrained model
2023-06-04 09:45:02,309:INFO:Naive Bayes Imported successfully
2023-06-04 09:45:02,316:INFO:Starting cross validation
2023-06-04 09:45:02,353:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:45:05,470:INFO:Calculating mean and std
2023-06-04 09:45:05,474:INFO:Creating metrics dataframe
2023-06-04 09:45:05,818:INFO:Uploading results into container
2023-06-04 09:45:05,819:INFO:Uploading model into container now
2023-06-04 09:45:05,820:INFO:_master_model_container: 3
2023-06-04 09:45:05,820:INFO:_display_container: 2
2023-06-04 09:45:05,820:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-04 09:45:05,820:INFO:create_model() successfully completed......................................
2023-06-04 09:45:05,988:INFO:SubProcess create_model() end ==================================
2023-06-04 09:45:05,988:INFO:Creating metrics dataframe
2023-06-04 09:45:06,000:INFO:Initializing Decision Tree Classifier
2023-06-04 09:45:06,000:INFO:Total runtime is 0.35289656321207685 minutes
2023-06-04 09:45:06,004:INFO:SubProcess create_model() called ==================================
2023-06-04 09:45:06,004:INFO:Initializing create_model()
2023-06-04 09:45:06,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:45:06,004:INFO:Checking exceptions
2023-06-04 09:45:06,004:INFO:Importing libraries
2023-06-04 09:45:06,004:INFO:Copying training dataset
2023-06-04 09:45:06,139:INFO:Defining folds
2023-06-04 09:45:06,139:INFO:Declaring metric variables
2023-06-04 09:45:06,143:INFO:Importing untrained model
2023-06-04 09:45:06,146:INFO:Decision Tree Classifier Imported successfully
2023-06-04 09:45:06,153:INFO:Starting cross validation
2023-06-04 09:45:06,190:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:45:10,736:INFO:Calculating mean and std
2023-06-04 09:45:10,739:INFO:Creating metrics dataframe
2023-06-04 09:45:10,868:INFO:Uploading results into container
2023-06-04 09:45:10,869:INFO:Uploading model into container now
2023-06-04 09:45:10,869:INFO:_master_model_container: 4
2023-06-04 09:45:10,869:INFO:_display_container: 2
2023-06-04 09:45:10,870:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-06-04 09:45:10,870:INFO:create_model() successfully completed......................................
2023-06-04 09:45:11,019:INFO:SubProcess create_model() end ==================================
2023-06-04 09:45:11,019:INFO:Creating metrics dataframe
2023-06-04 09:45:11,031:INFO:Initializing SVM - Linear Kernel
2023-06-04 09:45:11,031:INFO:Total runtime is 0.43674435615539553 minutes
2023-06-04 09:45:11,034:INFO:SubProcess create_model() called ==================================
2023-06-04 09:45:11,035:INFO:Initializing create_model()
2023-06-04 09:45:11,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:45:11,035:INFO:Checking exceptions
2023-06-04 09:45:11,035:INFO:Importing libraries
2023-06-04 09:45:11,035:INFO:Copying training dataset
2023-06-04 09:45:11,167:INFO:Defining folds
2023-06-04 09:45:11,168:INFO:Declaring metric variables
2023-06-04 09:45:11,171:INFO:Importing untrained model
2023-06-04 09:45:11,175:INFO:SVM - Linear Kernel Imported successfully
2023-06-04 09:45:11,182:INFO:Starting cross validation
2023-06-04 09:45:11,220:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:45:13,481:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:45:13,498:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:45:13,555:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:45:13,606:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:45:13,629:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:45:13,647:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:45:13,648:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:45:13,670:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-04 09:45:14,163:INFO:Calculating mean and std
2023-06-04 09:45:14,166:INFO:Creating metrics dataframe
2023-06-04 09:45:14,529:INFO:Uploading results into container
2023-06-04 09:45:14,530:INFO:Uploading model into container now
2023-06-04 09:45:14,530:INFO:_master_model_container: 5
2023-06-04 09:45:14,530:INFO:_display_container: 2
2023-06-04 09:45:14,531:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-04 09:45:14,531:INFO:create_model() successfully completed......................................
2023-06-04 09:45:14,661:INFO:SubProcess create_model() end ==================================
2023-06-04 09:45:14,661:INFO:Creating metrics dataframe
2023-06-04 09:45:14,673:INFO:Initializing Ridge Classifier
2023-06-04 09:45:14,673:INFO:Total runtime is 0.4974453647931417 minutes
2023-06-04 09:45:14,676:INFO:SubProcess create_model() called ==================================
2023-06-04 09:45:14,677:INFO:Initializing create_model()
2023-06-04 09:45:14,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:45:14,677:INFO:Checking exceptions
2023-06-04 09:45:14,677:INFO:Importing libraries
2023-06-04 09:45:14,677:INFO:Copying training dataset
2023-06-04 09:45:14,803:INFO:Defining folds
2023-06-04 09:45:14,803:INFO:Declaring metric variables
2023-06-04 09:45:14,807:INFO:Importing untrained model
2023-06-04 09:45:14,810:INFO:Ridge Classifier Imported successfully
2023-06-04 09:45:14,817:INFO:Starting cross validation
2023-06-04 09:45:14,854:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:45:15,795:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.82598e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-06-04 09:45:15,800:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.77794e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-06-04 09:45:15,817:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.85249e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-06-04 09:45:17,091:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:45:17,094:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:45:17,094:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:45:17,103:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:45:17,107:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:45:17,116:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:45:17,139:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:45:17,341:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-04 09:45:17,847:INFO:Calculating mean and std
2023-06-04 09:45:17,850:INFO:Creating metrics dataframe
2023-06-04 09:45:17,972:INFO:Uploading results into container
2023-06-04 09:45:17,973:INFO:Uploading model into container now
2023-06-04 09:45:17,973:INFO:_master_model_container: 6
2023-06-04 09:45:17,973:INFO:_display_container: 2
2023-06-04 09:45:17,973:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-06-04 09:45:17,974:INFO:create_model() successfully completed......................................
2023-06-04 09:45:18,100:INFO:SubProcess create_model() end ==================================
2023-06-04 09:45:18,100:INFO:Creating metrics dataframe
2023-06-04 09:45:18,112:INFO:Initializing Random Forest Classifier
2023-06-04 09:45:18,112:INFO:Total runtime is 0.5547645370165507 minutes
2023-06-04 09:45:18,115:INFO:SubProcess create_model() called ==================================
2023-06-04 09:45:18,116:INFO:Initializing create_model()
2023-06-04 09:45:18,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:45:18,116:INFO:Checking exceptions
2023-06-04 09:45:18,116:INFO:Importing libraries
2023-06-04 09:45:18,116:INFO:Copying training dataset
2023-06-04 09:45:18,242:INFO:Defining folds
2023-06-04 09:45:18,242:INFO:Declaring metric variables
2023-06-04 09:45:18,246:INFO:Importing untrained model
2023-06-04 09:45:18,250:INFO:Random Forest Classifier Imported successfully
2023-06-04 09:45:18,256:INFO:Starting cross validation
2023-06-04 09:45:18,294:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:45:21,157:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-04 09:45:22,364:INFO:Calculating mean and std
2023-06-04 09:45:22,366:INFO:Creating metrics dataframe
2023-06-04 09:45:22,493:INFO:Uploading results into container
2023-06-04 09:45:22,494:INFO:Uploading model into container now
2023-06-04 09:45:22,494:INFO:_master_model_container: 7
2023-06-04 09:45:22,494:INFO:_display_container: 2
2023-06-04 09:45:22,495:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-06-04 09:45:22,495:INFO:create_model() successfully completed......................................
2023-06-04 09:45:22,625:INFO:SubProcess create_model() end ==================================
2023-06-04 09:45:22,625:INFO:Creating metrics dataframe
2023-06-04 09:45:22,637:INFO:Initializing Quadratic Discriminant Analysis
2023-06-04 09:45:22,638:INFO:Total runtime is 0.6301897406578064 minutes
2023-06-04 09:45:22,641:INFO:SubProcess create_model() called ==================================
2023-06-04 09:45:22,641:INFO:Initializing create_model()
2023-06-04 09:45:22,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:45:22,641:INFO:Checking exceptions
2023-06-04 09:45:22,642:INFO:Importing libraries
2023-06-04 09:45:22,642:INFO:Copying training dataset
2023-06-04 09:45:22,773:INFO:Defining folds
2023-06-04 09:45:22,773:INFO:Declaring metric variables
2023-06-04 09:45:22,778:INFO:Importing untrained model
2023-06-04 09:45:22,781:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-04 09:45:22,788:INFO:Starting cross validation
2023-06-04 09:45:22,825:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:45:24,706:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:45:24,707:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:45:24,764:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:45:24,791:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:45:24,809:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:45:24,910:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:45:24,910:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:45:24,994:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:45:28,136:INFO:Calculating mean and std
2023-06-04 09:45:28,140:INFO:Creating metrics dataframe
2023-06-04 09:45:28,520:INFO:Uploading results into container
2023-06-04 09:45:28,521:INFO:Uploading model into container now
2023-06-04 09:45:28,521:INFO:_master_model_container: 8
2023-06-04 09:45:28,521:INFO:_display_container: 2
2023-06-04 09:45:28,522:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-04 09:45:28,522:INFO:create_model() successfully completed......................................
2023-06-04 09:45:28,658:INFO:SubProcess create_model() end ==================================
2023-06-04 09:45:28,658:INFO:Creating metrics dataframe
2023-06-04 09:45:28,672:INFO:Initializing Ada Boost Classifier
2023-06-04 09:45:28,672:INFO:Total runtime is 0.7307629148165385 minutes
2023-06-04 09:45:28,676:INFO:SubProcess create_model() called ==================================
2023-06-04 09:45:28,676:INFO:Initializing create_model()
2023-06-04 09:45:28,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:45:28,676:INFO:Checking exceptions
2023-06-04 09:45:28,676:INFO:Importing libraries
2023-06-04 09:45:28,677:INFO:Copying training dataset
2023-06-04 09:45:28,811:INFO:Defining folds
2023-06-04 09:45:28,812:INFO:Declaring metric variables
2023-06-04 09:45:28,817:INFO:Importing untrained model
2023-06-04 09:45:28,821:INFO:Ada Boost Classifier Imported successfully
2023-06-04 09:45:28,829:INFO:Starting cross validation
2023-06-04 09:45:28,868:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:46:07,921:INFO:Calculating mean and std
2023-06-04 09:46:07,924:INFO:Creating metrics dataframe
2023-06-04 09:46:08,303:INFO:Uploading results into container
2023-06-04 09:46:08,304:INFO:Uploading model into container now
2023-06-04 09:46:08,305:INFO:_master_model_container: 9
2023-06-04 09:46:08,305:INFO:_display_container: 2
2023-06-04 09:46:08,305:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-06-04 09:46:08,305:INFO:create_model() successfully completed......................................
2023-06-04 09:46:08,444:INFO:SubProcess create_model() end ==================================
2023-06-04 09:46:08,445:INFO:Creating metrics dataframe
2023-06-04 09:46:08,457:INFO:Initializing Gradient Boosting Classifier
2023-06-04 09:46:08,457:INFO:Total runtime is 1.3938544392585754 minutes
2023-06-04 09:46:08,461:INFO:SubProcess create_model() called ==================================
2023-06-04 09:46:08,461:INFO:Initializing create_model()
2023-06-04 09:46:08,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:46:08,461:INFO:Checking exceptions
2023-06-04 09:46:08,461:INFO:Importing libraries
2023-06-04 09:46:08,461:INFO:Copying training dataset
2023-06-04 09:46:08,593:INFO:Defining folds
2023-06-04 09:46:08,593:INFO:Declaring metric variables
2023-06-04 09:46:08,597:INFO:Importing untrained model
2023-06-04 09:46:08,600:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 09:46:08,607:INFO:Starting cross validation
2023-06-04 09:46:08,647:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:48:44,934:INFO:Calculating mean and std
2023-06-04 09:48:44,938:INFO:Creating metrics dataframe
2023-06-04 09:48:45,328:INFO:Uploading results into container
2023-06-04 09:48:45,329:INFO:Uploading model into container now
2023-06-04 09:48:45,329:INFO:_master_model_container: 10
2023-06-04 09:48:45,330:INFO:_display_container: 2
2023-06-04 09:48:45,330:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 09:48:45,330:INFO:create_model() successfully completed......................................
2023-06-04 09:48:45,491:INFO:SubProcess create_model() end ==================================
2023-06-04 09:48:45,492:INFO:Creating metrics dataframe
2023-06-04 09:48:45,506:INFO:Initializing Linear Discriminant Analysis
2023-06-04 09:48:45,506:INFO:Total runtime is 4.011331780751546 minutes
2023-06-04 09:48:45,510:INFO:SubProcess create_model() called ==================================
2023-06-04 09:48:45,510:INFO:Initializing create_model()
2023-06-04 09:48:45,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:48:45,510:INFO:Checking exceptions
2023-06-04 09:48:45,511:INFO:Importing libraries
2023-06-04 09:48:45,511:INFO:Copying training dataset
2023-06-04 09:48:45,643:INFO:Defining folds
2023-06-04 09:48:45,643:INFO:Declaring metric variables
2023-06-04 09:48:45,647:INFO:Importing untrained model
2023-06-04 09:48:45,651:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 09:48:45,658:INFO:Starting cross validation
2023-06-04 09:48:45,697:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:48:52,005:INFO:Calculating mean and std
2023-06-04 09:48:52,007:INFO:Creating metrics dataframe
2023-06-04 09:48:52,391:INFO:Uploading results into container
2023-06-04 09:48:52,392:INFO:Uploading model into container now
2023-06-04 09:48:52,392:INFO:_master_model_container: 11
2023-06-04 09:48:52,392:INFO:_display_container: 2
2023-06-04 09:48:52,393:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 09:48:52,393:INFO:create_model() successfully completed......................................
2023-06-04 09:48:52,538:INFO:SubProcess create_model() end ==================================
2023-06-04 09:48:52,538:INFO:Creating metrics dataframe
2023-06-04 09:48:52,551:INFO:Initializing Extra Trees Classifier
2023-06-04 09:48:52,551:INFO:Total runtime is 4.128753360112508 minutes
2023-06-04 09:48:52,555:INFO:SubProcess create_model() called ==================================
2023-06-04 09:48:52,555:INFO:Initializing create_model()
2023-06-04 09:48:52,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:48:52,555:INFO:Checking exceptions
2023-06-04 09:48:52,555:INFO:Importing libraries
2023-06-04 09:48:52,556:INFO:Copying training dataset
2023-06-04 09:48:52,683:INFO:Defining folds
2023-06-04 09:48:52,683:INFO:Declaring metric variables
2023-06-04 09:48:52,687:INFO:Importing untrained model
2023-06-04 09:48:52,691:INFO:Extra Trees Classifier Imported successfully
2023-06-04 09:48:52,697:INFO:Starting cross validation
2023-06-04 09:48:52,734:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:48:56,471:INFO:Calculating mean and std
2023-06-04 09:48:56,473:INFO:Creating metrics dataframe
2023-06-04 09:48:56,854:INFO:Uploading results into container
2023-06-04 09:48:56,855:INFO:Uploading model into container now
2023-06-04 09:48:56,856:INFO:_master_model_container: 12
2023-06-04 09:48:56,856:INFO:_display_container: 2
2023-06-04 09:48:56,856:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-06-04 09:48:56,856:INFO:create_model() successfully completed......................................
2023-06-04 09:48:56,986:INFO:SubProcess create_model() end ==================================
2023-06-04 09:48:56,986:INFO:Creating metrics dataframe
2023-06-04 09:48:57,000:INFO:Initializing Light Gradient Boosting Machine
2023-06-04 09:48:57,001:INFO:Total runtime is 4.202907145023346 minutes
2023-06-04 09:48:57,005:INFO:SubProcess create_model() called ==================================
2023-06-04 09:48:57,005:INFO:Initializing create_model()
2023-06-04 09:48:57,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:48:57,006:INFO:Checking exceptions
2023-06-04 09:48:57,006:INFO:Importing libraries
2023-06-04 09:48:57,006:INFO:Copying training dataset
2023-06-04 09:48:57,135:INFO:Defining folds
2023-06-04 09:48:57,135:INFO:Declaring metric variables
2023-06-04 09:48:57,140:INFO:Importing untrained model
2023-06-04 09:48:57,145:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-04 09:48:57,153:INFO:Starting cross validation
2023-06-04 09:48:57,193:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:51:13,580:INFO:Calculating mean and std
2023-06-04 09:51:13,584:INFO:Creating metrics dataframe
2023-06-04 09:51:13,989:INFO:Uploading results into container
2023-06-04 09:51:13,990:INFO:Uploading model into container now
2023-06-04 09:51:13,991:INFO:_master_model_container: 13
2023-06-04 09:51:13,991:INFO:_display_container: 2
2023-06-04 09:51:13,992:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-04 09:51:13,992:INFO:create_model() successfully completed......................................
2023-06-04 09:51:14,163:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:14,163:INFO:Creating metrics dataframe
2023-06-04 09:51:14,178:INFO:Initializing Dummy Classifier
2023-06-04 09:51:14,178:INFO:Total runtime is 6.48920183579127 minutes
2023-06-04 09:51:14,182:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:14,182:INFO:Initializing create_model()
2023-06-04 09:51:14,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75d7e3a400>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:14,182:INFO:Checking exceptions
2023-06-04 09:51:14,182:INFO:Importing libraries
2023-06-04 09:51:14,183:INFO:Copying training dataset
2023-06-04 09:51:14,314:INFO:Defining folds
2023-06-04 09:51:14,315:INFO:Declaring metric variables
2023-06-04 09:51:14,319:INFO:Importing untrained model
2023-06-04 09:51:14,323:INFO:Dummy Classifier Imported successfully
2023-06-04 09:51:14,331:INFO:Starting cross validation
2023-06-04 09:51:14,370:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-06-04 09:51:16,808:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 09:51:16,911:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 09:51:16,929:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 09:51:17,064:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-04 09:51:17,616:INFO:Calculating mean and std
2023-06-04 09:51:17,620:INFO:Creating metrics dataframe
2023-06-04 09:51:17,725:INFO:Uploading results into container
2023-06-04 09:51:17,726:INFO:Uploading model into container now
2023-06-04 09:51:17,726:INFO:_master_model_container: 14
2023-06-04 09:51:17,727:INFO:_display_container: 2
2023-06-04 09:51:17,727:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-06-04 09:51:17,727:INFO:create_model() successfully completed......................................
2023-06-04 09:51:17,872:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:17,872:INFO:Creating metrics dataframe
2023-06-04 09:51:17,895:INFO:Initializing create_model()
2023-06-04 09:51:17,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75de3c4940>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:17,895:INFO:Checking exceptions
2023-06-04 09:51:17,897:INFO:Importing libraries
2023-06-04 09:51:17,897:INFO:Copying training dataset
2023-06-04 09:51:18,026:INFO:Defining folds
2023-06-04 09:51:18,026:INFO:Declaring metric variables
2023-06-04 09:51:18,026:INFO:Importing untrained model
2023-06-04 09:51:18,026:INFO:Declaring custom model
2023-06-04 09:51:18,027:INFO:Logistic Regression Imported successfully
2023-06-04 09:51:18,063:INFO:Cross validation set to False
2023-06-04 09:51:18,063:INFO:Fitting Model
2023-06-04 09:51:22,169:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 09:51:22,169:INFO:create_model() successfully completed......................................
2023-06-04 09:51:22,345:INFO:_master_model_container: 14
2023-06-04 09:51:22,345:INFO:_display_container: 2
2023-06-04 09:51:22,346:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 09:51:22,346:INFO:compare_models() successfully completed......................................
2023-06-04 09:51:34,442:INFO:Initializing set_config()
2023-06-04 09:51:34,443:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, variable=seed, value=42, kwargs={})
2023-06-04 09:51:34,443:INFO:Global variable: seed updated to 42
2023-06-04 09:51:34,444:INFO:set_config() successfully completed......................................
2023-06-04 09:51:34,585:INFO:PyCaret ClassificationExperiment
2023-06-04 09:51:34,586:INFO:Logging name: clf-default-name
2023-06-04 09:51:34,586:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-04 09:51:34,586:INFO:version 3.0.2
2023-06-04 09:51:34,586:INFO:Initializing setup()
2023-06-04 09:51:34,586:INFO:self.USI: 39a0
2023-06-04 09:51:34,586:INFO:self._variable_keys: {'y_train', 'y', 'fix_imbalance', 'X_test', 'gpu_n_jobs_param', 'exp_name_log', 'USI', 'html_param', 'y_test', 'pipeline', 'exp_id', 'logging_param', 'fold_shuffle_param', 'X', 'X_train', '_available_plots', '_ml_usecase', 'data', 'is_multiclass', 'log_plots_param', 'fold_generator', 'idx', 'gpu_param', 'seed', 'memory', 'n_jobs_param', 'target_param', 'fold_groups_param'}
2023-06-04 09:51:34,586:INFO:Checking environment
2023-06-04 09:51:34,586:INFO:python_version: 3.9.16
2023-06-04 09:51:34,586:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-06-04 09:51:34,586:INFO:machine: x86_64
2023-06-04 09:51:34,586:INFO:platform: Linux-5.4.0-148-generic-x86_64-with-glibc2.31
2023-06-04 09:51:34,586:INFO:Memory: svmem(total=33556725760, available=15803584512, percent=52.9, used=17242980352, free=12033716224, active=15889301504, inactive=3755147264, buffers=261939200, cached=4018089984, shared=23207936, slab=1117933568)
2023-06-04 09:51:34,588:INFO:Physical Core: 28
2023-06-04 09:51:34,588:INFO:Logical Core: 56
2023-06-04 09:51:34,588:INFO:Checking libraries
2023-06-04 09:51:34,588:INFO:System:
2023-06-04 09:51:34,588:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-06-04 09:51:34,588:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-06-04 09:51:34,588:INFO:   machine: Linux-5.4.0-148-generic-x86_64-with-glibc2.31
2023-06-04 09:51:34,588:INFO:PyCaret required dependencies:
2023-06-04 09:51:34,588:INFO:                 pip: 23.0.1
2023-06-04 09:51:34,588:INFO:          setuptools: 66.0.0
2023-06-04 09:51:34,588:INFO:             pycaret: 3.0.2
2023-06-04 09:51:34,588:INFO:             IPython: 8.13.2
2023-06-04 09:51:34,588:INFO:          ipywidgets: 8.0.6
2023-06-04 09:51:34,588:INFO:                tqdm: 4.65.0
2023-06-04 09:51:34,588:INFO:               numpy: 1.23.5
2023-06-04 09:51:34,588:INFO:              pandas: 1.5.3
2023-06-04 09:51:34,588:INFO:              jinja2: 3.1.2
2023-06-04 09:51:34,588:INFO:               scipy: 1.10.1
2023-06-04 09:51:34,589:INFO:              joblib: 1.2.0
2023-06-04 09:51:34,589:INFO:             sklearn: 1.2.2
2023-06-04 09:51:34,589:INFO:                pyod: 1.0.9
2023-06-04 09:51:34,589:INFO:            imblearn: 0.10.1
2023-06-04 09:51:34,589:INFO:   category_encoders: 2.6.1
2023-06-04 09:51:34,589:INFO:            lightgbm: 3.3.5
2023-06-04 09:51:34,589:INFO:               numba: 0.57.0
2023-06-04 09:51:34,589:INFO:            requests: 2.28.1
2023-06-04 09:51:34,589:INFO:          matplotlib: 3.7.1
2023-06-04 09:51:34,589:INFO:          scikitplot: 0.3.7
2023-06-04 09:51:34,589:INFO:         yellowbrick: 1.5
2023-06-04 09:51:34,589:INFO:              plotly: 5.14.1
2023-06-04 09:51:34,589:INFO:             kaleido: 0.2.1
2023-06-04 09:51:34,589:INFO:         statsmodels: 0.14.0
2023-06-04 09:51:34,589:INFO:              sktime: 0.17.0
2023-06-04 09:51:34,589:INFO:               tbats: 1.1.3
2023-06-04 09:51:34,589:INFO:            pmdarima: 2.0.3
2023-06-04 09:51:34,589:INFO:              psutil: 5.9.5
2023-06-04 09:51:34,589:INFO:PyCaret optional dependencies:
2023-06-04 09:51:34,589:INFO:                shap: Not installed
2023-06-04 09:51:34,589:INFO:           interpret: Not installed
2023-06-04 09:51:34,589:INFO:                umap: Not installed
2023-06-04 09:51:34,589:INFO:    pandas_profiling: Not installed
2023-06-04 09:51:34,589:INFO:  explainerdashboard: Not installed
2023-06-04 09:51:34,589:INFO:             autoviz: Not installed
2023-06-04 09:51:34,589:INFO:           fairlearn: Not installed
2023-06-04 09:51:34,589:INFO:             xgboost: Not installed
2023-06-04 09:51:34,589:INFO:            catboost: Not installed
2023-06-04 09:51:34,589:INFO:              kmodes: Not installed
2023-06-04 09:51:34,589:INFO:             mlxtend: Not installed
2023-06-04 09:51:34,589:INFO:       statsforecast: Not installed
2023-06-04 09:51:34,590:INFO:        tune_sklearn: Not installed
2023-06-04 09:51:34,590:INFO:                 ray: Not installed
2023-06-04 09:51:34,590:INFO:            hyperopt: Not installed
2023-06-04 09:51:34,590:INFO:              optuna: Not installed
2023-06-04 09:51:34,590:INFO:               skopt: Not installed
2023-06-04 09:51:34,590:INFO:              mlflow: Not installed
2023-06-04 09:51:34,590:INFO:              gradio: Not installed
2023-06-04 09:51:34,590:INFO:             fastapi: Not installed
2023-06-04 09:51:34,590:INFO:             uvicorn: Not installed
2023-06-04 09:51:34,590:INFO:              m2cgen: Not installed
2023-06-04 09:51:34,590:INFO:           evidently: Not installed
2023-06-04 09:51:34,590:INFO:               fugue: Not installed
2023-06-04 09:51:34,590:INFO:           streamlit: Not installed
2023-06-04 09:51:34,590:INFO:             prophet: Not installed
2023-06-04 09:51:34,590:INFO:None
2023-06-04 09:51:34,590:INFO:Set up data.
2023-06-04 09:51:34,670:INFO:Set up train/test split.
2023-06-04 09:51:34,678:INFO:Set up index.
2023-06-04 09:51:34,678:INFO:Set up folding strategy.
2023-06-04 09:51:34,678:INFO:Assigning column types.
2023-06-04 09:51:34,682:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-04 09:51:34,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 09:51:34,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:51:34,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-04 09:51:34,784:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:51:34,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,809:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-04 09:51:34,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:51:34,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,910:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-04 09:51:34,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,934:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-04 09:51:34,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:34,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:35,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:35,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:35,062:INFO:Preparing preprocessing pipeline...
2023-06-04 09:51:35,063:INFO:Set up simple imputation.
2023-06-04 09:51:35,091:INFO:Finished creating preprocessing pipeline.
2023-06-04 09:51:35,096:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-06-04 09:51:35,096:INFO:Creating final display dataframe.
2023-06-04 09:51:35,204:INFO:Setup _display_container:                     Description             Value
0                    Session id                44
1                        Target             group
2                   Target type            Binary
3           Original data shape        (742, 294)
4        Transformed data shape        (742, 294)
5   Transformed train set shape        (667, 294)
6    Transformed test set shape         (75, 294)
7              Numeric features               293
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              39a0
2023-06-04 09:51:35,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:35,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:35,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:35,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-04 09:51:35,336:INFO:setup() successfully completed in 0.89s...............
2023-06-04 09:51:51,232:INFO:Initializing compare_models()
2023-06-04 09:51:51,233:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, include=None, fold=None, round=4, cross_validation=False, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': False, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-04 09:51:51,233:INFO:Checking exceptions
2023-06-04 09:51:51,244:INFO:Preparing display monitor
2023-06-04 09:51:51,276:INFO:Initializing Logistic Regression
2023-06-04 09:51:51,276:INFO:Total runtime is 3.441174825032552e-06 minutes
2023-06-04 09:51:51,280:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:51,281:INFO:Initializing create_model()
2023-06-04 09:51:51,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:51,281:INFO:Checking exceptions
2023-06-04 09:51:51,281:INFO:Importing libraries
2023-06-04 09:51:51,281:INFO:Copying training dataset
2023-06-04 09:51:51,288:INFO:Defining folds
2023-06-04 09:51:51,288:INFO:Declaring metric variables
2023-06-04 09:51:51,292:INFO:Importing untrained model
2023-06-04 09:51:51,297:INFO:Logistic Regression Imported successfully
2023-06-04 09:51:51,303:INFO:Cross validation set to False
2023-06-04 09:51:51,303:INFO:Fitting Model
2023-06-04 09:51:51,416:INFO:Initializing predict_model()
2023-06-04 09:51:51,416:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=44,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f763ae0d0d0>)
2023-06-04 09:51:51,416:INFO:Checking exceptions
2023-06-04 09:51:51,416:INFO:Preloading libraries
2023-06-04 09:51:51,702:INFO:_display_container: 2
2023-06-04 09:51:51,801:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 09:51:51,801:INFO:create_model() successfully completed......................................
2023-06-04 09:51:51,925:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:51,925:INFO:Creating metrics dataframe
2023-06-04 09:51:51,934:INFO:Initializing K Neighbors Classifier
2023-06-04 09:51:51,934:INFO:Total runtime is 0.010977514584859212 minutes
2023-06-04 09:51:51,938:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:51,938:INFO:Initializing create_model()
2023-06-04 09:51:51,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:51,939:INFO:Checking exceptions
2023-06-04 09:51:51,939:INFO:Importing libraries
2023-06-04 09:51:51,939:INFO:Copying training dataset
2023-06-04 09:51:51,945:INFO:Defining folds
2023-06-04 09:51:51,945:INFO:Declaring metric variables
2023-06-04 09:51:51,948:INFO:Importing untrained model
2023-06-04 09:51:51,951:INFO:K Neighbors Classifier Imported successfully
2023-06-04 09:51:51,956:INFO:Cross validation set to False
2023-06-04 09:51:51,956:INFO:Fitting Model
2023-06-04 09:51:51,995:INFO:Initializing predict_model()
2023-06-04 09:51:51,995:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f75de960ca0>)
2023-06-04 09:51:51,995:INFO:Checking exceptions
2023-06-04 09:51:51,995:INFO:Preloading libraries
2023-06-04 09:51:52,438:INFO:_display_container: 2
2023-06-04 09:51:52,537:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-04 09:51:52,537:INFO:create_model() successfully completed......................................
2023-06-04 09:51:52,670:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:52,670:INFO:Creating metrics dataframe
2023-06-04 09:51:52,681:INFO:Initializing Naive Bayes
2023-06-04 09:51:52,682:INFO:Total runtime is 0.023428420225779213 minutes
2023-06-04 09:51:52,685:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:52,685:INFO:Initializing create_model()
2023-06-04 09:51:52,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:52,686:INFO:Checking exceptions
2023-06-04 09:51:52,686:INFO:Importing libraries
2023-06-04 09:51:52,686:INFO:Copying training dataset
2023-06-04 09:51:52,692:INFO:Defining folds
2023-06-04 09:51:52,692:INFO:Declaring metric variables
2023-06-04 09:51:52,695:INFO:Importing untrained model
2023-06-04 09:51:52,699:INFO:Naive Bayes Imported successfully
2023-06-04 09:51:52,703:INFO:Cross validation set to False
2023-06-04 09:51:52,703:INFO:Fitting Model
2023-06-04 09:51:52,743:INFO:Initializing predict_model()
2023-06-04 09:51:52,743:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f75de960ca0>)
2023-06-04 09:51:52,743:INFO:Checking exceptions
2023-06-04 09:51:52,743:INFO:Preloading libraries
2023-06-04 09:51:52,963:INFO:_display_container: 2
2023-06-04 09:51:53,062:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-04 09:51:53,062:INFO:create_model() successfully completed......................................
2023-06-04 09:51:53,205:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:53,205:INFO:Creating metrics dataframe
2023-06-04 09:51:53,216:INFO:Initializing Decision Tree Classifier
2023-06-04 09:51:53,216:INFO:Total runtime is 0.03233610391616821 minutes
2023-06-04 09:51:53,219:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:53,220:INFO:Initializing create_model()
2023-06-04 09:51:53,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:53,220:INFO:Checking exceptions
2023-06-04 09:51:53,220:INFO:Importing libraries
2023-06-04 09:51:53,220:INFO:Copying training dataset
2023-06-04 09:51:53,226:INFO:Defining folds
2023-06-04 09:51:53,226:INFO:Declaring metric variables
2023-06-04 09:51:53,230:INFO:Importing untrained model
2023-06-04 09:51:53,233:INFO:Decision Tree Classifier Imported successfully
2023-06-04 09:51:53,238:INFO:Cross validation set to False
2023-06-04 09:51:53,238:INFO:Fitting Model
2023-06-04 09:51:53,310:INFO:Initializing predict_model()
2023-06-04 09:51:53,310:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=44, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f763ae0d040>)
2023-06-04 09:51:53,310:INFO:Checking exceptions
2023-06-04 09:51:53,310:INFO:Preloading libraries
2023-06-04 09:51:53,534:INFO:_display_container: 2
2023-06-04 09:51:53,630:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=44, splitter='best')
2023-06-04 09:51:53,630:INFO:create_model() successfully completed......................................
2023-06-04 09:51:53,782:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:53,782:INFO:Creating metrics dataframe
2023-06-04 09:51:53,793:INFO:Initializing SVM - Linear Kernel
2023-06-04 09:51:53,794:INFO:Total runtime is 0.041961995760599766 minutes
2023-06-04 09:51:53,797:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:53,797:INFO:Initializing create_model()
2023-06-04 09:51:53,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:53,797:INFO:Checking exceptions
2023-06-04 09:51:53,797:INFO:Importing libraries
2023-06-04 09:51:53,798:INFO:Copying training dataset
2023-06-04 09:51:53,804:INFO:Defining folds
2023-06-04 09:51:53,804:INFO:Declaring metric variables
2023-06-04 09:51:53,807:INFO:Importing untrained model
2023-06-04 09:51:53,811:INFO:SVM - Linear Kernel Imported successfully
2023-06-04 09:51:53,815:INFO:Cross validation set to False
2023-06-04 09:51:53,815:INFO:Fitting Model
2023-06-04 09:51:53,872:INFO:Initializing predict_model()
2023-06-04 09:51:53,872:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('actual_estimator',
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=44,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f75de9fd820>)
2023-06-04 09:51:53,872:INFO:Checking exceptions
2023-06-04 09:51:53,872:INFO:Preloading libraries
2023-06-04 09:51:54,129:INFO:_display_container: 2
2023-06-04 09:51:54,226:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=44, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-04 09:51:54,226:INFO:create_model() successfully completed......................................
2023-06-04 09:51:54,351:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:54,351:INFO:Creating metrics dataframe
2023-06-04 09:51:54,363:INFO:Initializing Ridge Classifier
2023-06-04 09:51:54,363:INFO:Total runtime is 0.05144994258880615 minutes
2023-06-04 09:51:54,366:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:54,366:INFO:Initializing create_model()
2023-06-04 09:51:54,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:54,367:INFO:Checking exceptions
2023-06-04 09:51:54,367:INFO:Importing libraries
2023-06-04 09:51:54,367:INFO:Copying training dataset
2023-06-04 09:51:54,373:INFO:Defining folds
2023-06-04 09:51:54,373:INFO:Declaring metric variables
2023-06-04 09:51:54,376:INFO:Importing untrained model
2023-06-04 09:51:54,379:INFO:Ridge Classifier Imported successfully
2023-06-04 09:51:54,384:INFO:Cross validation set to False
2023-06-04 09:51:54,384:INFO:Fitting Model
2023-06-04 09:51:54,461:INFO:Initializing predict_model()
2023-06-04 09:51:54,461:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=44, solver='auto',
                                 tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f763ae0d040>)
2023-06-04 09:51:54,461:INFO:Checking exceptions
2023-06-04 09:51:54,461:INFO:Preloading libraries
2023-06-04 09:51:54,777:INFO:_display_container: 2
2023-06-04 09:51:54,876:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=44, solver='auto',
                tol=0.0001)
2023-06-04 09:51:54,876:INFO:create_model() successfully completed......................................
2023-06-04 09:51:55,002:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:55,003:INFO:Creating metrics dataframe
2023-06-04 09:51:55,015:INFO:Initializing Random Forest Classifier
2023-06-04 09:51:55,015:INFO:Total runtime is 0.06231857935587565 minutes
2023-06-04 09:51:55,022:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:55,022:INFO:Initializing create_model()
2023-06-04 09:51:55,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:55,022:INFO:Checking exceptions
2023-06-04 09:51:55,022:INFO:Importing libraries
2023-06-04 09:51:55,023:INFO:Copying training dataset
2023-06-04 09:51:55,031:INFO:Defining folds
2023-06-04 09:51:55,031:INFO:Declaring metric variables
2023-06-04 09:51:55,035:INFO:Importing untrained model
2023-06-04 09:51:55,039:INFO:Random Forest Classifier Imported successfully
2023-06-04 09:51:55,045:INFO:Cross validation set to False
2023-06-04 09:51:55,045:INFO:Fitting Model
2023-06-04 09:51:55,744:INFO:Initializing predict_model()
2023-06-04 09:51:55,744:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=44,
                                        verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f770c913820>)
2023-06-04 09:51:55,744:INFO:Checking exceptions
2023-06-04 09:51:55,744:INFO:Preloading libraries
2023-06-04 09:51:56,060:INFO:_display_container: 2
2023-06-04 09:51:56,173:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=44, verbose=0, warm_start=False)
2023-06-04 09:51:56,173:INFO:create_model() successfully completed......................................
2023-06-04 09:51:56,306:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:56,306:INFO:Creating metrics dataframe
2023-06-04 09:51:56,318:INFO:Initializing Quadratic Discriminant Analysis
2023-06-04 09:51:56,318:INFO:Total runtime is 0.08404039939244588 minutes
2023-06-04 09:51:56,322:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:56,322:INFO:Initializing create_model()
2023-06-04 09:51:56,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:56,322:INFO:Checking exceptions
2023-06-04 09:51:56,322:INFO:Importing libraries
2023-06-04 09:51:56,322:INFO:Copying training dataset
2023-06-04 09:51:56,328:INFO:Defining folds
2023-06-04 09:51:56,328:INFO:Declaring metric variables
2023-06-04 09:51:56,332:INFO:Importing untrained model
2023-06-04 09:51:56,335:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-04 09:51:56,340:INFO:Cross validation set to False
2023-06-04 09:51:56,340:INFO:Fitting Model
2023-06-04 09:51:56,427:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-04 09:51:56,647:INFO:Initializing predict_model()
2023-06-04 09:51:56,647:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f75de3f1160>)
2023-06-04 09:51:56,647:INFO:Checking exceptions
2023-06-04 09:51:56,648:INFO:Preloading libraries
2023-06-04 09:51:56,923:INFO:_display_container: 2
2023-06-04 09:51:57,022:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-04 09:51:57,022:INFO:create_model() successfully completed......................................
2023-06-04 09:51:57,151:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:57,151:INFO:Creating metrics dataframe
2023-06-04 09:51:57,163:INFO:Initializing Ada Boost Classifier
2023-06-04 09:51:57,163:INFO:Total runtime is 0.09812105496724446 minutes
2023-06-04 09:51:57,166:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:57,167:INFO:Initializing create_model()
2023-06-04 09:51:57,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:57,167:INFO:Checking exceptions
2023-06-04 09:51:57,167:INFO:Importing libraries
2023-06-04 09:51:57,167:INFO:Copying training dataset
2023-06-04 09:51:57,173:INFO:Defining folds
2023-06-04 09:51:57,173:INFO:Declaring metric variables
2023-06-04 09:51:57,176:INFO:Importing untrained model
2023-06-04 09:51:57,180:INFO:Ada Boost Classifier Imported successfully
2023-06-04 09:51:57,184:INFO:Cross validation set to False
2023-06-04 09:51:57,184:INFO:Fitting Model
2023-06-04 09:51:58,308:INFO:Initializing predict_model()
2023-06-04 09:51:58,309:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=44))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f75de3f1af0>)
2023-06-04 09:51:58,309:INFO:Checking exceptions
2023-06-04 09:51:58,309:INFO:Preloading libraries
2023-06-04 09:51:58,530:INFO:_display_container: 2
2023-06-04 09:51:58,629:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=44)
2023-06-04 09:51:58,629:INFO:create_model() successfully completed......................................
2023-06-04 09:51:58,755:INFO:SubProcess create_model() end ==================================
2023-06-04 09:51:58,755:INFO:Creating metrics dataframe
2023-06-04 09:51:58,768:INFO:Initializing Gradient Boosting Classifier
2023-06-04 09:51:58,768:INFO:Total runtime is 0.12486993074417115 minutes
2023-06-04 09:51:58,771:INFO:SubProcess create_model() called ==================================
2023-06-04 09:51:58,772:INFO:Initializing create_model()
2023-06-04 09:51:58,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:51:58,772:INFO:Checking exceptions
2023-06-04 09:51:58,772:INFO:Importing libraries
2023-06-04 09:51:58,772:INFO:Copying training dataset
2023-06-04 09:51:58,777:INFO:Defining folds
2023-06-04 09:51:58,778:INFO:Declaring metric variables
2023-06-04 09:51:58,781:INFO:Importing untrained model
2023-06-04 09:51:58,784:INFO:Gradient Boosting Classifier Imported successfully
2023-06-04 09:51:58,789:INFO:Cross validation set to False
2023-06-04 09:51:58,789:INFO:Fitting Model
2023-06-04 09:52:02,066:INFO:Initializing predict_model()
2023-06-04 09:52:02,066:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=44, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f770cc7e0d0>)
2023-06-04 09:52:02,066:INFO:Checking exceptions
2023-06-04 09:52:02,066:INFO:Preloading libraries
2023-06-04 09:52:02,271:INFO:_display_container: 2
2023-06-04 09:52:02,370:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=44, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-04 09:52:02,370:INFO:create_model() successfully completed......................................
2023-06-04 09:52:02,501:INFO:SubProcess create_model() end ==================================
2023-06-04 09:52:02,501:INFO:Creating metrics dataframe
2023-06-04 09:52:02,514:INFO:Initializing Linear Discriminant Analysis
2023-06-04 09:52:02,514:INFO:Total runtime is 0.1873050371805827 minutes
2023-06-04 09:52:02,517:INFO:SubProcess create_model() called ==================================
2023-06-04 09:52:02,518:INFO:Initializing create_model()
2023-06-04 09:52:02,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:52:02,518:INFO:Checking exceptions
2023-06-04 09:52:02,518:INFO:Importing libraries
2023-06-04 09:52:02,518:INFO:Copying training dataset
2023-06-04 09:52:02,524:INFO:Defining folds
2023-06-04 09:52:02,524:INFO:Declaring metric variables
2023-06-04 09:52:02,527:INFO:Importing untrained model
2023-06-04 09:52:02,530:INFO:Linear Discriminant Analysis Imported successfully
2023-06-04 09:52:02,535:INFO:Cross validation set to False
2023-06-04 09:52:02,535:INFO:Fitting Model
2023-06-04 09:52:02,837:INFO:Initializing predict_model()
2023-06-04 09:52:02,837:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f763cc06c10>)
2023-06-04 09:52:02,837:INFO:Checking exceptions
2023-06-04 09:52:02,837:INFO:Preloading libraries
2023-06-04 09:52:03,104:INFO:_display_container: 2
2023-06-04 09:52:03,205:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-04 09:52:03,205:INFO:create_model() successfully completed......................................
2023-06-04 09:52:03,334:INFO:SubProcess create_model() end ==================================
2023-06-04 09:52:03,334:INFO:Creating metrics dataframe
2023-06-04 09:52:03,347:INFO:Initializing Extra Trees Classifier
2023-06-04 09:52:03,347:INFO:Total runtime is 0.20118579864501954 minutes
2023-06-04 09:52:03,350:INFO:SubProcess create_model() called ==================================
2023-06-04 09:52:03,351:INFO:Initializing create_model()
2023-06-04 09:52:03,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:52:03,351:INFO:Checking exceptions
2023-06-04 09:52:03,351:INFO:Importing libraries
2023-06-04 09:52:03,351:INFO:Copying training dataset
2023-06-04 09:52:03,356:INFO:Defining folds
2023-06-04 09:52:03,357:INFO:Declaring metric variables
2023-06-04 09:52:03,360:INFO:Importing untrained model
2023-06-04 09:52:03,363:INFO:Extra Trees Classifier Imported successfully
2023-06-04 09:52:03,368:INFO:Cross validation set to False
2023-06-04 09:52:03,368:INFO:Fitting Model
2023-06-04 09:52:03,881:INFO:Initializing predict_model()
2023-06-04 09:52:03,881:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=44,
                                      verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f763ae16f70>)
2023-06-04 09:52:03,881:INFO:Checking exceptions
2023-06-04 09:52:03,881:INFO:Preloading libraries
2023-06-04 09:52:04,209:INFO:_display_container: 2
2023-06-04 09:52:04,309:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=44, verbose=0, warm_start=False)
2023-06-04 09:52:04,309:INFO:create_model() successfully completed......................................
2023-06-04 09:52:04,435:INFO:SubProcess create_model() end ==================================
2023-06-04 09:52:04,435:INFO:Creating metrics dataframe
2023-06-04 09:52:04,448:INFO:Initializing Light Gradient Boosting Machine
2023-06-04 09:52:04,448:INFO:Total runtime is 0.21954039732615155 minutes
2023-06-04 09:52:04,452:INFO:SubProcess create_model() called ==================================
2023-06-04 09:52:04,452:INFO:Initializing create_model()
2023-06-04 09:52:04,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:52:04,452:INFO:Checking exceptions
2023-06-04 09:52:04,452:INFO:Importing libraries
2023-06-04 09:52:04,452:INFO:Copying training dataset
2023-06-04 09:52:04,458:INFO:Defining folds
2023-06-04 09:52:04,458:INFO:Declaring metric variables
2023-06-04 09:52:04,462:INFO:Importing untrained model
2023-06-04 09:52:04,466:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-04 09:52:04,470:INFO:Cross validation set to False
2023-06-04 09:52:04,470:INFO:Fitting Model
2023-06-04 09:52:05,059:INFO:Initializing predict_model()
2023-06-04 09:52:05,059:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=44,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f763cc06af0>)
2023-06-04 09:52:05,059:INFO:Checking exceptions
2023-06-04 09:52:05,059:INFO:Preloading libraries
2023-06-04 09:52:05,275:INFO:_display_container: 2
2023-06-04 09:52:05,374:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=44, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-04 09:52:05,374:INFO:create_model() successfully completed......................................
2023-06-04 09:52:05,499:INFO:SubProcess create_model() end ==================================
2023-06-04 09:52:05,499:INFO:Creating metrics dataframe
2023-06-04 09:52:05,513:INFO:Initializing Dummy Classifier
2023-06-04 09:52:05,513:INFO:Total runtime is 0.23729272683461508 minutes
2023-06-04 09:52:05,517:INFO:SubProcess create_model() called ==================================
2023-06-04 09:52:05,517:INFO:Initializing create_model()
2023-06-04 09:52:05,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f75de0285b0>, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:52:05,517:INFO:Checking exceptions
2023-06-04 09:52:05,517:INFO:Importing libraries
2023-06-04 09:52:05,517:INFO:Copying training dataset
2023-06-04 09:52:05,523:INFO:Defining folds
2023-06-04 09:52:05,523:INFO:Declaring metric variables
2023-06-04 09:52:05,526:INFO:Importing untrained model
2023-06-04 09:52:05,530:INFO:Dummy Classifier Imported successfully
2023-06-04 09:52:05,535:INFO:Cross validation set to False
2023-06-04 09:52:05,535:INFO:Fitting Model
2023-06-04 09:52:05,572:INFO:Initializing predict_model()
2023-06-04 09:52:05,572:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DummyClassifier(constant=None, random_state=44,
                                 strategy='prior'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f770c913670>)
2023-06-04 09:52:05,572:INFO:Checking exceptions
2023-06-04 09:52:05,572:INFO:Preloading libraries
2023-06-04 09:52:05,769:INFO:_display_container: 2
2023-06-04 09:52:05,871:INFO:DummyClassifier(constant=None, random_state=44, strategy='prior')
2023-06-04 09:52:05,871:INFO:create_model() successfully completed......................................
2023-06-04 09:52:05,997:INFO:SubProcess create_model() end ==================================
2023-06-04 09:52:05,997:INFO:Creating metrics dataframe
2023-06-04 09:52:06,019:INFO:Initializing create_model()
2023-06-04 09:52:06,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f75ddfcc3a0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-04 09:52:06,020:INFO:Checking exceptions
2023-06-04 09:52:06,021:INFO:Importing libraries
2023-06-04 09:52:06,021:INFO:Copying training dataset
2023-06-04 09:52:06,027:INFO:Defining folds
2023-06-04 09:52:06,027:INFO:Declaring metric variables
2023-06-04 09:52:06,027:INFO:Importing untrained model
2023-06-04 09:52:06,028:INFO:Declaring custom model
2023-06-04 09:52:06,028:INFO:Logistic Regression Imported successfully
2023-06-04 09:52:06,029:INFO:Cross validation set to False
2023-06-04 09:52:06,029:INFO:Fitting Model
2023-06-04 09:52:06,289:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 09:52:06,289:INFO:create_model() successfully completed......................................
2023-06-04 09:52:06,447:INFO:_master_model_container: 0
2023-06-04 09:52:06,447:INFO:_display_container: 2
2023-06-04 09:52:06,448:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-04 09:52:06,448:INFO:compare_models() successfully completed......................................
2023-07-31 09:48:35,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 09:48:35,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 09:48:35,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 09:48:35,957:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 09:48:36,289:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-31 09:48:36,407:INFO:Initializing set_config()
2023-07-31 09:48:36,407:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa120247730>, variable=seed, value=42, kwargs={})
2023-07-31 09:48:36,408:INFO:Global variable: seed updated to 42
2023-07-31 09:48:36,408:INFO:set_config() successfully completed......................................
2023-07-31 09:48:36,674:INFO:Initializing set_config()
2023-07-31 09:48:36,674:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa120615310>, variable=seed, value=42, kwargs={})
2023-07-31 09:48:36,674:INFO:Global variable: seed updated to 42
2023-07-31 09:48:36,674:INFO:set_config() successfully completed......................................
2023-07-31 09:49:09,570:INFO:Initializing set_config()
2023-07-31 09:49:09,571:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, variable=seed, value=42, kwargs={})
2023-07-31 09:49:09,571:INFO:Global variable: seed updated to 42
2023-07-31 09:49:09,571:INFO:set_config() successfully completed......................................
2023-07-31 09:49:09,649:INFO:PyCaret ClassificationExperiment
2023-07-31 09:49:09,649:INFO:Logging name: clf-default-name
2023-07-31 09:49:09,649:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 09:49:09,649:INFO:version 3.0.2
2023-07-31 09:49:09,649:INFO:Initializing setup()
2023-07-31 09:49:09,649:INFO:self.USI: 5e1a
2023-07-31 09:49:09,649:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 09:49:09,649:INFO:Checking environment
2023-07-31 09:49:09,649:INFO:python_version: 3.9.16
2023-07-31 09:49:09,649:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 09:49:09,649:INFO:machine: x86_64
2023-07-31 09:49:09,649:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 09:49:09,650:INFO:Memory: svmem(total=67419119616, available=17451065344, percent=74.1, used=49097043968, free=2035961856, active=52471808000, inactive=10095898624, buffers=846532608, cached=15439581184, shared=190455808, slab=1875976192)
2023-07-31 09:49:09,652:INFO:Physical Core: 28
2023-07-31 09:49:09,652:INFO:Logical Core: 56
2023-07-31 09:49:09,652:INFO:Checking libraries
2023-07-31 09:49:09,652:INFO:System:
2023-07-31 09:49:09,652:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 09:49:09,652:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 09:49:09,652:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 09:49:09,652:INFO:PyCaret required dependencies:
2023-07-31 09:49:09,652:INFO:                 pip: 23.0.1
2023-07-31 09:49:09,652:INFO:          setuptools: 66.0.0
2023-07-31 09:49:09,652:INFO:             pycaret: 3.0.2
2023-07-31 09:49:09,652:INFO:             IPython: 8.13.2
2023-07-31 09:49:09,652:INFO:          ipywidgets: 8.0.6
2023-07-31 09:49:09,652:INFO:                tqdm: 4.65.0
2023-07-31 09:49:09,652:INFO:               numpy: 1.23.5
2023-07-31 09:49:09,652:INFO:              pandas: 1.5.3
2023-07-31 09:49:09,652:INFO:              jinja2: 3.1.2
2023-07-31 09:49:09,652:INFO:               scipy: 1.10.1
2023-07-31 09:49:09,652:INFO:              joblib: 1.2.0
2023-07-31 09:49:09,652:INFO:             sklearn: 1.2.2
2023-07-31 09:49:09,652:INFO:                pyod: 1.0.9
2023-07-31 09:49:09,652:INFO:            imblearn: 0.10.1
2023-07-31 09:49:09,652:INFO:   category_encoders: 2.6.1
2023-07-31 09:49:09,652:INFO:            lightgbm: 3.3.5
2023-07-31 09:49:09,652:INFO:               numba: 0.57.0
2023-07-31 09:49:09,652:INFO:            requests: 2.28.1
2023-07-31 09:49:09,653:INFO:          matplotlib: 3.7.1
2023-07-31 09:49:09,653:INFO:          scikitplot: 0.3.7
2023-07-31 09:49:09,653:INFO:         yellowbrick: 1.5
2023-07-31 09:49:09,653:INFO:              plotly: 5.14.1
2023-07-31 09:49:09,653:INFO:             kaleido: 0.2.1
2023-07-31 09:49:09,653:INFO:         statsmodels: 0.14.0
2023-07-31 09:49:09,653:INFO:              sktime: 0.17.0
2023-07-31 09:49:09,653:INFO:               tbats: 1.1.3
2023-07-31 09:49:09,653:INFO:            pmdarima: 2.0.3
2023-07-31 09:49:09,653:INFO:              psutil: 5.9.5
2023-07-31 09:49:09,653:INFO:PyCaret optional dependencies:
2023-07-31 09:49:09,671:INFO:                shap: Not installed
2023-07-31 09:49:09,671:INFO:           interpret: Not installed
2023-07-31 09:49:09,671:INFO:                umap: Not installed
2023-07-31 09:49:09,671:INFO:    pandas_profiling: Not installed
2023-07-31 09:49:09,671:INFO:  explainerdashboard: Not installed
2023-07-31 09:49:09,671:INFO:             autoviz: Not installed
2023-07-31 09:49:09,671:INFO:           fairlearn: Not installed
2023-07-31 09:49:09,671:INFO:             xgboost: Not installed
2023-07-31 09:49:09,671:INFO:            catboost: Not installed
2023-07-31 09:49:09,671:INFO:              kmodes: Not installed
2023-07-31 09:49:09,671:INFO:             mlxtend: Not installed
2023-07-31 09:49:09,671:INFO:       statsforecast: Not installed
2023-07-31 09:49:09,671:INFO:        tune_sklearn: Not installed
2023-07-31 09:49:09,672:INFO:                 ray: Not installed
2023-07-31 09:49:09,672:INFO:            hyperopt: Not installed
2023-07-31 09:49:09,672:INFO:              optuna: Not installed
2023-07-31 09:49:09,672:INFO:               skopt: Not installed
2023-07-31 09:49:09,672:INFO:              mlflow: Not installed
2023-07-31 09:49:09,672:INFO:              gradio: Not installed
2023-07-31 09:49:09,672:INFO:             fastapi: Not installed
2023-07-31 09:49:09,672:INFO:             uvicorn: Not installed
2023-07-31 09:49:09,672:INFO:              m2cgen: Not installed
2023-07-31 09:49:09,672:INFO:           evidently: Not installed
2023-07-31 09:49:09,672:INFO:               fugue: Not installed
2023-07-31 09:49:09,672:INFO:           streamlit: Not installed
2023-07-31 09:49:09,672:INFO:             prophet: Not installed
2023-07-31 09:49:09,672:INFO:None
2023-07-31 09:49:09,672:INFO:Set up data.
2023-07-31 09:49:13,395:INFO:Set up train/test split.
2023-07-31 09:49:13,576:INFO:Set up index.
2023-07-31 09:49:13,577:INFO:Set up folding strategy.
2023-07-31 09:49:13,577:INFO:Assigning column types.
2023-07-31 09:49:13,663:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 09:49:13,707:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 09:49:13,709:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:49:13,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:13,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:13,808:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 09:49:13,809:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:49:13,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:13,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:13,837:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 09:49:13,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:49:13,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:13,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:13,956:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:49:13,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:13,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:13,983:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 09:49:14,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:14,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:14,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:14,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:14,129:INFO:Preparing preprocessing pipeline...
2023-07-31 09:49:14,148:INFO:Set up simple imputation.
2023-07-31 09:49:14,161:INFO:Set up column name cleaning.
2023-07-31 09:49:14,895:INFO:Finished creating preprocessing pipeline.
2023-07-31 09:49:14,961:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 09:49:14,961:INFO:Creating final display dataframe.
2023-07-31 09:49:17,825:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (421, 11886)
4        Transformed data shape      (421, 11886)
5   Transformed train set shape      (294, 11886)
6    Transformed test set shape      (127, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5e1a
2023-07-31 09:49:17,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:17,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:18,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:18,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:49:18,021:INFO:setup() successfully completed in 8.45s...............
2023-07-31 09:49:18,031:INFO:Initializing compare_models()
2023-07-31 09:49:18,031:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 09:49:18,032:INFO:Checking exceptions
2023-07-31 09:49:18,089:INFO:Preparing display monitor
2023-07-31 09:49:18,117:INFO:Initializing Logistic Regression
2023-07-31 09:49:18,117:INFO:Total runtime is 3.524621327718099e-06 minutes
2023-07-31 09:49:18,120:INFO:SubProcess create_model() called ==================================
2023-07-31 09:49:18,121:INFO:Initializing create_model()
2023-07-31 09:49:18,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:49:18,121:INFO:Checking exceptions
2023-07-31 09:49:18,121:INFO:Importing libraries
2023-07-31 09:49:18,121:INFO:Copying training dataset
2023-07-31 09:49:18,193:INFO:Defining folds
2023-07-31 09:49:18,193:INFO:Declaring metric variables
2023-07-31 09:49:18,197:INFO:Importing untrained model
2023-07-31 09:49:18,201:INFO:Logistic Regression Imported successfully
2023-07-31 09:49:18,208:INFO:Starting cross validation
2023-07-31 09:49:18,249:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:49:26,334:INFO:Calculating mean and std
2023-07-31 09:49:26,339:INFO:Creating metrics dataframe
2023-07-31 09:49:26,644:INFO:Uploading results into container
2023-07-31 09:49:26,646:INFO:Uploading model into container now
2023-07-31 09:49:26,646:INFO:_master_model_container: 1
2023-07-31 09:49:26,646:INFO:_display_container: 2
2023-07-31 09:49:26,647:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 09:49:26,647:INFO:create_model() successfully completed......................................
2023-07-31 09:49:26,881:INFO:SubProcess create_model() end ==================================
2023-07-31 09:49:26,881:INFO:Creating metrics dataframe
2023-07-31 09:49:26,895:INFO:Initializing K Neighbors Classifier
2023-07-31 09:49:26,895:INFO:Total runtime is 0.14630857706069947 minutes
2023-07-31 09:49:26,899:INFO:SubProcess create_model() called ==================================
2023-07-31 09:49:26,900:INFO:Initializing create_model()
2023-07-31 09:49:26,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:49:26,900:INFO:Checking exceptions
2023-07-31 09:49:26,900:INFO:Importing libraries
2023-07-31 09:49:26,900:INFO:Copying training dataset
2023-07-31 09:49:26,970:INFO:Defining folds
2023-07-31 09:49:26,971:INFO:Declaring metric variables
2023-07-31 09:49:26,975:INFO:Importing untrained model
2023-07-31 09:49:26,979:INFO:K Neighbors Classifier Imported successfully
2023-07-31 09:49:26,986:INFO:Starting cross validation
2023-07-31 09:49:27,028:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:49:30,163:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:31,279:INFO:Calculating mean and std
2023-07-31 09:49:31,282:INFO:Creating metrics dataframe
2023-07-31 09:49:31,373:INFO:Uploading results into container
2023-07-31 09:49:31,374:INFO:Uploading model into container now
2023-07-31 09:49:31,375:INFO:_master_model_container: 2
2023-07-31 09:49:31,375:INFO:_display_container: 2
2023-07-31 09:49:31,375:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 09:49:31,376:INFO:create_model() successfully completed......................................
2023-07-31 09:49:31,527:INFO:SubProcess create_model() end ==================================
2023-07-31 09:49:31,527:INFO:Creating metrics dataframe
2023-07-31 09:49:31,539:INFO:Initializing Naive Bayes
2023-07-31 09:49:31,539:INFO:Total runtime is 0.22370941638946534 minutes
2023-07-31 09:49:31,543:INFO:SubProcess create_model() called ==================================
2023-07-31 09:49:31,543:INFO:Initializing create_model()
2023-07-31 09:49:31,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:49:31,544:INFO:Checking exceptions
2023-07-31 09:49:31,544:INFO:Importing libraries
2023-07-31 09:49:31,544:INFO:Copying training dataset
2023-07-31 09:49:31,611:INFO:Defining folds
2023-07-31 09:49:31,612:INFO:Declaring metric variables
2023-07-31 09:49:31,616:INFO:Importing untrained model
2023-07-31 09:49:31,620:INFO:Naive Bayes Imported successfully
2023-07-31 09:49:31,627:INFO:Starting cross validation
2023-07-31 09:49:31,669:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:49:35,855:INFO:Calculating mean and std
2023-07-31 09:49:35,861:INFO:Creating metrics dataframe
2023-07-31 09:49:36,184:INFO:Uploading results into container
2023-07-31 09:49:36,185:INFO:Uploading model into container now
2023-07-31 09:49:36,186:INFO:_master_model_container: 3
2023-07-31 09:49:36,186:INFO:_display_container: 2
2023-07-31 09:49:36,186:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 09:49:36,186:INFO:create_model() successfully completed......................................
2023-07-31 09:49:36,332:INFO:SubProcess create_model() end ==================================
2023-07-31 09:49:36,332:INFO:Creating metrics dataframe
2023-07-31 09:49:36,344:INFO:Initializing Decision Tree Classifier
2023-07-31 09:49:36,345:INFO:Total runtime is 0.3038006663322449 minutes
2023-07-31 09:49:36,348:INFO:SubProcess create_model() called ==================================
2023-07-31 09:49:36,349:INFO:Initializing create_model()
2023-07-31 09:49:36,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:49:36,349:INFO:Checking exceptions
2023-07-31 09:49:36,349:INFO:Importing libraries
2023-07-31 09:49:36,349:INFO:Copying training dataset
2023-07-31 09:49:36,413:INFO:Defining folds
2023-07-31 09:49:36,413:INFO:Declaring metric variables
2023-07-31 09:49:36,417:INFO:Importing untrained model
2023-07-31 09:49:36,421:INFO:Decision Tree Classifier Imported successfully
2023-07-31 09:49:36,429:INFO:Starting cross validation
2023-07-31 09:49:36,470:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:49:40,560:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:41,215:INFO:Calculating mean and std
2023-07-31 09:49:41,221:INFO:Creating metrics dataframe
2023-07-31 09:49:41,503:INFO:Uploading results into container
2023-07-31 09:49:41,504:INFO:Uploading model into container now
2023-07-31 09:49:41,504:INFO:_master_model_container: 4
2023-07-31 09:49:41,505:INFO:_display_container: 2
2023-07-31 09:49:41,505:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 09:49:41,506:INFO:create_model() successfully completed......................................
2023-07-31 09:49:41,658:INFO:SubProcess create_model() end ==================================
2023-07-31 09:49:41,659:INFO:Creating metrics dataframe
2023-07-31 09:49:41,672:INFO:Initializing SVM - Linear Kernel
2023-07-31 09:49:41,672:INFO:Total runtime is 0.3925907095273336 minutes
2023-07-31 09:49:41,676:INFO:SubProcess create_model() called ==================================
2023-07-31 09:49:41,676:INFO:Initializing create_model()
2023-07-31 09:49:41,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:49:41,677:INFO:Checking exceptions
2023-07-31 09:49:41,677:INFO:Importing libraries
2023-07-31 09:49:41,677:INFO:Copying training dataset
2023-07-31 09:49:41,742:INFO:Defining folds
2023-07-31 09:49:41,742:INFO:Declaring metric variables
2023-07-31 09:49:41,747:INFO:Importing untrained model
2023-07-31 09:49:41,751:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 09:49:41,758:INFO:Starting cross validation
2023-07-31 09:49:41,800:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:49:45,166:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:49:45,171:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:49:45,233:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:49:45,252:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:49:45,283:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:49:45,303:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:45,344:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:49:45,378:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:49:45,388:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:49:45,882:INFO:Calculating mean and std
2023-07-31 09:49:45,885:INFO:Creating metrics dataframe
2023-07-31 09:49:46,012:INFO:Uploading results into container
2023-07-31 09:49:46,014:INFO:Uploading model into container now
2023-07-31 09:49:46,014:INFO:_master_model_container: 5
2023-07-31 09:49:46,014:INFO:_display_container: 2
2023-07-31 09:49:46,015:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 09:49:46,015:INFO:create_model() successfully completed......................................
2023-07-31 09:49:46,143:INFO:SubProcess create_model() end ==================================
2023-07-31 09:49:46,143:INFO:Creating metrics dataframe
2023-07-31 09:49:46,156:INFO:Initializing Ridge Classifier
2023-07-31 09:49:46,156:INFO:Total runtime is 0.46732370853424077 minutes
2023-07-31 09:49:46,160:INFO:SubProcess create_model() called ==================================
2023-07-31 09:49:46,160:INFO:Initializing create_model()
2023-07-31 09:49:46,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:49:46,160:INFO:Checking exceptions
2023-07-31 09:49:46,160:INFO:Importing libraries
2023-07-31 09:49:46,160:INFO:Copying training dataset
2023-07-31 09:49:46,223:INFO:Defining folds
2023-07-31 09:49:46,224:INFO:Declaring metric variables
2023-07-31 09:49:46,228:INFO:Importing untrained model
2023-07-31 09:49:46,232:INFO:Ridge Classifier Imported successfully
2023-07-31 09:49:46,240:INFO:Starting cross validation
2023-07-31 09:49:46,281:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:49:49,477:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:49:49,490:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:49:49,500:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:49:49,531:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:49:49,549:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:49:49,556:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:49:49,581:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:49:49,600:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:49:50,105:INFO:Calculating mean and std
2023-07-31 09:49:50,109:INFO:Creating metrics dataframe
2023-07-31 09:49:50,418:INFO:Uploading results into container
2023-07-31 09:49:50,419:INFO:Uploading model into container now
2023-07-31 09:49:50,419:INFO:_master_model_container: 6
2023-07-31 09:49:50,419:INFO:_display_container: 2
2023-07-31 09:49:50,420:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 09:49:50,420:INFO:create_model() successfully completed......................................
2023-07-31 09:49:50,547:INFO:SubProcess create_model() end ==================================
2023-07-31 09:49:50,547:INFO:Creating metrics dataframe
2023-07-31 09:49:50,560:INFO:Initializing Random Forest Classifier
2023-07-31 09:49:50,560:INFO:Total runtime is 0.540726121266683 minutes
2023-07-31 09:49:50,564:INFO:SubProcess create_model() called ==================================
2023-07-31 09:49:50,564:INFO:Initializing create_model()
2023-07-31 09:49:50,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:49:50,564:INFO:Checking exceptions
2023-07-31 09:49:50,564:INFO:Importing libraries
2023-07-31 09:49:50,564:INFO:Copying training dataset
2023-07-31 09:49:50,626:INFO:Defining folds
2023-07-31 09:49:50,627:INFO:Declaring metric variables
2023-07-31 09:49:50,631:INFO:Importing untrained model
2023-07-31 09:49:50,636:INFO:Random Forest Classifier Imported successfully
2023-07-31 09:49:50,644:INFO:Starting cross validation
2023-07-31 09:49:50,685:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:49:54,492:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:54,553:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:54,602:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:54,624:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:54,641:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:54,654:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:54,655:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:54,721:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:56,021:INFO:Calculating mean and std
2023-07-31 09:49:56,022:INFO:Creating metrics dataframe
2023-07-31 09:49:56,118:INFO:Uploading results into container
2023-07-31 09:49:56,119:INFO:Uploading model into container now
2023-07-31 09:49:56,119:INFO:_master_model_container: 7
2023-07-31 09:49:56,119:INFO:_display_container: 2
2023-07-31 09:49:56,119:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 09:49:56,120:INFO:create_model() successfully completed......................................
2023-07-31 09:49:56,229:INFO:SubProcess create_model() end ==================================
2023-07-31 09:49:56,230:INFO:Creating metrics dataframe
2023-07-31 09:49:56,242:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 09:49:56,243:INFO:Total runtime is 0.6354336857795715 minutes
2023-07-31 09:49:56,246:INFO:SubProcess create_model() called ==================================
2023-07-31 09:49:56,247:INFO:Initializing create_model()
2023-07-31 09:49:56,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:49:56,247:INFO:Checking exceptions
2023-07-31 09:49:56,247:INFO:Importing libraries
2023-07-31 09:49:56,247:INFO:Copying training dataset
2023-07-31 09:49:56,312:INFO:Defining folds
2023-07-31 09:49:56,312:INFO:Declaring metric variables
2023-07-31 09:49:56,317:INFO:Importing untrained model
2023-07-31 09:49:56,321:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 09:49:56,328:INFO:Starting cross validation
2023-07-31 09:49:56,370:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:49:57,173:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:49:57,180:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:49:57,332:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:49:57,343:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:49:57,508:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:49:57,515:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:49:57,526:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:49:57,992:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:49:59,491:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:59,562:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:49:59,984:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:00,836:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:00,872:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:01,169:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:01,251:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:01,993:INFO:Calculating mean and std
2023-07-31 09:50:01,996:INFO:Creating metrics dataframe
2023-07-31 09:50:02,119:INFO:Uploading results into container
2023-07-31 09:50:02,121:INFO:Uploading model into container now
2023-07-31 09:50:02,121:INFO:_master_model_container: 8
2023-07-31 09:50:02,121:INFO:_display_container: 2
2023-07-31 09:50:02,122:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 09:50:02,122:INFO:create_model() successfully completed......................................
2023-07-31 09:50:02,301:INFO:SubProcess create_model() end ==================================
2023-07-31 09:50:02,301:INFO:Creating metrics dataframe
2023-07-31 09:50:02,317:INFO:Initializing Ada Boost Classifier
2023-07-31 09:50:02,317:INFO:Total runtime is 0.7366789897282918 minutes
2023-07-31 09:50:02,322:INFO:SubProcess create_model() called ==================================
2023-07-31 09:50:02,323:INFO:Initializing create_model()
2023-07-31 09:50:02,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:50:02,323:INFO:Checking exceptions
2023-07-31 09:50:02,323:INFO:Importing libraries
2023-07-31 09:50:02,323:INFO:Copying training dataset
2023-07-31 09:50:02,406:INFO:Defining folds
2023-07-31 09:50:02,406:INFO:Declaring metric variables
2023-07-31 09:50:02,411:INFO:Importing untrained model
2023-07-31 09:50:02,416:INFO:Ada Boost Classifier Imported successfully
2023-07-31 09:50:02,426:INFO:Starting cross validation
2023-07-31 09:50:02,469:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:50:19,691:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:19,924:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:20,133:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:20,167:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:20,929:INFO:Calculating mean and std
2023-07-31 09:50:20,932:INFO:Creating metrics dataframe
2023-07-31 09:50:21,278:INFO:Uploading results into container
2023-07-31 09:50:21,279:INFO:Uploading model into container now
2023-07-31 09:50:21,280:INFO:_master_model_container: 9
2023-07-31 09:50:21,280:INFO:_display_container: 2
2023-07-31 09:50:21,281:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 09:50:21,281:INFO:create_model() successfully completed......................................
2023-07-31 09:50:21,413:INFO:SubProcess create_model() end ==================================
2023-07-31 09:50:21,414:INFO:Creating metrics dataframe
2023-07-31 09:50:21,428:INFO:Initializing Gradient Boosting Classifier
2023-07-31 09:50:21,428:INFO:Total runtime is 1.0551856557528179 minutes
2023-07-31 09:50:21,432:INFO:SubProcess create_model() called ==================================
2023-07-31 09:50:21,432:INFO:Initializing create_model()
2023-07-31 09:50:21,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:50:21,432:INFO:Checking exceptions
2023-07-31 09:50:21,432:INFO:Importing libraries
2023-07-31 09:50:21,432:INFO:Copying training dataset
2023-07-31 09:50:21,496:INFO:Defining folds
2023-07-31 09:50:21,496:INFO:Declaring metric variables
2023-07-31 09:50:21,501:INFO:Importing untrained model
2023-07-31 09:50:21,505:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 09:50:21,512:INFO:Starting cross validation
2023-07-31 09:50:21,555:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:50:53,202:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:50:55,098:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:16,315:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:16,884:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:17,290:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:17,566:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:18,102:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:18,504:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:19,011:INFO:Calculating mean and std
2023-07-31 09:51:19,015:INFO:Creating metrics dataframe
2023-07-31 09:51:19,390:INFO:Uploading results into container
2023-07-31 09:51:19,391:INFO:Uploading model into container now
2023-07-31 09:51:19,392:INFO:_master_model_container: 10
2023-07-31 09:51:19,392:INFO:_display_container: 2
2023-07-31 09:51:19,393:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 09:51:19,393:INFO:create_model() successfully completed......................................
2023-07-31 09:51:19,560:INFO:SubProcess create_model() end ==================================
2023-07-31 09:51:19,560:INFO:Creating metrics dataframe
2023-07-31 09:51:19,575:INFO:Initializing Linear Discriminant Analysis
2023-07-31 09:51:19,576:INFO:Total runtime is 2.024317522843679 minutes
2023-07-31 09:51:19,580:INFO:SubProcess create_model() called ==================================
2023-07-31 09:51:19,580:INFO:Initializing create_model()
2023-07-31 09:51:19,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:51:19,580:INFO:Checking exceptions
2023-07-31 09:51:19,580:INFO:Importing libraries
2023-07-31 09:51:19,580:INFO:Copying training dataset
2023-07-31 09:51:19,652:INFO:Defining folds
2023-07-31 09:51:19,652:INFO:Declaring metric variables
2023-07-31 09:51:19,657:INFO:Importing untrained model
2023-07-31 09:51:19,661:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 09:51:19,669:INFO:Starting cross validation
2023-07-31 09:51:19,711:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:51:23,377:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:24,570:INFO:Calculating mean and std
2023-07-31 09:51:24,574:INFO:Creating metrics dataframe
2023-07-31 09:51:24,721:INFO:Uploading results into container
2023-07-31 09:51:24,723:INFO:Uploading model into container now
2023-07-31 09:51:24,723:INFO:_master_model_container: 11
2023-07-31 09:51:24,724:INFO:_display_container: 2
2023-07-31 09:51:24,724:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 09:51:24,724:INFO:create_model() successfully completed......................................
2023-07-31 09:51:25,097:INFO:SubProcess create_model() end ==================================
2023-07-31 09:51:25,098:INFO:Creating metrics dataframe
2023-07-31 09:51:25,121:INFO:Initializing Extra Trees Classifier
2023-07-31 09:51:25,122:INFO:Total runtime is 2.116751253604889 minutes
2023-07-31 09:51:25,129:INFO:SubProcess create_model() called ==================================
2023-07-31 09:51:25,130:INFO:Initializing create_model()
2023-07-31 09:51:25,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:51:25,130:INFO:Checking exceptions
2023-07-31 09:51:25,130:INFO:Importing libraries
2023-07-31 09:51:25,130:INFO:Copying training dataset
2023-07-31 09:51:25,283:INFO:Defining folds
2023-07-31 09:51:25,284:INFO:Declaring metric variables
2023-07-31 09:51:25,291:INFO:Importing untrained model
2023-07-31 09:51:25,298:INFO:Extra Trees Classifier Imported successfully
2023-07-31 09:51:25,311:INFO:Starting cross validation
2023-07-31 09:51:25,358:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:51:27,707:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:27,765:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:27,805:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:27,825:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:27,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:27,862:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:27,908:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:27,949:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:51:29,332:INFO:Calculating mean and std
2023-07-31 09:51:29,336:INFO:Creating metrics dataframe
2023-07-31 09:51:29,466:INFO:Uploading results into container
2023-07-31 09:51:29,467:INFO:Uploading model into container now
2023-07-31 09:51:29,467:INFO:_master_model_container: 12
2023-07-31 09:51:29,468:INFO:_display_container: 2
2023-07-31 09:51:29,468:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 09:51:29,468:INFO:create_model() successfully completed......................................
2023-07-31 09:51:29,615:INFO:SubProcess create_model() end ==================================
2023-07-31 09:51:29,615:INFO:Creating metrics dataframe
2023-07-31 09:51:29,630:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 09:51:29,630:INFO:Total runtime is 2.1918917059898377 minutes
2023-07-31 09:51:29,634:INFO:SubProcess create_model() called ==================================
2023-07-31 09:51:29,634:INFO:Initializing create_model()
2023-07-31 09:51:29,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:51:29,634:INFO:Checking exceptions
2023-07-31 09:51:29,635:INFO:Importing libraries
2023-07-31 09:51:29,635:INFO:Copying training dataset
2023-07-31 09:51:29,696:INFO:Defining folds
2023-07-31 09:51:29,697:INFO:Declaring metric variables
2023-07-31 09:51:29,701:INFO:Importing untrained model
2023-07-31 09:51:29,705:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 09:51:29,713:INFO:Starting cross validation
2023-07-31 09:51:29,754:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:52:21,550:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:52:24,209:INFO:Calculating mean and std
2023-07-31 09:52:24,215:INFO:Creating metrics dataframe
2023-07-31 09:52:24,620:INFO:Uploading results into container
2023-07-31 09:52:24,622:INFO:Uploading model into container now
2023-07-31 09:52:24,622:INFO:_master_model_container: 13
2023-07-31 09:52:24,623:INFO:_display_container: 2
2023-07-31 09:52:24,624:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 09:52:24,624:INFO:create_model() successfully completed......................................
2023-07-31 09:52:24,879:INFO:SubProcess create_model() end ==================================
2023-07-31 09:52:24,879:INFO:Creating metrics dataframe
2023-07-31 09:52:24,897:INFO:Initializing Dummy Classifier
2023-07-31 09:52:24,897:INFO:Total runtime is 3.1130130608876545 minutes
2023-07-31 09:52:24,902:INFO:SubProcess create_model() called ==================================
2023-07-31 09:52:24,903:INFO:Initializing create_model()
2023-07-31 09:52:24,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd152aa60>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:52:24,903:INFO:Checking exceptions
2023-07-31 09:52:24,903:INFO:Importing libraries
2023-07-31 09:52:24,903:INFO:Copying training dataset
2023-07-31 09:52:24,998:INFO:Defining folds
2023-07-31 09:52:24,998:INFO:Declaring metric variables
2023-07-31 09:52:25,004:INFO:Importing untrained model
2023-07-31 09:52:25,009:INFO:Dummy Classifier Imported successfully
2023-07-31 09:52:25,017:INFO:Starting cross validation
2023-07-31 09:52:25,061:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:52:28,025:INFO:Calculating mean and std
2023-07-31 09:52:28,028:INFO:Creating metrics dataframe
2023-07-31 09:52:28,172:INFO:Uploading results into container
2023-07-31 09:52:28,173:INFO:Uploading model into container now
2023-07-31 09:52:28,174:INFO:_master_model_container: 14
2023-07-31 09:52:28,174:INFO:_display_container: 2
2023-07-31 09:52:28,174:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 09:52:28,175:INFO:create_model() successfully completed......................................
2023-07-31 09:52:28,331:INFO:SubProcess create_model() end ==================================
2023-07-31 09:52:28,331:INFO:Creating metrics dataframe
2023-07-31 09:52:28,359:INFO:Initializing create_model()
2023-07-31 09:52:28,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd306d940>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:52:28,360:INFO:Checking exceptions
2023-07-31 09:52:28,369:INFO:Importing libraries
2023-07-31 09:52:28,369:INFO:Copying training dataset
2023-07-31 09:52:28,448:INFO:Defining folds
2023-07-31 09:52:28,448:INFO:Declaring metric variables
2023-07-31 09:52:28,449:INFO:Importing untrained model
2023-07-31 09:52:28,449:INFO:Declaring custom model
2023-07-31 09:52:28,449:INFO:Ada Boost Classifier Imported successfully
2023-07-31 09:52:28,492:INFO:Cross validation set to False
2023-07-31 09:52:28,492:INFO:Fitting Model
2023-07-31 09:52:47,838:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 09:52:47,838:INFO:create_model() successfully completed......................................
2023-07-31 09:52:48,066:INFO:_master_model_container: 14
2023-07-31 09:52:48,066:INFO:_display_container: 2
2023-07-31 09:52:48,066:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 09:52:48,067:INFO:compare_models() successfully completed......................................
2023-07-31 09:52:51,207:INFO:Initializing set_config()
2023-07-31 09:52:51,207:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6b20>, variable=seed, value=42, kwargs={})
2023-07-31 09:52:51,208:INFO:Global variable: seed updated to 42
2023-07-31 09:52:51,208:INFO:set_config() successfully completed......................................
2023-07-31 09:56:24,623:INFO:Initializing set_config()
2023-07-31 09:56:24,624:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, variable=seed, value=42, kwargs={})
2023-07-31 09:56:24,624:INFO:Global variable: seed updated to 42
2023-07-31 09:56:24,624:INFO:set_config() successfully completed......................................
2023-07-31 09:56:24,743:INFO:PyCaret ClassificationExperiment
2023-07-31 09:56:24,744:INFO:Logging name: clf-default-name
2023-07-31 09:56:24,744:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 09:56:24,744:INFO:version 3.0.2
2023-07-31 09:56:24,744:INFO:Initializing setup()
2023-07-31 09:56:24,744:INFO:self.USI: 11d7
2023-07-31 09:56:24,744:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 09:56:24,744:INFO:Checking environment
2023-07-31 09:56:24,744:INFO:python_version: 3.9.16
2023-07-31 09:56:24,744:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 09:56:24,744:INFO:machine: x86_64
2023-07-31 09:56:24,744:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 09:56:24,744:INFO:Memory: svmem(total=67419119616, available=15273172992, percent=77.3, used=51264610304, free=12547051520, active=46098395136, inactive=6459158528, buffers=44949504, cached=3562508288, shared=188067840, slab=1321943040)
2023-07-31 09:56:24,746:INFO:Physical Core: 28
2023-07-31 09:56:24,746:INFO:Logical Core: 56
2023-07-31 09:56:24,746:INFO:Checking libraries
2023-07-31 09:56:24,746:INFO:System:
2023-07-31 09:56:24,746:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 09:56:24,746:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 09:56:24,746:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 09:56:24,746:INFO:PyCaret required dependencies:
2023-07-31 09:56:24,746:INFO:                 pip: 23.0.1
2023-07-31 09:56:24,746:INFO:          setuptools: 66.0.0
2023-07-31 09:56:24,746:INFO:             pycaret: 3.0.2
2023-07-31 09:56:24,746:INFO:             IPython: 8.13.2
2023-07-31 09:56:24,746:INFO:          ipywidgets: 8.0.6
2023-07-31 09:56:24,746:INFO:                tqdm: 4.65.0
2023-07-31 09:56:24,746:INFO:               numpy: 1.23.5
2023-07-31 09:56:24,746:INFO:              pandas: 1.5.3
2023-07-31 09:56:24,746:INFO:              jinja2: 3.1.2
2023-07-31 09:56:24,747:INFO:               scipy: 1.10.1
2023-07-31 09:56:24,747:INFO:              joblib: 1.2.0
2023-07-31 09:56:24,747:INFO:             sklearn: 1.2.2
2023-07-31 09:56:24,747:INFO:                pyod: 1.0.9
2023-07-31 09:56:24,747:INFO:            imblearn: 0.10.1
2023-07-31 09:56:24,747:INFO:   category_encoders: 2.6.1
2023-07-31 09:56:24,747:INFO:            lightgbm: 3.3.5
2023-07-31 09:56:24,747:INFO:               numba: 0.57.0
2023-07-31 09:56:24,747:INFO:            requests: 2.28.1
2023-07-31 09:56:24,747:INFO:          matplotlib: 3.7.1
2023-07-31 09:56:24,747:INFO:          scikitplot: 0.3.7
2023-07-31 09:56:24,747:INFO:         yellowbrick: 1.5
2023-07-31 09:56:24,747:INFO:              plotly: 5.14.1
2023-07-31 09:56:24,747:INFO:             kaleido: 0.2.1
2023-07-31 09:56:24,747:INFO:         statsmodels: 0.14.0
2023-07-31 09:56:24,747:INFO:              sktime: 0.17.0
2023-07-31 09:56:24,747:INFO:               tbats: 1.1.3
2023-07-31 09:56:24,747:INFO:            pmdarima: 2.0.3
2023-07-31 09:56:24,747:INFO:              psutil: 5.9.5
2023-07-31 09:56:24,747:INFO:PyCaret optional dependencies:
2023-07-31 09:56:24,747:INFO:                shap: Not installed
2023-07-31 09:56:24,747:INFO:           interpret: Not installed
2023-07-31 09:56:24,747:INFO:                umap: Not installed
2023-07-31 09:56:24,747:INFO:    pandas_profiling: Not installed
2023-07-31 09:56:24,747:INFO:  explainerdashboard: Not installed
2023-07-31 09:56:24,747:INFO:             autoviz: Not installed
2023-07-31 09:56:24,747:INFO:           fairlearn: Not installed
2023-07-31 09:56:24,747:INFO:             xgboost: Not installed
2023-07-31 09:56:24,747:INFO:            catboost: Not installed
2023-07-31 09:56:24,747:INFO:              kmodes: Not installed
2023-07-31 09:56:24,747:INFO:             mlxtend: Not installed
2023-07-31 09:56:24,748:INFO:       statsforecast: Not installed
2023-07-31 09:56:24,748:INFO:        tune_sklearn: Not installed
2023-07-31 09:56:24,748:INFO:                 ray: Not installed
2023-07-31 09:56:24,748:INFO:            hyperopt: Not installed
2023-07-31 09:56:24,748:INFO:              optuna: Not installed
2023-07-31 09:56:24,748:INFO:               skopt: Not installed
2023-07-31 09:56:24,748:INFO:              mlflow: Not installed
2023-07-31 09:56:24,748:INFO:              gradio: Not installed
2023-07-31 09:56:24,748:INFO:             fastapi: Not installed
2023-07-31 09:56:24,748:INFO:             uvicorn: Not installed
2023-07-31 09:56:24,748:INFO:              m2cgen: Not installed
2023-07-31 09:56:24,748:INFO:           evidently: Not installed
2023-07-31 09:56:24,748:INFO:               fugue: Not installed
2023-07-31 09:56:24,748:INFO:           streamlit: Not installed
2023-07-31 09:56:24,748:INFO:             prophet: Not installed
2023-07-31 09:56:24,748:INFO:None
2023-07-31 09:56:24,748:INFO:Set up data.
2023-07-31 09:56:28,469:INFO:Set up train/test split.
2023-07-31 09:56:28,625:INFO:Set up index.
2023-07-31 09:56:28,625:INFO:Set up folding strategy.
2023-07-31 09:56:28,625:INFO:Assigning column types.
2023-07-31 09:56:28,687:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 09:56:28,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 09:56:28,733:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:56:28,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:28,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:28,806:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 09:56:28,806:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:56:28,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:28,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:28,835:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 09:56:28,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:56:28,909:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:28,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:28,954:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:56:28,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:28,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:28,983:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 09:56:29,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:29,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:29,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:29,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:29,132:INFO:Preparing preprocessing pipeline...
2023-07-31 09:56:29,144:INFO:Set up simple imputation.
2023-07-31 09:56:29,155:INFO:Set up column name cleaning.
2023-07-31 09:56:29,538:INFO:Finished creating preprocessing pipeline.
2023-07-31 09:56:29,604:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 09:56:29,604:INFO:Creating final display dataframe.
2023-07-31 09:56:31,005:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (421, 11886)
4        Transformed data shape      (421, 11886)
5   Transformed train set shape      (294, 11886)
6    Transformed test set shape      (127, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              11d7
2023-07-31 09:56:31,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:31,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:31,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:31,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:56:31,160:INFO:setup() successfully completed in 6.54s...............
2023-07-31 09:56:31,166:INFO:Initializing compare_models()
2023-07-31 09:56:31,166:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 09:56:31,167:INFO:Checking exceptions
2023-07-31 09:56:31,213:INFO:Preparing display monitor
2023-07-31 09:56:31,236:INFO:Initializing Logistic Regression
2023-07-31 09:56:31,236:INFO:Total runtime is 1.8358230590820313e-06 minutes
2023-07-31 09:56:31,240:INFO:SubProcess create_model() called ==================================
2023-07-31 09:56:31,240:INFO:Initializing create_model()
2023-07-31 09:56:31,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:56:31,240:INFO:Checking exceptions
2023-07-31 09:56:31,240:INFO:Importing libraries
2023-07-31 09:56:31,240:INFO:Copying training dataset
2023-07-31 09:56:31,306:INFO:Defining folds
2023-07-31 09:56:31,306:INFO:Declaring metric variables
2023-07-31 09:56:31,310:INFO:Importing untrained model
2023-07-31 09:56:31,314:INFO:Logistic Regression Imported successfully
2023-07-31 09:56:31,320:INFO:Starting cross validation
2023-07-31 09:56:31,362:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:56:34,956:INFO:Calculating mean and std
2023-07-31 09:56:34,960:INFO:Creating metrics dataframe
2023-07-31 09:56:35,137:INFO:Uploading results into container
2023-07-31 09:56:35,138:INFO:Uploading model into container now
2023-07-31 09:56:35,139:INFO:_master_model_container: 1
2023-07-31 09:56:35,139:INFO:_display_container: 2
2023-07-31 09:56:35,139:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 09:56:35,139:INFO:create_model() successfully completed......................................
2023-07-31 09:56:35,286:INFO:SubProcess create_model() end ==================================
2023-07-31 09:56:35,286:INFO:Creating metrics dataframe
2023-07-31 09:56:35,297:INFO:Initializing K Neighbors Classifier
2023-07-31 09:56:35,297:INFO:Total runtime is 0.06768740812937418 minutes
2023-07-31 09:56:35,301:INFO:SubProcess create_model() called ==================================
2023-07-31 09:56:35,301:INFO:Initializing create_model()
2023-07-31 09:56:35,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:56:35,302:INFO:Checking exceptions
2023-07-31 09:56:35,302:INFO:Importing libraries
2023-07-31 09:56:35,302:INFO:Copying training dataset
2023-07-31 09:56:35,365:INFO:Defining folds
2023-07-31 09:56:35,365:INFO:Declaring metric variables
2023-07-31 09:56:35,369:INFO:Importing untrained model
2023-07-31 09:56:35,373:INFO:K Neighbors Classifier Imported successfully
2023-07-31 09:56:35,379:INFO:Starting cross validation
2023-07-31 09:56:35,422:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:56:37,886:INFO:Calculating mean and std
2023-07-31 09:56:37,888:INFO:Creating metrics dataframe
2023-07-31 09:56:38,334:INFO:Uploading results into container
2023-07-31 09:56:38,335:INFO:Uploading model into container now
2023-07-31 09:56:38,336:INFO:_master_model_container: 2
2023-07-31 09:56:38,336:INFO:_display_container: 2
2023-07-31 09:56:38,337:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 09:56:38,337:INFO:create_model() successfully completed......................................
2023-07-31 09:56:38,442:INFO:SubProcess create_model() end ==================================
2023-07-31 09:56:38,442:INFO:Creating metrics dataframe
2023-07-31 09:56:38,453:INFO:Initializing Naive Bayes
2023-07-31 09:56:38,453:INFO:Total runtime is 0.12027982076009114 minutes
2023-07-31 09:56:38,456:INFO:SubProcess create_model() called ==================================
2023-07-31 09:56:38,457:INFO:Initializing create_model()
2023-07-31 09:56:38,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:56:38,457:INFO:Checking exceptions
2023-07-31 09:56:38,457:INFO:Importing libraries
2023-07-31 09:56:38,457:INFO:Copying training dataset
2023-07-31 09:56:38,514:INFO:Defining folds
2023-07-31 09:56:38,514:INFO:Declaring metric variables
2023-07-31 09:56:38,518:INFO:Importing untrained model
2023-07-31 09:56:38,522:INFO:Naive Bayes Imported successfully
2023-07-31 09:56:38,528:INFO:Starting cross validation
2023-07-31 09:56:38,571:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:56:42,361:INFO:Calculating mean and std
2023-07-31 09:56:42,364:INFO:Creating metrics dataframe
2023-07-31 09:56:42,543:INFO:Uploading results into container
2023-07-31 09:56:42,544:INFO:Uploading model into container now
2023-07-31 09:56:42,545:INFO:_master_model_container: 3
2023-07-31 09:56:42,545:INFO:_display_container: 2
2023-07-31 09:56:42,545:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 09:56:42,545:INFO:create_model() successfully completed......................................
2023-07-31 09:56:42,666:INFO:SubProcess create_model() end ==================================
2023-07-31 09:56:42,666:INFO:Creating metrics dataframe
2023-07-31 09:56:42,678:INFO:Initializing Decision Tree Classifier
2023-07-31 09:56:42,678:INFO:Total runtime is 0.1906995932261149 minutes
2023-07-31 09:56:42,682:INFO:SubProcess create_model() called ==================================
2023-07-31 09:56:42,682:INFO:Initializing create_model()
2023-07-31 09:56:42,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:56:42,682:INFO:Checking exceptions
2023-07-31 09:56:42,682:INFO:Importing libraries
2023-07-31 09:56:42,682:INFO:Copying training dataset
2023-07-31 09:56:42,742:INFO:Defining folds
2023-07-31 09:56:42,742:INFO:Declaring metric variables
2023-07-31 09:56:42,746:INFO:Importing untrained model
2023-07-31 09:56:42,750:INFO:Decision Tree Classifier Imported successfully
2023-07-31 09:56:42,756:INFO:Starting cross validation
2023-07-31 09:56:42,799:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:56:46,061:INFO:Calculating mean and std
2023-07-31 09:56:46,066:INFO:Creating metrics dataframe
2023-07-31 09:56:46,513:INFO:Uploading results into container
2023-07-31 09:56:46,514:INFO:Uploading model into container now
2023-07-31 09:56:46,515:INFO:_master_model_container: 4
2023-07-31 09:56:46,515:INFO:_display_container: 2
2023-07-31 09:56:46,516:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 09:56:46,516:INFO:create_model() successfully completed......................................
2023-07-31 09:56:46,678:INFO:SubProcess create_model() end ==================================
2023-07-31 09:56:46,678:INFO:Creating metrics dataframe
2023-07-31 09:56:46,691:INFO:Initializing SVM - Linear Kernel
2023-07-31 09:56:46,691:INFO:Total runtime is 0.25758345127105714 minutes
2023-07-31 09:56:46,695:INFO:SubProcess create_model() called ==================================
2023-07-31 09:56:46,695:INFO:Initializing create_model()
2023-07-31 09:56:46,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:56:46,695:INFO:Checking exceptions
2023-07-31 09:56:46,695:INFO:Importing libraries
2023-07-31 09:56:46,695:INFO:Copying training dataset
2023-07-31 09:56:46,763:INFO:Defining folds
2023-07-31 09:56:46,763:INFO:Declaring metric variables
2023-07-31 09:56:46,767:INFO:Importing untrained model
2023-07-31 09:56:46,771:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 09:56:46,778:INFO:Starting cross validation
2023-07-31 09:56:46,820:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:56:48,833:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:56:48,895:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:56:48,912:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:56:48,929:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:56:48,940:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:56:48,951:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:56:48,961:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:56:48,965:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:56:49,776:INFO:Calculating mean and std
2023-07-31 09:56:49,778:INFO:Creating metrics dataframe
2023-07-31 09:56:49,949:INFO:Uploading results into container
2023-07-31 09:56:49,950:INFO:Uploading model into container now
2023-07-31 09:56:49,951:INFO:_master_model_container: 5
2023-07-31 09:56:49,951:INFO:_display_container: 2
2023-07-31 09:56:49,951:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 09:56:49,951:INFO:create_model() successfully completed......................................
2023-07-31 09:56:50,054:INFO:SubProcess create_model() end ==================================
2023-07-31 09:56:50,055:INFO:Creating metrics dataframe
2023-07-31 09:56:50,067:INFO:Initializing Ridge Classifier
2023-07-31 09:56:50,068:INFO:Total runtime is 0.3138577659924825 minutes
2023-07-31 09:56:50,072:INFO:SubProcess create_model() called ==================================
2023-07-31 09:56:50,072:INFO:Initializing create_model()
2023-07-31 09:56:50,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:56:50,072:INFO:Checking exceptions
2023-07-31 09:56:50,072:INFO:Importing libraries
2023-07-31 09:56:50,072:INFO:Copying training dataset
2023-07-31 09:56:50,129:INFO:Defining folds
2023-07-31 09:56:50,129:INFO:Declaring metric variables
2023-07-31 09:56:50,133:INFO:Importing untrained model
2023-07-31 09:56:50,138:INFO:Ridge Classifier Imported successfully
2023-07-31 09:56:50,146:INFO:Starting cross validation
2023-07-31 09:56:50,189:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:56:52,228:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:56:52,244:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:56:52,264:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:56:52,265:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:56:52,269:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:56:52,272:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:56:52,273:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:56:52,275:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:56:53,177:INFO:Calculating mean and std
2023-07-31 09:56:53,179:INFO:Creating metrics dataframe
2023-07-31 09:56:53,380:INFO:Uploading results into container
2023-07-31 09:56:53,381:INFO:Uploading model into container now
2023-07-31 09:56:53,382:INFO:_master_model_container: 6
2023-07-31 09:56:53,382:INFO:_display_container: 2
2023-07-31 09:56:53,382:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 09:56:53,382:INFO:create_model() successfully completed......................................
2023-07-31 09:56:53,502:INFO:SubProcess create_model() end ==================================
2023-07-31 09:56:53,502:INFO:Creating metrics dataframe
2023-07-31 09:56:53,515:INFO:Initializing Random Forest Classifier
2023-07-31 09:56:53,515:INFO:Total runtime is 0.3713166117668152 minutes
2023-07-31 09:56:53,519:INFO:SubProcess create_model() called ==================================
2023-07-31 09:56:53,519:INFO:Initializing create_model()
2023-07-31 09:56:53,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:56:53,519:INFO:Checking exceptions
2023-07-31 09:56:53,519:INFO:Importing libraries
2023-07-31 09:56:53,519:INFO:Copying training dataset
2023-07-31 09:56:53,578:INFO:Defining folds
2023-07-31 09:56:53,578:INFO:Declaring metric variables
2023-07-31 09:56:53,582:INFO:Importing untrained model
2023-07-31 09:56:53,586:INFO:Random Forest Classifier Imported successfully
2023-07-31 09:56:53,593:INFO:Starting cross validation
2023-07-31 09:56:53,635:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:56:57,259:INFO:Calculating mean and std
2023-07-31 09:56:57,261:INFO:Creating metrics dataframe
2023-07-31 09:56:57,424:INFO:Uploading results into container
2023-07-31 09:56:57,425:INFO:Uploading model into container now
2023-07-31 09:56:57,425:INFO:_master_model_container: 7
2023-07-31 09:56:57,425:INFO:_display_container: 2
2023-07-31 09:56:57,426:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 09:56:57,426:INFO:create_model() successfully completed......................................
2023-07-31 09:56:57,547:INFO:SubProcess create_model() end ==================================
2023-07-31 09:56:57,547:INFO:Creating metrics dataframe
2023-07-31 09:56:57,560:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 09:56:57,560:INFO:Total runtime is 0.4387286106745402 minutes
2023-07-31 09:56:57,563:INFO:SubProcess create_model() called ==================================
2023-07-31 09:56:57,564:INFO:Initializing create_model()
2023-07-31 09:56:57,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:56:57,564:INFO:Checking exceptions
2023-07-31 09:56:57,564:INFO:Importing libraries
2023-07-31 09:56:57,564:INFO:Copying training dataset
2023-07-31 09:56:57,623:INFO:Defining folds
2023-07-31 09:56:57,624:INFO:Declaring metric variables
2023-07-31 09:56:57,628:INFO:Importing untrained model
2023-07-31 09:56:57,631:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 09:56:57,638:INFO:Starting cross validation
2023-07-31 09:56:57,680:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:00,083:INFO:Calculating mean and std
2023-07-31 09:57:00,085:INFO:Creating metrics dataframe
2023-07-31 09:57:00,251:INFO:Uploading results into container
2023-07-31 09:57:00,252:INFO:Uploading model into container now
2023-07-31 09:57:00,252:INFO:_master_model_container: 8
2023-07-31 09:57:00,252:INFO:_display_container: 2
2023-07-31 09:57:00,253:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 09:57:00,253:INFO:create_model() successfully completed......................................
2023-07-31 09:57:00,355:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:00,356:INFO:Creating metrics dataframe
2023-07-31 09:57:00,369:INFO:Initializing Ada Boost Classifier
2023-07-31 09:57:00,369:INFO:Total runtime is 0.4855439027150472 minutes
2023-07-31 09:57:00,372:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:00,373:INFO:Initializing create_model()
2023-07-31 09:57:00,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:00,373:INFO:Checking exceptions
2023-07-31 09:57:00,373:INFO:Importing libraries
2023-07-31 09:57:00,373:INFO:Copying training dataset
2023-07-31 09:57:00,429:INFO:Defining folds
2023-07-31 09:57:00,430:INFO:Declaring metric variables
2023-07-31 09:57:00,434:INFO:Importing untrained model
2023-07-31 09:57:00,437:INFO:Ada Boost Classifier Imported successfully
2023-07-31 09:57:00,444:INFO:Starting cross validation
2023-07-31 09:57:00,486:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:02,888:INFO:Calculating mean and std
2023-07-31 09:57:02,890:INFO:Creating metrics dataframe
2023-07-31 09:57:03,046:INFO:Uploading results into container
2023-07-31 09:57:03,047:INFO:Uploading model into container now
2023-07-31 09:57:03,047:INFO:_master_model_container: 9
2023-07-31 09:57:03,047:INFO:_display_container: 2
2023-07-31 09:57:03,048:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 09:57:03,048:INFO:create_model() successfully completed......................................
2023-07-31 09:57:03,157:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:03,157:INFO:Creating metrics dataframe
2023-07-31 09:57:03,170:INFO:Initializing Gradient Boosting Classifier
2023-07-31 09:57:03,170:INFO:Total runtime is 0.5322320143381755 minutes
2023-07-31 09:57:03,174:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:03,174:INFO:Initializing create_model()
2023-07-31 09:57:03,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:03,174:INFO:Checking exceptions
2023-07-31 09:57:03,174:INFO:Importing libraries
2023-07-31 09:57:03,174:INFO:Copying training dataset
2023-07-31 09:57:03,231:INFO:Defining folds
2023-07-31 09:57:03,231:INFO:Declaring metric variables
2023-07-31 09:57:03,235:INFO:Importing untrained model
2023-07-31 09:57:03,239:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 09:57:03,246:INFO:Starting cross validation
2023-07-31 09:57:03,288:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:05,026:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:05,061:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:05,076:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:05,087:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:05,121:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:05,143:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:05,155:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:05,164:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:06,358:INFO:Calculating mean and std
2023-07-31 09:57:06,360:INFO:Creating metrics dataframe
2023-07-31 09:57:06,791:INFO:Uploading results into container
2023-07-31 09:57:06,792:INFO:Uploading model into container now
2023-07-31 09:57:06,793:INFO:_master_model_container: 10
2023-07-31 09:57:06,793:INFO:_display_container: 2
2023-07-31 09:57:06,793:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 09:57:06,793:INFO:create_model() successfully completed......................................
2023-07-31 09:57:06,898:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:06,898:INFO:Creating metrics dataframe
2023-07-31 09:57:06,913:INFO:Initializing Linear Discriminant Analysis
2023-07-31 09:57:06,913:INFO:Total runtime is 0.5946149984995525 minutes
2023-07-31 09:57:06,917:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:06,918:INFO:Initializing create_model()
2023-07-31 09:57:06,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:06,918:INFO:Checking exceptions
2023-07-31 09:57:06,918:INFO:Importing libraries
2023-07-31 09:57:06,918:INFO:Copying training dataset
2023-07-31 09:57:06,977:INFO:Defining folds
2023-07-31 09:57:06,978:INFO:Declaring metric variables
2023-07-31 09:57:06,982:INFO:Importing untrained model
2023-07-31 09:57:06,986:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 09:57:06,993:INFO:Starting cross validation
2023-07-31 09:57:07,035:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:09,323:INFO:Calculating mean and std
2023-07-31 09:57:09,326:INFO:Creating metrics dataframe
2023-07-31 09:57:09,500:INFO:Uploading results into container
2023-07-31 09:57:09,501:INFO:Uploading model into container now
2023-07-31 09:57:09,501:INFO:_master_model_container: 11
2023-07-31 09:57:09,502:INFO:_display_container: 2
2023-07-31 09:57:09,502:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 09:57:09,502:INFO:create_model() successfully completed......................................
2023-07-31 09:57:09,605:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:09,606:INFO:Creating metrics dataframe
2023-07-31 09:57:09,619:INFO:Initializing Extra Trees Classifier
2023-07-31 09:57:09,620:INFO:Total runtime is 0.639723547299703 minutes
2023-07-31 09:57:09,623:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:09,623:INFO:Initializing create_model()
2023-07-31 09:57:09,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:09,624:INFO:Checking exceptions
2023-07-31 09:57:09,624:INFO:Importing libraries
2023-07-31 09:57:09,624:INFO:Copying training dataset
2023-07-31 09:57:09,680:INFO:Defining folds
2023-07-31 09:57:09,681:INFO:Declaring metric variables
2023-07-31 09:57:09,685:INFO:Importing untrained model
2023-07-31 09:57:09,688:INFO:Extra Trees Classifier Imported successfully
2023-07-31 09:57:09,695:INFO:Starting cross validation
2023-07-31 09:57:09,737:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:12,293:INFO:Calculating mean and std
2023-07-31 09:57:12,296:INFO:Creating metrics dataframe
2023-07-31 09:57:12,471:INFO:Uploading results into container
2023-07-31 09:57:12,473:INFO:Uploading model into container now
2023-07-31 09:57:12,473:INFO:_master_model_container: 12
2023-07-31 09:57:12,473:INFO:_display_container: 2
2023-07-31 09:57:12,474:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 09:57:12,474:INFO:create_model() successfully completed......................................
2023-07-31 09:57:12,599:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:12,599:INFO:Creating metrics dataframe
2023-07-31 09:57:12,614:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 09:57:12,614:INFO:Total runtime is 0.6896260261535645 minutes
2023-07-31 09:57:12,617:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:12,618:INFO:Initializing create_model()
2023-07-31 09:57:12,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:12,618:INFO:Checking exceptions
2023-07-31 09:57:12,618:INFO:Importing libraries
2023-07-31 09:57:12,618:INFO:Copying training dataset
2023-07-31 09:57:12,684:INFO:Defining folds
2023-07-31 09:57:12,684:INFO:Declaring metric variables
2023-07-31 09:57:12,688:INFO:Importing untrained model
2023-07-31 09:57:12,692:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 09:57:12,698:INFO:Starting cross validation
2023-07-31 09:57:12,741:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:14,992:INFO:Calculating mean and std
2023-07-31 09:57:14,995:INFO:Creating metrics dataframe
2023-07-31 09:57:15,157:INFO:Uploading results into container
2023-07-31 09:57:15,158:INFO:Uploading model into container now
2023-07-31 09:57:15,158:INFO:_master_model_container: 13
2023-07-31 09:57:15,158:INFO:_display_container: 2
2023-07-31 09:57:15,159:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 09:57:15,159:INFO:create_model() successfully completed......................................
2023-07-31 09:57:15,287:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:15,287:INFO:Creating metrics dataframe
2023-07-31 09:57:15,301:INFO:Initializing Dummy Classifier
2023-07-31 09:57:15,302:INFO:Total runtime is 0.7344238718350729 minutes
2023-07-31 09:57:15,305:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:15,306:INFO:Initializing create_model()
2023-07-31 09:57:15,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1555580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:15,306:INFO:Checking exceptions
2023-07-31 09:57:15,306:INFO:Importing libraries
2023-07-31 09:57:15,306:INFO:Copying training dataset
2023-07-31 09:57:15,363:INFO:Defining folds
2023-07-31 09:57:15,363:INFO:Declaring metric variables
2023-07-31 09:57:15,367:INFO:Importing untrained model
2023-07-31 09:57:15,371:INFO:Dummy Classifier Imported successfully
2023-07-31 09:57:15,377:INFO:Starting cross validation
2023-07-31 09:57:15,420:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:17,593:INFO:Calculating mean and std
2023-07-31 09:57:17,595:INFO:Creating metrics dataframe
2023-07-31 09:57:17,751:INFO:Uploading results into container
2023-07-31 09:57:17,752:INFO:Uploading model into container now
2023-07-31 09:57:17,752:INFO:_master_model_container: 14
2023-07-31 09:57:17,753:INFO:_display_container: 2
2023-07-31 09:57:17,753:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 09:57:17,753:INFO:create_model() successfully completed......................................
2023-07-31 09:57:17,855:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:17,855:INFO:Creating metrics dataframe
2023-07-31 09:57:17,879:INFO:Initializing create_model()
2023-07-31 09:57:17,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd154df10>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:17,879:INFO:Checking exceptions
2023-07-31 09:57:17,881:INFO:Importing libraries
2023-07-31 09:57:17,881:INFO:Copying training dataset
2023-07-31 09:57:17,938:INFO:Defining folds
2023-07-31 09:57:17,938:INFO:Declaring metric variables
2023-07-31 09:57:17,938:INFO:Importing untrained model
2023-07-31 09:57:17,938:INFO:Declaring custom model
2023-07-31 09:57:17,939:INFO:Ada Boost Classifier Imported successfully
2023-07-31 09:57:17,980:INFO:Cross validation set to False
2023-07-31 09:57:17,980:INFO:Fitting Model
2023-07-31 09:57:18,572:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 09:57:18,572:INFO:create_model() successfully completed......................................
2023-07-31 09:57:18,706:INFO:_master_model_container: 14
2023-07-31 09:57:18,706:INFO:_display_container: 2
2023-07-31 09:57:18,707:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 09:57:18,707:INFO:compare_models() successfully completed......................................
2023-07-31 09:57:21,636:INFO:Initializing set_config()
2023-07-31 09:57:21,636:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, variable=seed, value=42, kwargs={})
2023-07-31 09:57:21,637:INFO:Global variable: seed updated to 42
2023-07-31 09:57:21,637:INFO:set_config() successfully completed......................................
2023-07-31 09:57:21,753:INFO:PyCaret ClassificationExperiment
2023-07-31 09:57:21,753:INFO:Logging name: clf-default-name
2023-07-31 09:57:21,753:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 09:57:21,753:INFO:version 3.0.2
2023-07-31 09:57:21,753:INFO:Initializing setup()
2023-07-31 09:57:21,753:INFO:self.USI: f402
2023-07-31 09:57:21,753:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 09:57:21,753:INFO:Checking environment
2023-07-31 09:57:21,753:INFO:python_version: 3.9.16
2023-07-31 09:57:21,753:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 09:57:21,753:INFO:machine: x86_64
2023-07-31 09:57:21,753:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 09:57:21,753:INFO:Memory: svmem(total=67419119616, available=13970829312, percent=79.3, used=52566888448, free=10848256000, active=48232095744, inactive=5982076928, buffers=48279552, cached=3955695616, shared=188133376, slab=1328881664)
2023-07-31 09:57:21,755:INFO:Physical Core: 28
2023-07-31 09:57:21,755:INFO:Logical Core: 56
2023-07-31 09:57:21,755:INFO:Checking libraries
2023-07-31 09:57:21,755:INFO:System:
2023-07-31 09:57:21,755:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 09:57:21,755:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 09:57:21,755:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 09:57:21,755:INFO:PyCaret required dependencies:
2023-07-31 09:57:21,756:INFO:                 pip: 23.0.1
2023-07-31 09:57:21,756:INFO:          setuptools: 66.0.0
2023-07-31 09:57:21,756:INFO:             pycaret: 3.0.2
2023-07-31 09:57:21,756:INFO:             IPython: 8.13.2
2023-07-31 09:57:21,756:INFO:          ipywidgets: 8.0.6
2023-07-31 09:57:21,756:INFO:                tqdm: 4.65.0
2023-07-31 09:57:21,756:INFO:               numpy: 1.23.5
2023-07-31 09:57:21,756:INFO:              pandas: 1.5.3
2023-07-31 09:57:21,756:INFO:              jinja2: 3.1.2
2023-07-31 09:57:21,756:INFO:               scipy: 1.10.1
2023-07-31 09:57:21,756:INFO:              joblib: 1.2.0
2023-07-31 09:57:21,756:INFO:             sklearn: 1.2.2
2023-07-31 09:57:21,756:INFO:                pyod: 1.0.9
2023-07-31 09:57:21,756:INFO:            imblearn: 0.10.1
2023-07-31 09:57:21,756:INFO:   category_encoders: 2.6.1
2023-07-31 09:57:21,756:INFO:            lightgbm: 3.3.5
2023-07-31 09:57:21,756:INFO:               numba: 0.57.0
2023-07-31 09:57:21,756:INFO:            requests: 2.28.1
2023-07-31 09:57:21,756:INFO:          matplotlib: 3.7.1
2023-07-31 09:57:21,756:INFO:          scikitplot: 0.3.7
2023-07-31 09:57:21,756:INFO:         yellowbrick: 1.5
2023-07-31 09:57:21,756:INFO:              plotly: 5.14.1
2023-07-31 09:57:21,756:INFO:             kaleido: 0.2.1
2023-07-31 09:57:21,756:INFO:         statsmodels: 0.14.0
2023-07-31 09:57:21,756:INFO:              sktime: 0.17.0
2023-07-31 09:57:21,756:INFO:               tbats: 1.1.3
2023-07-31 09:57:21,756:INFO:            pmdarima: 2.0.3
2023-07-31 09:57:21,756:INFO:              psutil: 5.9.5
2023-07-31 09:57:21,756:INFO:PyCaret optional dependencies:
2023-07-31 09:57:21,756:INFO:                shap: Not installed
2023-07-31 09:57:21,756:INFO:           interpret: Not installed
2023-07-31 09:57:21,756:INFO:                umap: Not installed
2023-07-31 09:57:21,756:INFO:    pandas_profiling: Not installed
2023-07-31 09:57:21,757:INFO:  explainerdashboard: Not installed
2023-07-31 09:57:21,757:INFO:             autoviz: Not installed
2023-07-31 09:57:21,757:INFO:           fairlearn: Not installed
2023-07-31 09:57:21,757:INFO:             xgboost: Not installed
2023-07-31 09:57:21,757:INFO:            catboost: Not installed
2023-07-31 09:57:21,757:INFO:              kmodes: Not installed
2023-07-31 09:57:21,757:INFO:             mlxtend: Not installed
2023-07-31 09:57:21,757:INFO:       statsforecast: Not installed
2023-07-31 09:57:21,757:INFO:        tune_sklearn: Not installed
2023-07-31 09:57:21,757:INFO:                 ray: Not installed
2023-07-31 09:57:21,757:INFO:            hyperopt: Not installed
2023-07-31 09:57:21,757:INFO:              optuna: Not installed
2023-07-31 09:57:21,757:INFO:               skopt: Not installed
2023-07-31 09:57:21,757:INFO:              mlflow: Not installed
2023-07-31 09:57:21,757:INFO:              gradio: Not installed
2023-07-31 09:57:21,757:INFO:             fastapi: Not installed
2023-07-31 09:57:21,757:INFO:             uvicorn: Not installed
2023-07-31 09:57:21,757:INFO:              m2cgen: Not installed
2023-07-31 09:57:21,757:INFO:           evidently: Not installed
2023-07-31 09:57:21,757:INFO:               fugue: Not installed
2023-07-31 09:57:21,757:INFO:           streamlit: Not installed
2023-07-31 09:57:21,757:INFO:             prophet: Not installed
2023-07-31 09:57:21,757:INFO:None
2023-07-31 09:57:21,757:INFO:Set up data.
2023-07-31 09:57:25,482:INFO:Set up train/test split.
2023-07-31 09:57:25,689:INFO:Set up index.
2023-07-31 09:57:25,689:INFO:Set up folding strategy.
2023-07-31 09:57:25,689:INFO:Assigning column types.
2023-07-31 09:57:25,817:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 09:57:25,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 09:57:25,904:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:57:25,940:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:25,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:25,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 09:57:25,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:57:26,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,014:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 09:57:26,060:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:57:26,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,133:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 09:57:26,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,161:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,161:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 09:57:26,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:26,308:INFO:Preparing preprocessing pipeline...
2023-07-31 09:57:26,331:INFO:Set up simple imputation.
2023-07-31 09:57:26,351:INFO:Set up column name cleaning.
2023-07-31 09:57:27,438:INFO:Finished creating preprocessing pipeline.
2023-07-31 09:57:27,507:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 09:57:27,507:INFO:Creating final display dataframe.
2023-07-31 09:57:30,670:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (742, 11886)
4        Transformed data shape      (742, 11886)
5   Transformed train set shape      (519, 11886)
6    Transformed test set shape      (223, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              f402
2023-07-31 09:57:30,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:30,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:30,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:30,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 09:57:30,828:INFO:setup() successfully completed in 9.19s...............
2023-07-31 09:57:30,834:INFO:Initializing compare_models()
2023-07-31 09:57:30,834:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 09:57:30,834:INFO:Checking exceptions
2023-07-31 09:57:30,920:INFO:Preparing display monitor
2023-07-31 09:57:30,942:INFO:Initializing Logistic Regression
2023-07-31 09:57:30,942:INFO:Total runtime is 3.07162602742513e-06 minutes
2023-07-31 09:57:30,945:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:30,946:INFO:Initializing create_model()
2023-07-31 09:57:30,946:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:30,946:INFO:Checking exceptions
2023-07-31 09:57:30,946:INFO:Importing libraries
2023-07-31 09:57:30,946:INFO:Copying training dataset
2023-07-31 09:57:31,059:INFO:Defining folds
2023-07-31 09:57:31,060:INFO:Declaring metric variables
2023-07-31 09:57:31,063:INFO:Importing untrained model
2023-07-31 09:57:31,067:INFO:Logistic Regression Imported successfully
2023-07-31 09:57:31,074:INFO:Starting cross validation
2023-07-31 09:57:31,116:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:38,620:INFO:Calculating mean and std
2023-07-31 09:57:38,623:INFO:Creating metrics dataframe
2023-07-31 09:57:38,813:INFO:Uploading results into container
2023-07-31 09:57:38,814:INFO:Uploading model into container now
2023-07-31 09:57:38,815:INFO:_master_model_container: 1
2023-07-31 09:57:38,815:INFO:_display_container: 2
2023-07-31 09:57:38,815:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 09:57:38,815:INFO:create_model() successfully completed......................................
2023-07-31 09:57:38,971:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:38,972:INFO:Creating metrics dataframe
2023-07-31 09:57:38,982:INFO:Initializing K Neighbors Classifier
2023-07-31 09:57:38,982:INFO:Total runtime is 0.13400702476501464 minutes
2023-07-31 09:57:38,986:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:38,986:INFO:Initializing create_model()
2023-07-31 09:57:38,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:38,986:INFO:Checking exceptions
2023-07-31 09:57:38,987:INFO:Importing libraries
2023-07-31 09:57:38,987:INFO:Copying training dataset
2023-07-31 09:57:39,100:INFO:Defining folds
2023-07-31 09:57:39,101:INFO:Declaring metric variables
2023-07-31 09:57:39,105:INFO:Importing untrained model
2023-07-31 09:57:39,108:INFO:K Neighbors Classifier Imported successfully
2023-07-31 09:57:39,115:INFO:Starting cross validation
2023-07-31 09:57:39,158:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:41,249:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:57:42,551:INFO:Calculating mean and std
2023-07-31 09:57:42,553:INFO:Creating metrics dataframe
2023-07-31 09:57:42,748:INFO:Uploading results into container
2023-07-31 09:57:42,749:INFO:Uploading model into container now
2023-07-31 09:57:42,749:INFO:_master_model_container: 2
2023-07-31 09:57:42,750:INFO:_display_container: 2
2023-07-31 09:57:42,750:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 09:57:42,750:INFO:create_model() successfully completed......................................
2023-07-31 09:57:42,869:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:42,869:INFO:Creating metrics dataframe
2023-07-31 09:57:42,880:INFO:Initializing Naive Bayes
2023-07-31 09:57:42,880:INFO:Total runtime is 0.1989738663037618 minutes
2023-07-31 09:57:42,884:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:42,884:INFO:Initializing create_model()
2023-07-31 09:57:42,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:42,884:INFO:Checking exceptions
2023-07-31 09:57:42,884:INFO:Importing libraries
2023-07-31 09:57:42,885:INFO:Copying training dataset
2023-07-31 09:57:42,990:INFO:Defining folds
2023-07-31 09:57:42,990:INFO:Declaring metric variables
2023-07-31 09:57:42,994:INFO:Importing untrained model
2023-07-31 09:57:42,998:INFO:Naive Bayes Imported successfully
2023-07-31 09:57:43,005:INFO:Starting cross validation
2023-07-31 09:57:43,047:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:46,351:INFO:Calculating mean and std
2023-07-31 09:57:46,354:INFO:Creating metrics dataframe
2023-07-31 09:57:46,798:INFO:Uploading results into container
2023-07-31 09:57:46,799:INFO:Uploading model into container now
2023-07-31 09:57:46,799:INFO:_master_model_container: 3
2023-07-31 09:57:46,799:INFO:_display_container: 2
2023-07-31 09:57:46,800:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 09:57:46,800:INFO:create_model() successfully completed......................................
2023-07-31 09:57:46,911:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:46,911:INFO:Creating metrics dataframe
2023-07-31 09:57:46,923:INFO:Initializing Decision Tree Classifier
2023-07-31 09:57:46,923:INFO:Total runtime is 0.2663528521855672 minutes
2023-07-31 09:57:46,927:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:46,927:INFO:Initializing create_model()
2023-07-31 09:57:46,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:46,927:INFO:Checking exceptions
2023-07-31 09:57:46,927:INFO:Importing libraries
2023-07-31 09:57:46,927:INFO:Copying training dataset
2023-07-31 09:57:47,033:INFO:Defining folds
2023-07-31 09:57:47,033:INFO:Declaring metric variables
2023-07-31 09:57:47,037:INFO:Importing untrained model
2023-07-31 09:57:47,041:INFO:Decision Tree Classifier Imported successfully
2023-07-31 09:57:47,047:INFO:Starting cross validation
2023-07-31 09:57:47,090:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:51,285:INFO:Calculating mean and std
2023-07-31 09:57:51,287:INFO:Creating metrics dataframe
2023-07-31 09:57:51,468:INFO:Uploading results into container
2023-07-31 09:57:51,469:INFO:Uploading model into container now
2023-07-31 09:57:51,469:INFO:_master_model_container: 4
2023-07-31 09:57:51,469:INFO:_display_container: 2
2023-07-31 09:57:51,470:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 09:57:51,470:INFO:create_model() successfully completed......................................
2023-07-31 09:57:51,575:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:51,575:INFO:Creating metrics dataframe
2023-07-31 09:57:51,587:INFO:Initializing SVM - Linear Kernel
2023-07-31 09:57:51,587:INFO:Total runtime is 0.34408950408299765 minutes
2023-07-31 09:57:51,591:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:51,591:INFO:Initializing create_model()
2023-07-31 09:57:51,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:51,591:INFO:Checking exceptions
2023-07-31 09:57:51,591:INFO:Importing libraries
2023-07-31 09:57:51,591:INFO:Copying training dataset
2023-07-31 09:57:51,696:INFO:Defining folds
2023-07-31 09:57:51,697:INFO:Declaring metric variables
2023-07-31 09:57:51,701:INFO:Importing untrained model
2023-07-31 09:57:51,704:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 09:57:51,711:INFO:Starting cross validation
2023-07-31 09:57:51,754:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:53,951:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:57:54,014:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:57:54,034:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:57:54,037:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:57:54,040:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:57:54,073:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:57:54,142:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:57:54,209:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 09:57:54,912:INFO:Calculating mean and std
2023-07-31 09:57:54,914:INFO:Creating metrics dataframe
2023-07-31 09:57:55,091:INFO:Uploading results into container
2023-07-31 09:57:55,092:INFO:Uploading model into container now
2023-07-31 09:57:55,092:INFO:_master_model_container: 5
2023-07-31 09:57:55,092:INFO:_display_container: 2
2023-07-31 09:57:55,093:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 09:57:55,093:INFO:create_model() successfully completed......................................
2023-07-31 09:57:55,209:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:55,209:INFO:Creating metrics dataframe
2023-07-31 09:57:55,221:INFO:Initializing Ridge Classifier
2023-07-31 09:57:55,221:INFO:Total runtime is 0.40465700229008994 minutes
2023-07-31 09:57:55,225:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:55,225:INFO:Initializing create_model()
2023-07-31 09:57:55,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:55,225:INFO:Checking exceptions
2023-07-31 09:57:55,225:INFO:Importing libraries
2023-07-31 09:57:55,225:INFO:Copying training dataset
2023-07-31 09:57:55,330:INFO:Defining folds
2023-07-31 09:57:55,331:INFO:Declaring metric variables
2023-07-31 09:57:55,335:INFO:Importing untrained model
2023-07-31 09:57:55,338:INFO:Ridge Classifier Imported successfully
2023-07-31 09:57:55,345:INFO:Starting cross validation
2023-07-31 09:57:55,387:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:57:57,482:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:57:57,502:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:57:57,505:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:57:57,578:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:57:57,582:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:57:57,596:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:57:57,684:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:57:57,942:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 09:57:58,531:INFO:Calculating mean and std
2023-07-31 09:57:58,533:INFO:Creating metrics dataframe
2023-07-31 09:57:58,734:INFO:Uploading results into container
2023-07-31 09:57:58,735:INFO:Uploading model into container now
2023-07-31 09:57:58,736:INFO:_master_model_container: 6
2023-07-31 09:57:58,736:INFO:_display_container: 2
2023-07-31 09:57:58,736:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 09:57:58,736:INFO:create_model() successfully completed......................................
2023-07-31 09:57:58,855:INFO:SubProcess create_model() end ==================================
2023-07-31 09:57:58,855:INFO:Creating metrics dataframe
2023-07-31 09:57:58,868:INFO:Initializing Random Forest Classifier
2023-07-31 09:57:58,868:INFO:Total runtime is 0.46543376843134565 minutes
2023-07-31 09:57:58,872:INFO:SubProcess create_model() called ==================================
2023-07-31 09:57:58,872:INFO:Initializing create_model()
2023-07-31 09:57:58,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:57:58,872:INFO:Checking exceptions
2023-07-31 09:57:58,872:INFO:Importing libraries
2023-07-31 09:57:58,872:INFO:Copying training dataset
2023-07-31 09:57:58,981:INFO:Defining folds
2023-07-31 09:57:58,982:INFO:Declaring metric variables
2023-07-31 09:57:58,986:INFO:Importing untrained model
2023-07-31 09:57:58,990:INFO:Random Forest Classifier Imported successfully
2023-07-31 09:57:58,996:INFO:Starting cross validation
2023-07-31 09:57:59,039:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:58:01,696:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:58:01,713:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:58:01,729:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:58:01,734:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:58:01,762:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:58:01,768:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:58:01,785:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:58:01,798:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 09:58:03,238:INFO:Calculating mean and std
2023-07-31 09:58:03,240:INFO:Creating metrics dataframe
2023-07-31 09:58:03,413:INFO:Uploading results into container
2023-07-31 09:58:03,414:INFO:Uploading model into container now
2023-07-31 09:58:03,415:INFO:_master_model_container: 7
2023-07-31 09:58:03,415:INFO:_display_container: 2
2023-07-31 09:58:03,415:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 09:58:03,415:INFO:create_model() successfully completed......................................
2023-07-31 09:58:03,545:INFO:SubProcess create_model() end ==================================
2023-07-31 09:58:03,545:INFO:Creating metrics dataframe
2023-07-31 09:58:03,558:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 09:58:03,558:INFO:Total runtime is 0.5435943762461345 minutes
2023-07-31 09:58:03,561:INFO:SubProcess create_model() called ==================================
2023-07-31 09:58:03,561:INFO:Initializing create_model()
2023-07-31 09:58:03,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:58:03,562:INFO:Checking exceptions
2023-07-31 09:58:03,562:INFO:Importing libraries
2023-07-31 09:58:03,562:INFO:Copying training dataset
2023-07-31 09:58:03,671:INFO:Defining folds
2023-07-31 09:58:03,672:INFO:Declaring metric variables
2023-07-31 09:58:03,676:INFO:Importing untrained model
2023-07-31 09:58:03,679:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 09:58:03,686:INFO:Starting cross validation
2023-07-31 09:58:03,729:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:58:05,159:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:58:05,169:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:58:05,217:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:58:05,376:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:58:05,392:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:58:05,427:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:58:05,480:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:58:05,506:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 09:58:08,719:INFO:Calculating mean and std
2023-07-31 09:58:08,722:INFO:Creating metrics dataframe
2023-07-31 09:58:08,907:INFO:Uploading results into container
2023-07-31 09:58:08,908:INFO:Uploading model into container now
2023-07-31 09:58:08,908:INFO:_master_model_container: 8
2023-07-31 09:58:08,908:INFO:_display_container: 2
2023-07-31 09:58:08,909:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 09:58:08,909:INFO:create_model() successfully completed......................................
2023-07-31 09:58:09,058:INFO:SubProcess create_model() end ==================================
2023-07-31 09:58:09,058:INFO:Creating metrics dataframe
2023-07-31 09:58:09,072:INFO:Initializing Ada Boost Classifier
2023-07-31 09:58:09,072:INFO:Total runtime is 0.6354965368906658 minutes
2023-07-31 09:58:09,075:INFO:SubProcess create_model() called ==================================
2023-07-31 09:58:09,076:INFO:Initializing create_model()
2023-07-31 09:58:09,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:58:09,076:INFO:Checking exceptions
2023-07-31 09:58:09,076:INFO:Importing libraries
2023-07-31 09:58:09,076:INFO:Copying training dataset
2023-07-31 09:58:09,185:INFO:Defining folds
2023-07-31 09:58:09,185:INFO:Declaring metric variables
2023-07-31 09:58:09,189:INFO:Importing untrained model
2023-07-31 09:58:09,193:INFO:Ada Boost Classifier Imported successfully
2023-07-31 09:58:09,199:INFO:Starting cross validation
2023-07-31 09:58:09,242:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 09:58:40,610:INFO:Calculating mean and std
2023-07-31 09:58:40,612:INFO:Creating metrics dataframe
2023-07-31 09:58:41,044:INFO:Uploading results into container
2023-07-31 09:58:41,045:INFO:Uploading model into container now
2023-07-31 09:58:41,046:INFO:_master_model_container: 9
2023-07-31 09:58:41,046:INFO:_display_container: 2
2023-07-31 09:58:41,046:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 09:58:41,046:INFO:create_model() successfully completed......................................
2023-07-31 09:58:41,169:INFO:SubProcess create_model() end ==================================
2023-07-31 09:58:41,169:INFO:Creating metrics dataframe
2023-07-31 09:58:41,183:INFO:Initializing Gradient Boosting Classifier
2023-07-31 09:58:41,183:INFO:Total runtime is 1.1706812183062236 minutes
2023-07-31 09:58:41,186:INFO:SubProcess create_model() called ==================================
2023-07-31 09:58:41,187:INFO:Initializing create_model()
2023-07-31 09:58:41,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 09:58:41,187:INFO:Checking exceptions
2023-07-31 09:58:41,187:INFO:Importing libraries
2023-07-31 09:58:41,187:INFO:Copying training dataset
2023-07-31 09:58:41,291:INFO:Defining folds
2023-07-31 09:58:41,291:INFO:Declaring metric variables
2023-07-31 09:58:41,295:INFO:Importing untrained model
2023-07-31 09:58:41,299:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 09:58:41,307:INFO:Starting cross validation
2023-07-31 09:58:41,346:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:00:18,924:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:20,422:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:22,795:INFO:Calculating mean and std
2023-07-31 10:00:22,799:INFO:Creating metrics dataframe
2023-07-31 10:00:23,251:INFO:Uploading results into container
2023-07-31 10:00:23,252:INFO:Uploading model into container now
2023-07-31 10:00:23,252:INFO:_master_model_container: 10
2023-07-31 10:00:23,253:INFO:_display_container: 2
2023-07-31 10:00:23,253:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 10:00:23,253:INFO:create_model() successfully completed......................................
2023-07-31 10:00:23,395:INFO:SubProcess create_model() end ==================================
2023-07-31 10:00:23,396:INFO:Creating metrics dataframe
2023-07-31 10:00:23,410:INFO:Initializing Linear Discriminant Analysis
2023-07-31 10:00:23,410:INFO:Total runtime is 2.8744686961174013 minutes
2023-07-31 10:00:23,414:INFO:SubProcess create_model() called ==================================
2023-07-31 10:00:23,414:INFO:Initializing create_model()
2023-07-31 10:00:23,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:00:23,414:INFO:Checking exceptions
2023-07-31 10:00:23,414:INFO:Importing libraries
2023-07-31 10:00:23,415:INFO:Copying training dataset
2023-07-31 10:00:23,519:INFO:Defining folds
2023-07-31 10:00:23,519:INFO:Declaring metric variables
2023-07-31 10:00:23,524:INFO:Importing untrained model
2023-07-31 10:00:23,527:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:00:23,535:INFO:Starting cross validation
2023-07-31 10:00:23,574:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:00:29,836:INFO:Calculating mean and std
2023-07-31 10:00:29,838:INFO:Creating metrics dataframe
2023-07-31 10:00:30,120:INFO:Uploading results into container
2023-07-31 10:00:30,121:INFO:Uploading model into container now
2023-07-31 10:00:30,122:INFO:_master_model_container: 11
2023-07-31 10:00:30,122:INFO:_display_container: 2
2023-07-31 10:00:30,122:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:00:30,122:INFO:create_model() successfully completed......................................
2023-07-31 10:00:30,249:INFO:SubProcess create_model() end ==================================
2023-07-31 10:00:30,249:INFO:Creating metrics dataframe
2023-07-31 10:00:30,267:INFO:Initializing Extra Trees Classifier
2023-07-31 10:00:30,267:INFO:Total runtime is 2.98874888420105 minutes
2023-07-31 10:00:30,271:INFO:SubProcess create_model() called ==================================
2023-07-31 10:00:30,272:INFO:Initializing create_model()
2023-07-31 10:00:30,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:00:30,272:INFO:Checking exceptions
2023-07-31 10:00:30,272:INFO:Importing libraries
2023-07-31 10:00:30,272:INFO:Copying training dataset
2023-07-31 10:00:30,405:INFO:Defining folds
2023-07-31 10:00:30,405:INFO:Declaring metric variables
2023-07-31 10:00:30,410:INFO:Importing untrained model
2023-07-31 10:00:30,415:INFO:Extra Trees Classifier Imported successfully
2023-07-31 10:00:30,423:INFO:Starting cross validation
2023-07-31 10:00:30,497:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:00:34,049:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:34,091:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:34,481:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:34,531:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:34,585:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:34,591:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:34,677:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:34,705:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:00:36,439:INFO:Calculating mean and std
2023-07-31 10:00:36,441:INFO:Creating metrics dataframe
2023-07-31 10:00:36,728:INFO:Uploading results into container
2023-07-31 10:00:36,729:INFO:Uploading model into container now
2023-07-31 10:00:36,730:INFO:_master_model_container: 12
2023-07-31 10:00:36,730:INFO:_display_container: 2
2023-07-31 10:00:36,731:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 10:00:36,731:INFO:create_model() successfully completed......................................
2023-07-31 10:00:36,857:INFO:SubProcess create_model() end ==================================
2023-07-31 10:00:36,857:INFO:Creating metrics dataframe
2023-07-31 10:00:36,875:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 10:00:36,875:INFO:Total runtime is 3.0988863388697307 minutes
2023-07-31 10:00:36,883:INFO:SubProcess create_model() called ==================================
2023-07-31 10:00:36,883:INFO:Initializing create_model()
2023-07-31 10:00:36,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:00:36,884:INFO:Checking exceptions
2023-07-31 10:00:36,884:INFO:Importing libraries
2023-07-31 10:00:36,884:INFO:Copying training dataset
2023-07-31 10:00:37,018:INFO:Defining folds
2023-07-31 10:00:37,018:INFO:Declaring metric variables
2023-07-31 10:00:37,023:INFO:Importing untrained model
2023-07-31 10:00:37,028:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 10:00:37,035:INFO:Starting cross validation
2023-07-31 10:00:37,111:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:01:48,245:INFO:Calculating mean and std
2023-07-31 10:01:48,248:INFO:Creating metrics dataframe
2023-07-31 10:01:48,701:INFO:Uploading results into container
2023-07-31 10:01:48,702:INFO:Uploading model into container now
2023-07-31 10:01:48,703:INFO:_master_model_container: 13
2023-07-31 10:01:48,703:INFO:_display_container: 2
2023-07-31 10:01:48,704:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 10:01:48,704:INFO:create_model() successfully completed......................................
2023-07-31 10:01:48,848:INFO:SubProcess create_model() end ==================================
2023-07-31 10:01:48,849:INFO:Creating metrics dataframe
2023-07-31 10:01:48,863:INFO:Initializing Dummy Classifier
2023-07-31 10:01:48,863:INFO:Total runtime is 4.2986796776453655 minutes
2023-07-31 10:01:48,866:INFO:SubProcess create_model() called ==================================
2023-07-31 10:01:48,867:INFO:Initializing create_model()
2023-07-31 10:01:48,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14a6970>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:01:48,867:INFO:Checking exceptions
2023-07-31 10:01:48,867:INFO:Importing libraries
2023-07-31 10:01:48,867:INFO:Copying training dataset
2023-07-31 10:01:48,969:INFO:Defining folds
2023-07-31 10:01:48,969:INFO:Declaring metric variables
2023-07-31 10:01:48,973:INFO:Importing untrained model
2023-07-31 10:01:48,977:INFO:Dummy Classifier Imported successfully
2023-07-31 10:01:48,984:INFO:Starting cross validation
2023-07-31 10:01:49,022:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:01:51,052:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:01:51,082:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:01:51,117:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:01:51,920:INFO:Calculating mean and std
2023-07-31 10:01:51,923:INFO:Creating metrics dataframe
2023-07-31 10:01:52,099:INFO:Uploading results into container
2023-07-31 10:01:52,100:INFO:Uploading model into container now
2023-07-31 10:01:52,100:INFO:_master_model_container: 14
2023-07-31 10:01:52,100:INFO:_display_container: 2
2023-07-31 10:01:52,101:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 10:01:52,101:INFO:create_model() successfully completed......................................
2023-07-31 10:01:52,213:INFO:SubProcess create_model() end ==================================
2023-07-31 10:01:52,213:INFO:Creating metrics dataframe
2023-07-31 10:01:52,235:INFO:Initializing create_model()
2023-07-31 10:01:52,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151c0a0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:01:52,235:INFO:Checking exceptions
2023-07-31 10:01:52,237:INFO:Importing libraries
2023-07-31 10:01:52,237:INFO:Copying training dataset
2023-07-31 10:01:52,344:INFO:Defining folds
2023-07-31 10:01:52,344:INFO:Declaring metric variables
2023-07-31 10:01:52,344:INFO:Importing untrained model
2023-07-31 10:01:52,344:INFO:Declaring custom model
2023-07-31 10:01:52,345:INFO:Logistic Regression Imported successfully
2023-07-31 10:01:52,381:INFO:Cross validation set to False
2023-07-31 10:01:52,381:INFO:Fitting Model
2023-07-31 10:01:55,556:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:01:55,556:INFO:create_model() successfully completed......................................
2023-07-31 10:01:55,684:INFO:_master_model_container: 14
2023-07-31 10:01:55,684:INFO:_display_container: 2
2023-07-31 10:01:55,684:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:01:55,684:INFO:compare_models() successfully completed......................................
2023-07-31 10:01:55,761:INFO:Initializing set_config()
2023-07-31 10:01:55,761:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, variable=seed, value=42, kwargs={})
2023-07-31 10:01:55,761:INFO:Global variable: seed updated to 42
2023-07-31 10:01:55,761:INFO:set_config() successfully completed......................................
2023-07-31 10:01:55,883:INFO:PyCaret ClassificationExperiment
2023-07-31 10:01:55,883:INFO:Logging name: clf-default-name
2023-07-31 10:01:55,883:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 10:01:55,883:INFO:version 3.0.2
2023-07-31 10:01:55,883:INFO:Initializing setup()
2023-07-31 10:01:55,883:INFO:self.USI: 55f4
2023-07-31 10:01:55,883:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 10:01:55,883:INFO:Checking environment
2023-07-31 10:01:55,883:INFO:python_version: 3.9.16
2023-07-31 10:01:55,883:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 10:01:55,883:INFO:machine: x86_64
2023-07-31 10:01:55,883:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:01:55,883:INFO:Memory: svmem(total=67419119616, available=18175455232, percent=73.0, used=48391016448, free=13912862720, active=44897083392, inactive=6284156928, buffers=54898688, cached=5060341760, shared=160055296, slab=1346957312)
2023-07-31 10:01:55,885:INFO:Physical Core: 28
2023-07-31 10:01:55,885:INFO:Logical Core: 56
2023-07-31 10:01:55,885:INFO:Checking libraries
2023-07-31 10:01:55,885:INFO:System:
2023-07-31 10:01:55,885:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 10:01:55,885:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 10:01:55,885:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:01:55,885:INFO:PyCaret required dependencies:
2023-07-31 10:01:55,885:INFO:                 pip: 23.0.1
2023-07-31 10:01:55,885:INFO:          setuptools: 66.0.0
2023-07-31 10:01:55,885:INFO:             pycaret: 3.0.2
2023-07-31 10:01:55,885:INFO:             IPython: 8.13.2
2023-07-31 10:01:55,885:INFO:          ipywidgets: 8.0.6
2023-07-31 10:01:55,885:INFO:                tqdm: 4.65.0
2023-07-31 10:01:55,885:INFO:               numpy: 1.23.5
2023-07-31 10:01:55,885:INFO:              pandas: 1.5.3
2023-07-31 10:01:55,885:INFO:              jinja2: 3.1.2
2023-07-31 10:01:55,885:INFO:               scipy: 1.10.1
2023-07-31 10:01:55,885:INFO:              joblib: 1.2.0
2023-07-31 10:01:55,885:INFO:             sklearn: 1.2.2
2023-07-31 10:01:55,885:INFO:                pyod: 1.0.9
2023-07-31 10:01:55,885:INFO:            imblearn: 0.10.1
2023-07-31 10:01:55,886:INFO:   category_encoders: 2.6.1
2023-07-31 10:01:55,886:INFO:            lightgbm: 3.3.5
2023-07-31 10:01:55,886:INFO:               numba: 0.57.0
2023-07-31 10:01:55,886:INFO:            requests: 2.28.1
2023-07-31 10:01:55,886:INFO:          matplotlib: 3.7.1
2023-07-31 10:01:55,886:INFO:          scikitplot: 0.3.7
2023-07-31 10:01:55,886:INFO:         yellowbrick: 1.5
2023-07-31 10:01:55,886:INFO:              plotly: 5.14.1
2023-07-31 10:01:55,886:INFO:             kaleido: 0.2.1
2023-07-31 10:01:55,886:INFO:         statsmodels: 0.14.0
2023-07-31 10:01:55,886:INFO:              sktime: 0.17.0
2023-07-31 10:01:55,886:INFO:               tbats: 1.1.3
2023-07-31 10:01:55,886:INFO:            pmdarima: 2.0.3
2023-07-31 10:01:55,886:INFO:              psutil: 5.9.5
2023-07-31 10:01:55,886:INFO:PyCaret optional dependencies:
2023-07-31 10:01:55,886:INFO:                shap: Not installed
2023-07-31 10:01:55,886:INFO:           interpret: Not installed
2023-07-31 10:01:55,886:INFO:                umap: Not installed
2023-07-31 10:01:55,886:INFO:    pandas_profiling: Not installed
2023-07-31 10:01:55,886:INFO:  explainerdashboard: Not installed
2023-07-31 10:01:55,886:INFO:             autoviz: Not installed
2023-07-31 10:01:55,886:INFO:           fairlearn: Not installed
2023-07-31 10:01:55,886:INFO:             xgboost: Not installed
2023-07-31 10:01:55,886:INFO:            catboost: Not installed
2023-07-31 10:01:55,886:INFO:              kmodes: Not installed
2023-07-31 10:01:55,886:INFO:             mlxtend: Not installed
2023-07-31 10:01:55,886:INFO:       statsforecast: Not installed
2023-07-31 10:01:55,886:INFO:        tune_sklearn: Not installed
2023-07-31 10:01:55,886:INFO:                 ray: Not installed
2023-07-31 10:01:55,886:INFO:            hyperopt: Not installed
2023-07-31 10:01:55,886:INFO:              optuna: Not installed
2023-07-31 10:01:55,886:INFO:               skopt: Not installed
2023-07-31 10:01:55,886:INFO:              mlflow: Not installed
2023-07-31 10:01:55,886:INFO:              gradio: Not installed
2023-07-31 10:01:55,886:INFO:             fastapi: Not installed
2023-07-31 10:01:55,886:INFO:             uvicorn: Not installed
2023-07-31 10:01:55,886:INFO:              m2cgen: Not installed
2023-07-31 10:01:55,887:INFO:           evidently: Not installed
2023-07-31 10:01:55,887:INFO:               fugue: Not installed
2023-07-31 10:01:55,887:INFO:           streamlit: Not installed
2023-07-31 10:01:55,887:INFO:             prophet: Not installed
2023-07-31 10:01:55,887:INFO:None
2023-07-31 10:01:55,887:INFO:Set up data.
2023-07-31 10:01:55,963:INFO:Set up train/test split.
2023-07-31 10:01:55,969:INFO:Set up index.
2023-07-31 10:01:55,969:INFO:Set up folding strategy.
2023-07-31 10:01:55,969:INFO:Assigning column types.
2023-07-31 10:01:55,973:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 10:01:56,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:01:56,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:01:56,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:01:56,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:01:56,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,102:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 10:01:56,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:01:56,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,209:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:01:56,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,234:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 10:01:56,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,365:INFO:Preparing preprocessing pipeline...
2023-07-31 10:01:56,366:INFO:Set up simple imputation.
2023-07-31 10:01:56,393:INFO:Finished creating preprocessing pipeline.
2023-07-31 10:01:56,397:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-07-31 10:01:56,397:INFO:Creating final display dataframe.
2023-07-31 10:01:56,508:INFO:Setup _display_container:                     Description             Value
0                    Session id                44
1                        Target             group
2                   Target type            Binary
3           Original data shape        (742, 294)
4        Transformed data shape        (742, 294)
5   Transformed train set shape        (519, 294)
6    Transformed test set shape        (223, 294)
7              Numeric features               293
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              55f4
2023-07-31 10:01:56,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:01:56,646:INFO:setup() successfully completed in 0.89s...............
2023-07-31 10:01:56,652:INFO:Initializing compare_models()
2023-07-31 10:01:56,652:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, include=None, fold=None, round=4, cross_validation=False, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': False, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 10:01:56,652:INFO:Checking exceptions
2023-07-31 10:01:56,656:INFO:Preparing display monitor
2023-07-31 10:01:56,678:INFO:Initializing Logistic Regression
2023-07-31 10:01:56,678:INFO:Total runtime is 2.932548522949219e-06 minutes
2023-07-31 10:01:56,681:INFO:SubProcess create_model() called ==================================
2023-07-31 10:01:56,682:INFO:Initializing create_model()
2023-07-31 10:01:56,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:01:56,682:INFO:Checking exceptions
2023-07-31 10:01:56,682:INFO:Importing libraries
2023-07-31 10:01:56,682:INFO:Copying training dataset
2023-07-31 10:01:56,687:INFO:Defining folds
2023-07-31 10:01:56,687:INFO:Declaring metric variables
2023-07-31 10:01:56,690:INFO:Importing untrained model
2023-07-31 10:01:56,694:INFO:Logistic Regression Imported successfully
2023-07-31 10:01:56,698:INFO:Cross validation set to False
2023-07-31 10:01:56,698:INFO:Fitting Model
2023-07-31 10:01:56,803:INFO:Initializing predict_model()
2023-07-31 10:01:56,803:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=44,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd14f3ca0>)
2023-07-31 10:01:56,803:INFO:Checking exceptions
2023-07-31 10:01:56,803:INFO:Preloading libraries
2023-07-31 10:01:57,113:INFO:_display_container: 2
2023-07-31 10:01:57,233:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:01:57,233:INFO:create_model() successfully completed......................................
2023-07-31 10:01:57,331:INFO:SubProcess create_model() end ==================================
2023-07-31 10:01:57,331:INFO:Creating metrics dataframe
2023-07-31 10:01:57,340:INFO:Initializing K Neighbors Classifier
2023-07-31 10:01:57,341:INFO:Total runtime is 0.011045948664347332 minutes
2023-07-31 10:01:57,344:INFO:SubProcess create_model() called ==================================
2023-07-31 10:01:57,344:INFO:Initializing create_model()
2023-07-31 10:01:57,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:01:57,344:INFO:Checking exceptions
2023-07-31 10:01:57,344:INFO:Importing libraries
2023-07-31 10:01:57,344:INFO:Copying training dataset
2023-07-31 10:01:57,349:INFO:Defining folds
2023-07-31 10:01:57,349:INFO:Declaring metric variables
2023-07-31 10:01:57,352:INFO:Importing untrained model
2023-07-31 10:01:57,355:INFO:K Neighbors Classifier Imported successfully
2023-07-31 10:01:57,360:INFO:Cross validation set to False
2023-07-31 10:01:57,360:INFO:Fitting Model
2023-07-31 10:01:57,397:INFO:Initializing predict_model()
2023-07-31 10:01:57,397:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd14f3b80>)
2023-07-31 10:01:57,397:INFO:Checking exceptions
2023-07-31 10:01:57,397:INFO:Preloading libraries
2023-07-31 10:01:57,903:INFO:_display_container: 2
2023-07-31 10:01:58,028:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 10:01:58,029:INFO:create_model() successfully completed......................................
2023-07-31 10:01:58,182:INFO:SubProcess create_model() end ==================================
2023-07-31 10:01:58,182:INFO:Creating metrics dataframe
2023-07-31 10:01:58,194:INFO:Initializing Naive Bayes
2023-07-31 10:01:58,195:INFO:Total runtime is 0.025277634461720787 minutes
2023-07-31 10:01:58,198:INFO:SubProcess create_model() called ==================================
2023-07-31 10:01:58,199:INFO:Initializing create_model()
2023-07-31 10:01:58,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:01:58,199:INFO:Checking exceptions
2023-07-31 10:01:58,199:INFO:Importing libraries
2023-07-31 10:01:58,199:INFO:Copying training dataset
2023-07-31 10:01:58,205:INFO:Defining folds
2023-07-31 10:01:58,205:INFO:Declaring metric variables
2023-07-31 10:01:58,209:INFO:Importing untrained model
2023-07-31 10:01:58,213:INFO:Naive Bayes Imported successfully
2023-07-31 10:01:58,217:INFO:Cross validation set to False
2023-07-31 10:01:58,217:INFO:Fitting Model
2023-07-31 10:01:58,257:INFO:Initializing predict_model()
2023-07-31 10:01:58,257:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f982fb80>)
2023-07-31 10:01:58,257:INFO:Checking exceptions
2023-07-31 10:01:58,257:INFO:Preloading libraries
2023-07-31 10:01:58,484:INFO:_display_container: 2
2023-07-31 10:01:58,606:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 10:01:58,606:INFO:create_model() successfully completed......................................
2023-07-31 10:01:58,718:INFO:SubProcess create_model() end ==================================
2023-07-31 10:01:58,718:INFO:Creating metrics dataframe
2023-07-31 10:01:58,729:INFO:Initializing Decision Tree Classifier
2023-07-31 10:01:58,729:INFO:Total runtime is 0.034184686342875165 minutes
2023-07-31 10:01:58,732:INFO:SubProcess create_model() called ==================================
2023-07-31 10:01:58,733:INFO:Initializing create_model()
2023-07-31 10:01:58,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:01:58,733:INFO:Checking exceptions
2023-07-31 10:01:58,733:INFO:Importing libraries
2023-07-31 10:01:58,733:INFO:Copying training dataset
2023-07-31 10:01:58,739:INFO:Defining folds
2023-07-31 10:01:58,739:INFO:Declaring metric variables
2023-07-31 10:01:58,742:INFO:Importing untrained model
2023-07-31 10:01:58,746:INFO:Decision Tree Classifier Imported successfully
2023-07-31 10:01:58,750:INFO:Cross validation set to False
2023-07-31 10:01:58,750:INFO:Fitting Model
2023-07-31 10:01:58,820:INFO:Initializing predict_model()
2023-07-31 10:01:58,820:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=44, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fa781040>)
2023-07-31 10:01:58,820:INFO:Checking exceptions
2023-07-31 10:01:58,820:INFO:Preloading libraries
2023-07-31 10:01:59,007:INFO:_display_container: 2
2023-07-31 10:01:59,130:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=44, splitter='best')
2023-07-31 10:01:59,130:INFO:create_model() successfully completed......................................
2023-07-31 10:01:59,242:INFO:SubProcess create_model() end ==================================
2023-07-31 10:01:59,243:INFO:Creating metrics dataframe
2023-07-31 10:01:59,254:INFO:Initializing SVM - Linear Kernel
2023-07-31 10:01:59,254:INFO:Total runtime is 0.04293385744094849 minutes
2023-07-31 10:01:59,257:INFO:SubProcess create_model() called ==================================
2023-07-31 10:01:59,258:INFO:Initializing create_model()
2023-07-31 10:01:59,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:01:59,258:INFO:Checking exceptions
2023-07-31 10:01:59,258:INFO:Importing libraries
2023-07-31 10:01:59,258:INFO:Copying training dataset
2023-07-31 10:01:59,263:INFO:Defining folds
2023-07-31 10:01:59,264:INFO:Declaring metric variables
2023-07-31 10:01:59,267:INFO:Importing untrained model
2023-07-31 10:01:59,270:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 10:01:59,275:INFO:Cross validation set to False
2023-07-31 10:01:59,275:INFO:Fitting Model
2023-07-31 10:01:59,320:INFO:Initializing predict_model()
2023-07-31 10:01:59,320:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('actual_estimator',
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=44,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f982fb80>)
2023-07-31 10:01:59,320:INFO:Checking exceptions
2023-07-31 10:01:59,320:INFO:Preloading libraries
2023-07-31 10:01:59,550:INFO:_display_container: 2
2023-07-31 10:01:59,672:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=44, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 10:01:59,672:INFO:create_model() successfully completed......................................
2023-07-31 10:01:59,772:INFO:SubProcess create_model() end ==================================
2023-07-31 10:01:59,772:INFO:Creating metrics dataframe
2023-07-31 10:01:59,784:INFO:Initializing Ridge Classifier
2023-07-31 10:01:59,784:INFO:Total runtime is 0.05176961819330852 minutes
2023-07-31 10:01:59,787:INFO:SubProcess create_model() called ==================================
2023-07-31 10:01:59,788:INFO:Initializing create_model()
2023-07-31 10:01:59,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:01:59,788:INFO:Checking exceptions
2023-07-31 10:01:59,788:INFO:Importing libraries
2023-07-31 10:01:59,788:INFO:Copying training dataset
2023-07-31 10:01:59,793:INFO:Defining folds
2023-07-31 10:01:59,793:INFO:Declaring metric variables
2023-07-31 10:01:59,797:INFO:Importing untrained model
2023-07-31 10:01:59,800:INFO:Ridge Classifier Imported successfully
2023-07-31 10:01:59,804:INFO:Cross validation set to False
2023-07-31 10:01:59,804:INFO:Fitting Model
2023-07-31 10:01:59,865:INFO:Initializing predict_model()
2023-07-31 10:01:59,865:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=44, solver='auto',
                                 tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fa781040>)
2023-07-31 10:01:59,865:INFO:Checking exceptions
2023-07-31 10:01:59,865:INFO:Preloading libraries
2023-07-31 10:02:00,154:INFO:_display_container: 2
2023-07-31 10:02:00,275:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=44, solver='auto',
                tol=0.0001)
2023-07-31 10:02:00,275:INFO:create_model() successfully completed......................................
2023-07-31 10:02:00,376:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:00,376:INFO:Creating metrics dataframe
2023-07-31 10:02:00,388:INFO:Initializing Random Forest Classifier
2023-07-31 10:02:00,388:INFO:Total runtime is 0.06183483997980754 minutes
2023-07-31 10:02:00,391:INFO:SubProcess create_model() called ==================================
2023-07-31 10:02:00,391:INFO:Initializing create_model()
2023-07-31 10:02:00,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:00,392:INFO:Checking exceptions
2023-07-31 10:02:00,392:INFO:Importing libraries
2023-07-31 10:02:00,392:INFO:Copying training dataset
2023-07-31 10:02:00,397:INFO:Defining folds
2023-07-31 10:02:00,397:INFO:Declaring metric variables
2023-07-31 10:02:00,401:INFO:Importing untrained model
2023-07-31 10:02:00,404:INFO:Random Forest Classifier Imported successfully
2023-07-31 10:02:00,408:INFO:Cross validation set to False
2023-07-31 10:02:00,408:INFO:Fitting Model
2023-07-31 10:02:01,075:INFO:Initializing predict_model()
2023-07-31 10:02:01,075:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=44,
                                        verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fb263700>)
2023-07-31 10:02:01,075:INFO:Checking exceptions
2023-07-31 10:02:01,075:INFO:Preloading libraries
2023-07-31 10:02:01,377:INFO:_display_container: 2
2023-07-31 10:02:01,518:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=44, verbose=0, warm_start=False)
2023-07-31 10:02:01,519:INFO:create_model() successfully completed......................................
2023-07-31 10:02:01,624:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:01,625:INFO:Creating metrics dataframe
2023-07-31 10:02:01,637:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 10:02:01,637:INFO:Total runtime is 0.08265141248703003 minutes
2023-07-31 10:02:01,640:INFO:SubProcess create_model() called ==================================
2023-07-31 10:02:01,641:INFO:Initializing create_model()
2023-07-31 10:02:01,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:01,641:INFO:Checking exceptions
2023-07-31 10:02:01,641:INFO:Importing libraries
2023-07-31 10:02:01,641:INFO:Copying training dataset
2023-07-31 10:02:01,647:INFO:Defining folds
2023-07-31 10:02:01,647:INFO:Declaring metric variables
2023-07-31 10:02:01,650:INFO:Importing untrained model
2023-07-31 10:02:01,654:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 10:02:01,658:INFO:Cross validation set to False
2023-07-31 10:02:01,658:INFO:Fitting Model
2023-07-31 10:02:01,740:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:02:01,803:INFO:Initializing predict_model()
2023-07-31 10:02:01,803:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faae1160>)
2023-07-31 10:02:01,803:INFO:Checking exceptions
2023-07-31 10:02:01,803:INFO:Preloading libraries
2023-07-31 10:02:02,107:INFO:_display_container: 2
2023-07-31 10:02:02,229:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 10:02:02,229:INFO:create_model() successfully completed......................................
2023-07-31 10:02:02,329:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:02,330:INFO:Creating metrics dataframe
2023-07-31 10:02:02,342:INFO:Initializing Ada Boost Classifier
2023-07-31 10:02:02,342:INFO:Total runtime is 0.09440174897511801 minutes
2023-07-31 10:02:02,345:INFO:SubProcess create_model() called ==================================
2023-07-31 10:02:02,346:INFO:Initializing create_model()
2023-07-31 10:02:02,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:02,346:INFO:Checking exceptions
2023-07-31 10:02:02,346:INFO:Importing libraries
2023-07-31 10:02:02,346:INFO:Copying training dataset
2023-07-31 10:02:02,351:INFO:Defining folds
2023-07-31 10:02:02,352:INFO:Declaring metric variables
2023-07-31 10:02:02,355:INFO:Importing untrained model
2023-07-31 10:02:02,358:INFO:Ada Boost Classifier Imported successfully
2023-07-31 10:02:02,363:INFO:Cross validation set to False
2023-07-31 10:02:02,363:INFO:Fitting Model
2023-07-31 10:02:03,285:INFO:Initializing predict_model()
2023-07-31 10:02:03,285:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=44))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faae1160>)
2023-07-31 10:02:03,285:INFO:Checking exceptions
2023-07-31 10:02:03,285:INFO:Preloading libraries
2023-07-31 10:02:03,484:INFO:_display_container: 2
2023-07-31 10:02:03,606:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=44)
2023-07-31 10:02:03,606:INFO:create_model() successfully completed......................................
2023-07-31 10:02:03,707:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:03,707:INFO:Creating metrics dataframe
2023-07-31 10:02:03,719:INFO:Initializing Gradient Boosting Classifier
2023-07-31 10:02:03,719:INFO:Total runtime is 0.11736005942026775 minutes
2023-07-31 10:02:03,723:INFO:SubProcess create_model() called ==================================
2023-07-31 10:02:03,723:INFO:Initializing create_model()
2023-07-31 10:02:03,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:03,724:INFO:Checking exceptions
2023-07-31 10:02:03,724:INFO:Importing libraries
2023-07-31 10:02:03,724:INFO:Copying training dataset
2023-07-31 10:02:03,730:INFO:Defining folds
2023-07-31 10:02:03,730:INFO:Declaring metric variables
2023-07-31 10:02:03,733:INFO:Importing untrained model
2023-07-31 10:02:03,737:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 10:02:03,741:INFO:Cross validation set to False
2023-07-31 10:02:03,741:INFO:Fitting Model
2023-07-31 10:02:06,848:INFO:Initializing predict_model()
2023-07-31 10:02:06,848:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=44, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faad4430>)
2023-07-31 10:02:06,848:INFO:Checking exceptions
2023-07-31 10:02:06,848:INFO:Preloading libraries
2023-07-31 10:02:07,031:INFO:_display_container: 2
2023-07-31 10:02:07,152:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=44, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 10:02:07,152:INFO:create_model() successfully completed......................................
2023-07-31 10:02:07,253:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:07,253:INFO:Creating metrics dataframe
2023-07-31 10:02:07,266:INFO:Initializing Linear Discriminant Analysis
2023-07-31 10:02:07,266:INFO:Total runtime is 0.1764722506205241 minutes
2023-07-31 10:02:07,270:INFO:SubProcess create_model() called ==================================
2023-07-31 10:02:07,270:INFO:Initializing create_model()
2023-07-31 10:02:07,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:07,270:INFO:Checking exceptions
2023-07-31 10:02:07,270:INFO:Importing libraries
2023-07-31 10:02:07,270:INFO:Copying training dataset
2023-07-31 10:02:07,276:INFO:Defining folds
2023-07-31 10:02:07,276:INFO:Declaring metric variables
2023-07-31 10:02:07,280:INFO:Importing untrained model
2023-07-31 10:02:07,283:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:02:07,288:INFO:Cross validation set to False
2023-07-31 10:02:07,288:INFO:Fitting Model
2023-07-31 10:02:07,430:INFO:Initializing predict_model()
2023-07-31 10:02:07,430:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faae1790>)
2023-07-31 10:02:07,430:INFO:Checking exceptions
2023-07-31 10:02:07,431:INFO:Preloading libraries
2023-07-31 10:02:07,724:INFO:_display_container: 2
2023-07-31 10:02:07,847:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:02:07,847:INFO:create_model() successfully completed......................................
2023-07-31 10:02:07,947:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:07,947:INFO:Creating metrics dataframe
2023-07-31 10:02:07,960:INFO:Initializing Extra Trees Classifier
2023-07-31 10:02:07,960:INFO:Total runtime is 0.18803283770879112 minutes
2023-07-31 10:02:07,963:INFO:SubProcess create_model() called ==================================
2023-07-31 10:02:07,963:INFO:Initializing create_model()
2023-07-31 10:02:07,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:07,964:INFO:Checking exceptions
2023-07-31 10:02:07,964:INFO:Importing libraries
2023-07-31 10:02:07,964:INFO:Copying training dataset
2023-07-31 10:02:07,969:INFO:Defining folds
2023-07-31 10:02:07,969:INFO:Declaring metric variables
2023-07-31 10:02:07,973:INFO:Importing untrained model
2023-07-31 10:02:07,976:INFO:Extra Trees Classifier Imported successfully
2023-07-31 10:02:07,980:INFO:Cross validation set to False
2023-07-31 10:02:07,980:INFO:Fitting Model
2023-07-31 10:02:08,482:INFO:Initializing predict_model()
2023-07-31 10:02:08,482:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=44,
                                      verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd14f3d30>)
2023-07-31 10:02:08,482:INFO:Checking exceptions
2023-07-31 10:02:08,483:INFO:Preloading libraries
2023-07-31 10:02:08,790:INFO:_display_container: 2
2023-07-31 10:02:08,918:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=44, verbose=0, warm_start=False)
2023-07-31 10:02:08,919:INFO:create_model() successfully completed......................................
2023-07-31 10:02:09,017:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:09,017:INFO:Creating metrics dataframe
2023-07-31 10:02:09,031:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 10:02:09,031:INFO:Total runtime is 0.20588073333104454 minutes
2023-07-31 10:02:09,034:INFO:SubProcess create_model() called ==================================
2023-07-31 10:02:09,034:INFO:Initializing create_model()
2023-07-31 10:02:09,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:09,035:INFO:Checking exceptions
2023-07-31 10:02:09,035:INFO:Importing libraries
2023-07-31 10:02:09,035:INFO:Copying training dataset
2023-07-31 10:02:09,040:INFO:Defining folds
2023-07-31 10:02:09,040:INFO:Declaring metric variables
2023-07-31 10:02:09,044:INFO:Importing untrained model
2023-07-31 10:02:09,047:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 10:02:09,052:INFO:Cross validation set to False
2023-07-31 10:02:09,052:INFO:Fitting Model
2023-07-31 10:02:11,248:INFO:Initializing predict_model()
2023-07-31 10:02:11,249:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=44,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faad43a0>)
2023-07-31 10:02:11,249:INFO:Checking exceptions
2023-07-31 10:02:11,249:INFO:Preloading libraries
2023-07-31 10:02:11,485:INFO:_display_container: 2
2023-07-31 10:02:11,610:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=44, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 10:02:11,610:INFO:create_model() successfully completed......................................
2023-07-31 10:02:11,710:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:11,710:INFO:Creating metrics dataframe
2023-07-31 10:02:11,724:INFO:Initializing Dummy Classifier
2023-07-31 10:02:11,724:INFO:Total runtime is 0.25077242851257325 minutes
2023-07-31 10:02:11,727:INFO:SubProcess create_model() called ==================================
2023-07-31 10:02:11,728:INFO:Initializing create_model()
2023-07-31 10:02:11,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1562a90>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:11,728:INFO:Checking exceptions
2023-07-31 10:02:11,728:INFO:Importing libraries
2023-07-31 10:02:11,728:INFO:Copying training dataset
2023-07-31 10:02:11,733:INFO:Defining folds
2023-07-31 10:02:11,734:INFO:Declaring metric variables
2023-07-31 10:02:11,737:INFO:Importing untrained model
2023-07-31 10:02:11,740:INFO:Dummy Classifier Imported successfully
2023-07-31 10:02:11,745:INFO:Cross validation set to False
2023-07-31 10:02:11,745:INFO:Fitting Model
2023-07-31 10:02:11,780:INFO:Initializing predict_model()
2023-07-31 10:02:11,780:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DummyClassifier(constant=None, random_state=44,
                                 strategy='prior'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd14f3ee0>)
2023-07-31 10:02:11,780:INFO:Checking exceptions
2023-07-31 10:02:11,780:INFO:Preloading libraries
2023-07-31 10:02:11,952:INFO:_display_container: 2
2023-07-31 10:02:12,074:INFO:DummyClassifier(constant=None, random_state=44, strategy='prior')
2023-07-31 10:02:12,074:INFO:create_model() successfully completed......................................
2023-07-31 10:02:12,174:INFO:SubProcess create_model() end ==================================
2023-07-31 10:02:12,175:INFO:Creating metrics dataframe
2023-07-31 10:02:12,197:INFO:Initializing create_model()
2023-07-31 10:02:12,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b338b0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:02:12,197:INFO:Checking exceptions
2023-07-31 10:02:12,199:INFO:Importing libraries
2023-07-31 10:02:12,199:INFO:Copying training dataset
2023-07-31 10:02:12,204:INFO:Defining folds
2023-07-31 10:02:12,204:INFO:Declaring metric variables
2023-07-31 10:02:12,204:INFO:Importing untrained model
2023-07-31 10:02:12,204:INFO:Declaring custom model
2023-07-31 10:02:12,205:INFO:Logistic Regression Imported successfully
2023-07-31 10:02:12,206:INFO:Cross validation set to False
2023-07-31 10:02:12,206:INFO:Fitting Model
2023-07-31 10:02:12,408:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:02:12,408:INFO:create_model() successfully completed......................................
2023-07-31 10:02:12,539:INFO:_master_model_container: 0
2023-07-31 10:02:12,539:INFO:_display_container: 2
2023-07-31 10:02:12,540:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:02:12,540:INFO:compare_models() successfully completed......................................
2023-07-31 10:03:53,673:INFO:Initializing set_config()
2023-07-31 10:03:53,673:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, variable=seed, value=42, kwargs={})
2023-07-31 10:03:53,673:INFO:Global variable: seed updated to 42
2023-07-31 10:03:53,674:INFO:set_config() successfully completed......................................
2023-07-31 10:03:53,803:INFO:PyCaret ClassificationExperiment
2023-07-31 10:03:53,803:INFO:Logging name: clf-default-name
2023-07-31 10:03:53,803:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 10:03:53,803:INFO:version 3.0.2
2023-07-31 10:03:53,803:INFO:Initializing setup()
2023-07-31 10:03:53,803:INFO:self.USI: 407b
2023-07-31 10:03:53,803:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 10:03:53,803:INFO:Checking environment
2023-07-31 10:03:53,803:INFO:python_version: 3.9.16
2023-07-31 10:03:53,803:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 10:03:53,803:INFO:machine: x86_64
2023-07-31 10:03:53,803:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:03:53,804:INFO:Memory: svmem(total=67419119616, available=16961953792, percent=74.8, used=49563475968, free=11931467776, active=46484553728, inactive=6607478784, buffers=55894016, cached=5868281856, shared=200671232, slab=1368096768)
2023-07-31 10:03:53,805:INFO:Physical Core: 28
2023-07-31 10:03:53,805:INFO:Logical Core: 56
2023-07-31 10:03:53,805:INFO:Checking libraries
2023-07-31 10:03:53,805:INFO:System:
2023-07-31 10:03:53,805:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 10:03:53,805:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 10:03:53,805:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:03:53,805:INFO:PyCaret required dependencies:
2023-07-31 10:03:53,806:INFO:                 pip: 23.0.1
2023-07-31 10:03:53,806:INFO:          setuptools: 66.0.0
2023-07-31 10:03:53,806:INFO:             pycaret: 3.0.2
2023-07-31 10:03:53,806:INFO:             IPython: 8.13.2
2023-07-31 10:03:53,806:INFO:          ipywidgets: 8.0.6
2023-07-31 10:03:53,806:INFO:                tqdm: 4.65.0
2023-07-31 10:03:53,806:INFO:               numpy: 1.23.5
2023-07-31 10:03:53,806:INFO:              pandas: 1.5.3
2023-07-31 10:03:53,806:INFO:              jinja2: 3.1.2
2023-07-31 10:03:53,806:INFO:               scipy: 1.10.1
2023-07-31 10:03:53,806:INFO:              joblib: 1.2.0
2023-07-31 10:03:53,806:INFO:             sklearn: 1.2.2
2023-07-31 10:03:53,806:INFO:                pyod: 1.0.9
2023-07-31 10:03:53,806:INFO:            imblearn: 0.10.1
2023-07-31 10:03:53,806:INFO:   category_encoders: 2.6.1
2023-07-31 10:03:53,806:INFO:            lightgbm: 3.3.5
2023-07-31 10:03:53,806:INFO:               numba: 0.57.0
2023-07-31 10:03:53,806:INFO:            requests: 2.28.1
2023-07-31 10:03:53,806:INFO:          matplotlib: 3.7.1
2023-07-31 10:03:53,806:INFO:          scikitplot: 0.3.7
2023-07-31 10:03:53,806:INFO:         yellowbrick: 1.5
2023-07-31 10:03:53,806:INFO:              plotly: 5.14.1
2023-07-31 10:03:53,806:INFO:             kaleido: 0.2.1
2023-07-31 10:03:53,806:INFO:         statsmodels: 0.14.0
2023-07-31 10:03:53,806:INFO:              sktime: 0.17.0
2023-07-31 10:03:53,806:INFO:               tbats: 1.1.3
2023-07-31 10:03:53,806:INFO:            pmdarima: 2.0.3
2023-07-31 10:03:53,806:INFO:              psutil: 5.9.5
2023-07-31 10:03:53,806:INFO:PyCaret optional dependencies:
2023-07-31 10:03:53,806:INFO:                shap: Not installed
2023-07-31 10:03:53,806:INFO:           interpret: Not installed
2023-07-31 10:03:53,806:INFO:                umap: Not installed
2023-07-31 10:03:53,806:INFO:    pandas_profiling: Not installed
2023-07-31 10:03:53,807:INFO:  explainerdashboard: Not installed
2023-07-31 10:03:53,807:INFO:             autoviz: Not installed
2023-07-31 10:03:53,807:INFO:           fairlearn: Not installed
2023-07-31 10:03:53,807:INFO:             xgboost: Not installed
2023-07-31 10:03:53,807:INFO:            catboost: Not installed
2023-07-31 10:03:53,807:INFO:              kmodes: Not installed
2023-07-31 10:03:53,807:INFO:             mlxtend: Not installed
2023-07-31 10:03:53,807:INFO:       statsforecast: Not installed
2023-07-31 10:03:53,807:INFO:        tune_sklearn: Not installed
2023-07-31 10:03:53,807:INFO:                 ray: Not installed
2023-07-31 10:03:53,807:INFO:            hyperopt: Not installed
2023-07-31 10:03:53,807:INFO:              optuna: Not installed
2023-07-31 10:03:53,807:INFO:               skopt: Not installed
2023-07-31 10:03:53,807:INFO:              mlflow: Not installed
2023-07-31 10:03:53,807:INFO:              gradio: Not installed
2023-07-31 10:03:53,807:INFO:             fastapi: Not installed
2023-07-31 10:03:53,807:INFO:             uvicorn: Not installed
2023-07-31 10:03:53,807:INFO:              m2cgen: Not installed
2023-07-31 10:03:53,807:INFO:           evidently: Not installed
2023-07-31 10:03:53,807:INFO:               fugue: Not installed
2023-07-31 10:03:53,807:INFO:           streamlit: Not installed
2023-07-31 10:03:53,807:INFO:             prophet: Not installed
2023-07-31 10:03:53,807:INFO:None
2023-07-31 10:03:53,807:INFO:Set up data.
2023-07-31 10:03:57,526:INFO:Set up train/test split.
2023-07-31 10:03:57,671:INFO:Set up index.
2023-07-31 10:03:57,672:INFO:Set up folding strategy.
2023-07-31 10:03:57,672:INFO:Assigning column types.
2023-07-31 10:03:57,727:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 10:03:57,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:03:57,771:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:03:57,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:57,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:57,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:03:57,844:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:03:57,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:57,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:57,872:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 10:03:57,916:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:03:57,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:57,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:57,987:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:03:58,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:58,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:58,015:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 10:03:58,086:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:58,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:58,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:58,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:03:58,159:INFO:Preparing preprocessing pipeline...
2023-07-31 10:03:58,172:INFO:Set up simple imputation.
2023-07-31 10:03:58,182:INFO:Set up column name cleaning.
2023-07-31 10:03:58,876:INFO:Finished creating preprocessing pipeline.
2023-07-31 10:03:58,941:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 10:03:58,941:INFO:Creating final display dataframe.
2023-07-31 10:04:01,688:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (421, 11886)
4        Transformed data shape      (421, 11886)
5   Transformed train set shape      (336, 11886)
6    Transformed test set shape       (85, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 4
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              407b
2023-07-31 10:04:01,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:04:01,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:04:01,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:04:01,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:04:01,828:INFO:setup() successfully completed in 8.15s...............
2023-07-31 10:04:01,833:INFO:Initializing compare_models()
2023-07-31 10:04:01,833:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 10:04:01,833:INFO:Checking exceptions
2023-07-31 10:04:01,879:INFO:Preparing display monitor
2023-07-31 10:04:01,902:INFO:Initializing Logistic Regression
2023-07-31 10:04:01,902:INFO:Total runtime is 2.944469451904297e-06 minutes
2023-07-31 10:04:01,905:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:01,905:INFO:Initializing create_model()
2023-07-31 10:04:01,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=lr, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:01,906:INFO:Checking exceptions
2023-07-31 10:04:01,906:INFO:Importing libraries
2023-07-31 10:04:01,906:INFO:Copying training dataset
2023-07-31 10:04:01,966:INFO:Defining folds
2023-07-31 10:04:01,966:INFO:Declaring metric variables
2023-07-31 10:04:01,969:INFO:Importing untrained model
2023-07-31 10:04:01,973:INFO:Logistic Regression Imported successfully
2023-07-31 10:04:01,980:INFO:Starting cross validation
2023-07-31 10:04:02,019:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:07,227:INFO:Calculating mean and std
2023-07-31 10:04:07,231:INFO:Creating metrics dataframe
2023-07-31 10:04:07,451:INFO:Uploading results into container
2023-07-31 10:04:07,452:INFO:Uploading model into container now
2023-07-31 10:04:07,452:INFO:_master_model_container: 1
2023-07-31 10:04:07,452:INFO:_display_container: 2
2023-07-31 10:04:07,453:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:04:07,453:INFO:create_model() successfully completed......................................
2023-07-31 10:04:07,596:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:07,596:INFO:Creating metrics dataframe
2023-07-31 10:04:07,607:INFO:Initializing K Neighbors Classifier
2023-07-31 10:04:07,608:INFO:Total runtime is 0.0950990358988444 minutes
2023-07-31 10:04:07,611:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:07,612:INFO:Initializing create_model()
2023-07-31 10:04:07,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=knn, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:07,612:INFO:Checking exceptions
2023-07-31 10:04:07,612:INFO:Importing libraries
2023-07-31 10:04:07,612:INFO:Copying training dataset
2023-07-31 10:04:07,681:INFO:Defining folds
2023-07-31 10:04:07,681:INFO:Declaring metric variables
2023-07-31 10:04:07,686:INFO:Importing untrained model
2023-07-31 10:04:07,690:INFO:K Neighbors Classifier Imported successfully
2023-07-31 10:04:07,698:INFO:Starting cross validation
2023-07-31 10:04:07,740:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:10,688:INFO:Calculating mean and std
2023-07-31 10:04:10,692:INFO:Creating metrics dataframe
2023-07-31 10:04:10,982:INFO:Uploading results into container
2023-07-31 10:04:10,984:INFO:Uploading model into container now
2023-07-31 10:04:10,984:INFO:_master_model_container: 2
2023-07-31 10:04:10,984:INFO:_display_container: 2
2023-07-31 10:04:10,984:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 10:04:10,985:INFO:create_model() successfully completed......................................
2023-07-31 10:04:11,152:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:11,152:INFO:Creating metrics dataframe
2023-07-31 10:04:11,164:INFO:Initializing Naive Bayes
2023-07-31 10:04:11,164:INFO:Total runtime is 0.15437344312667847 minutes
2023-07-31 10:04:11,167:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:11,168:INFO:Initializing create_model()
2023-07-31 10:04:11,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=nb, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:11,168:INFO:Checking exceptions
2023-07-31 10:04:11,168:INFO:Importing libraries
2023-07-31 10:04:11,168:INFO:Copying training dataset
2023-07-31 10:04:11,226:INFO:Defining folds
2023-07-31 10:04:11,227:INFO:Declaring metric variables
2023-07-31 10:04:11,231:INFO:Importing untrained model
2023-07-31 10:04:11,234:INFO:Naive Bayes Imported successfully
2023-07-31 10:04:11,241:INFO:Starting cross validation
2023-07-31 10:04:11,280:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:13,944:INFO:Calculating mean and std
2023-07-31 10:04:13,947:INFO:Creating metrics dataframe
2023-07-31 10:04:14,428:INFO:Uploading results into container
2023-07-31 10:04:14,429:INFO:Uploading model into container now
2023-07-31 10:04:14,430:INFO:_master_model_container: 3
2023-07-31 10:04:14,430:INFO:_display_container: 2
2023-07-31 10:04:14,430:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 10:04:14,430:INFO:create_model() successfully completed......................................
2023-07-31 10:04:14,553:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:14,553:INFO:Creating metrics dataframe
2023-07-31 10:04:14,566:INFO:Initializing Decision Tree Classifier
2023-07-31 10:04:14,566:INFO:Total runtime is 0.21107274691263836 minutes
2023-07-31 10:04:14,571:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:14,571:INFO:Initializing create_model()
2023-07-31 10:04:14,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=dt, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:14,571:INFO:Checking exceptions
2023-07-31 10:04:14,571:INFO:Importing libraries
2023-07-31 10:04:14,571:INFO:Copying training dataset
2023-07-31 10:04:14,639:INFO:Defining folds
2023-07-31 10:04:14,639:INFO:Declaring metric variables
2023-07-31 10:04:14,644:INFO:Importing untrained model
2023-07-31 10:04:14,648:INFO:Decision Tree Classifier Imported successfully
2023-07-31 10:04:14,656:INFO:Starting cross validation
2023-07-31 10:04:14,698:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:17,831:INFO:Calculating mean and std
2023-07-31 10:04:17,833:INFO:Creating metrics dataframe
2023-07-31 10:04:18,329:INFO:Uploading results into container
2023-07-31 10:04:18,330:INFO:Uploading model into container now
2023-07-31 10:04:18,331:INFO:_master_model_container: 4
2023-07-31 10:04:18,331:INFO:_display_container: 2
2023-07-31 10:04:18,331:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 10:04:18,332:INFO:create_model() successfully completed......................................
2023-07-31 10:04:18,481:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:18,482:INFO:Creating metrics dataframe
2023-07-31 10:04:18,494:INFO:Initializing SVM - Linear Kernel
2023-07-31 10:04:18,494:INFO:Total runtime is 0.2765447934468587 minutes
2023-07-31 10:04:18,498:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:18,498:INFO:Initializing create_model()
2023-07-31 10:04:18,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=svm, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:18,498:INFO:Checking exceptions
2023-07-31 10:04:18,498:INFO:Importing libraries
2023-07-31 10:04:18,499:INFO:Copying training dataset
2023-07-31 10:04:18,563:INFO:Defining folds
2023-07-31 10:04:18,563:INFO:Declaring metric variables
2023-07-31 10:04:18,567:INFO:Importing untrained model
2023-07-31 10:04:18,571:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 10:04:18,578:INFO:Starting cross validation
2023-07-31 10:04:18,624:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:20,637:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:04:20,648:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:04:20,721:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:04:20,733:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:04:21,068:INFO:Calculating mean and std
2023-07-31 10:04:21,072:INFO:Creating metrics dataframe
2023-07-31 10:04:21,555:INFO:Uploading results into container
2023-07-31 10:04:21,556:INFO:Uploading model into container now
2023-07-31 10:04:21,557:INFO:_master_model_container: 5
2023-07-31 10:04:21,557:INFO:_display_container: 2
2023-07-31 10:04:21,557:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 10:04:21,558:INFO:create_model() successfully completed......................................
2023-07-31 10:04:21,694:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:21,694:INFO:Creating metrics dataframe
2023-07-31 10:04:21,707:INFO:Initializing Ridge Classifier
2023-07-31 10:04:21,707:INFO:Total runtime is 0.33009453614552814 minutes
2023-07-31 10:04:21,711:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:21,711:INFO:Initializing create_model()
2023-07-31 10:04:21,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=ridge, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:21,711:INFO:Checking exceptions
2023-07-31 10:04:21,711:INFO:Importing libraries
2023-07-31 10:04:21,711:INFO:Copying training dataset
2023-07-31 10:04:21,771:INFO:Defining folds
2023-07-31 10:04:21,771:INFO:Declaring metric variables
2023-07-31 10:04:21,775:INFO:Importing untrained model
2023-07-31 10:04:21,779:INFO:Ridge Classifier Imported successfully
2023-07-31 10:04:21,786:INFO:Starting cross validation
2023-07-31 10:04:21,828:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:23,798:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:04:23,832:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:04:23,836:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:04:23,865:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:04:24,223:INFO:Calculating mean and std
2023-07-31 10:04:24,225:INFO:Creating metrics dataframe
2023-07-31 10:04:24,732:INFO:Uploading results into container
2023-07-31 10:04:24,733:INFO:Uploading model into container now
2023-07-31 10:04:24,733:INFO:_master_model_container: 6
2023-07-31 10:04:24,733:INFO:_display_container: 2
2023-07-31 10:04:24,734:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 10:04:24,734:INFO:create_model() successfully completed......................................
2023-07-31 10:04:24,847:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:24,848:INFO:Creating metrics dataframe
2023-07-31 10:04:24,860:INFO:Initializing Random Forest Classifier
2023-07-31 10:04:24,860:INFO:Total runtime is 0.3826350371042887 minutes
2023-07-31 10:04:24,863:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:24,864:INFO:Initializing create_model()
2023-07-31 10:04:24,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=rf, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:24,864:INFO:Checking exceptions
2023-07-31 10:04:24,864:INFO:Importing libraries
2023-07-31 10:04:24,864:INFO:Copying training dataset
2023-07-31 10:04:24,925:INFO:Defining folds
2023-07-31 10:04:24,925:INFO:Declaring metric variables
2023-07-31 10:04:24,929:INFO:Importing untrained model
2023-07-31 10:04:24,933:INFO:Random Forest Classifier Imported successfully
2023-07-31 10:04:24,941:INFO:Starting cross validation
2023-07-31 10:04:24,983:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:27,364:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:04:27,410:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:04:27,436:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:04:28,519:INFO:Calculating mean and std
2023-07-31 10:04:28,521:INFO:Creating metrics dataframe
2023-07-31 10:04:28,765:INFO:Uploading results into container
2023-07-31 10:04:28,766:INFO:Uploading model into container now
2023-07-31 10:04:28,766:INFO:_master_model_container: 7
2023-07-31 10:04:28,767:INFO:_display_container: 2
2023-07-31 10:04:28,767:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 10:04:28,767:INFO:create_model() successfully completed......................................
2023-07-31 10:04:28,879:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:28,880:INFO:Creating metrics dataframe
2023-07-31 10:04:28,893:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 10:04:28,893:INFO:Total runtime is 0.44985299507776894 minutes
2023-07-31 10:04:28,896:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:28,897:INFO:Initializing create_model()
2023-07-31 10:04:28,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=qda, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:28,897:INFO:Checking exceptions
2023-07-31 10:04:28,897:INFO:Importing libraries
2023-07-31 10:04:28,897:INFO:Copying training dataset
2023-07-31 10:04:28,955:INFO:Defining folds
2023-07-31 10:04:28,955:INFO:Declaring metric variables
2023-07-31 10:04:28,959:INFO:Importing untrained model
2023-07-31 10:04:28,964:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 10:04:28,971:INFO:Starting cross validation
2023-07-31 10:04:29,013:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:29,686:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:04:29,694:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:04:29,700:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:04:29,773:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:04:32,408:INFO:Calculating mean and std
2023-07-31 10:04:32,411:INFO:Creating metrics dataframe
2023-07-31 10:04:32,890:INFO:Uploading results into container
2023-07-31 10:04:32,891:INFO:Uploading model into container now
2023-07-31 10:04:32,891:INFO:_master_model_container: 8
2023-07-31 10:04:32,891:INFO:_display_container: 2
2023-07-31 10:04:32,892:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 10:04:32,892:INFO:create_model() successfully completed......................................
2023-07-31 10:04:33,000:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:33,000:INFO:Creating metrics dataframe
2023-07-31 10:04:33,013:INFO:Initializing Ada Boost Classifier
2023-07-31 10:04:33,013:INFO:Total runtime is 0.5185284415880839 minutes
2023-07-31 10:04:33,017:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:33,017:INFO:Initializing create_model()
2023-07-31 10:04:33,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=ada, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:33,017:INFO:Checking exceptions
2023-07-31 10:04:33,018:INFO:Importing libraries
2023-07-31 10:04:33,018:INFO:Copying training dataset
2023-07-31 10:04:33,077:INFO:Defining folds
2023-07-31 10:04:33,077:INFO:Declaring metric variables
2023-07-31 10:04:33,083:INFO:Importing untrained model
2023-07-31 10:04:33,087:INFO:Ada Boost Classifier Imported successfully
2023-07-31 10:04:33,094:INFO:Starting cross validation
2023-07-31 10:04:33,136:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:04:51,034:INFO:Calculating mean and std
2023-07-31 10:04:51,038:INFO:Creating metrics dataframe
2023-07-31 10:04:51,273:INFO:Uploading results into container
2023-07-31 10:04:51,274:INFO:Uploading model into container now
2023-07-31 10:04:51,274:INFO:_master_model_container: 9
2023-07-31 10:04:51,274:INFO:_display_container: 2
2023-07-31 10:04:51,275:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 10:04:51,275:INFO:create_model() successfully completed......................................
2023-07-31 10:04:51,434:INFO:SubProcess create_model() end ==================================
2023-07-31 10:04:51,435:INFO:Creating metrics dataframe
2023-07-31 10:04:51,448:INFO:Initializing Gradient Boosting Classifier
2023-07-31 10:04:51,448:INFO:Total runtime is 0.8257794062296548 minutes
2023-07-31 10:04:51,452:INFO:SubProcess create_model() called ==================================
2023-07-31 10:04:51,452:INFO:Initializing create_model()
2023-07-31 10:04:51,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=gbc, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:04:51,452:INFO:Checking exceptions
2023-07-31 10:04:51,452:INFO:Importing libraries
2023-07-31 10:04:51,452:INFO:Copying training dataset
2023-07-31 10:04:51,517:INFO:Defining folds
2023-07-31 10:04:51,517:INFO:Declaring metric variables
2023-07-31 10:04:51,522:INFO:Importing untrained model
2023-07-31 10:04:51,526:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 10:04:51,533:INFO:Starting cross validation
2023-07-31 10:04:51,575:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:05:44,971:INFO:Calculating mean and std
2023-07-31 10:05:44,974:INFO:Creating metrics dataframe
2023-07-31 10:05:45,466:INFO:Uploading results into container
2023-07-31 10:05:45,467:INFO:Uploading model into container now
2023-07-31 10:05:45,468:INFO:_master_model_container: 10
2023-07-31 10:05:45,468:INFO:_display_container: 2
2023-07-31 10:05:45,468:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 10:05:45,469:INFO:create_model() successfully completed......................................
2023-07-31 10:05:45,598:INFO:SubProcess create_model() end ==================================
2023-07-31 10:05:45,598:INFO:Creating metrics dataframe
2023-07-31 10:05:45,611:INFO:Initializing Linear Discriminant Analysis
2023-07-31 10:05:45,612:INFO:Total runtime is 1.728499893347422 minutes
2023-07-31 10:05:45,615:INFO:SubProcess create_model() called ==================================
2023-07-31 10:05:45,615:INFO:Initializing create_model()
2023-07-31 10:05:45,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=lda, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:05:45,615:INFO:Checking exceptions
2023-07-31 10:05:45,616:INFO:Importing libraries
2023-07-31 10:05:45,616:INFO:Copying training dataset
2023-07-31 10:05:45,676:INFO:Defining folds
2023-07-31 10:05:45,676:INFO:Declaring metric variables
2023-07-31 10:05:45,680:INFO:Importing untrained model
2023-07-31 10:05:45,683:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:05:45,690:INFO:Starting cross validation
2023-07-31 10:05:45,731:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:05:49,871:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:05:50,484:INFO:Calculating mean and std
2023-07-31 10:05:50,486:INFO:Creating metrics dataframe
2023-07-31 10:05:50,993:INFO:Uploading results into container
2023-07-31 10:05:50,994:INFO:Uploading model into container now
2023-07-31 10:05:50,995:INFO:_master_model_container: 11
2023-07-31 10:05:50,995:INFO:_display_container: 2
2023-07-31 10:05:50,995:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:05:50,995:INFO:create_model() successfully completed......................................
2023-07-31 10:05:51,104:INFO:SubProcess create_model() end ==================================
2023-07-31 10:05:51,104:INFO:Creating metrics dataframe
2023-07-31 10:05:51,117:INFO:Initializing Extra Trees Classifier
2023-07-31 10:05:51,118:INFO:Total runtime is 1.8202666242917376 minutes
2023-07-31 10:05:51,121:INFO:SubProcess create_model() called ==================================
2023-07-31 10:05:51,121:INFO:Initializing create_model()
2023-07-31 10:05:51,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=et, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:05:51,121:INFO:Checking exceptions
2023-07-31 10:05:51,122:INFO:Importing libraries
2023-07-31 10:05:51,122:INFO:Copying training dataset
2023-07-31 10:05:51,179:INFO:Defining folds
2023-07-31 10:05:51,180:INFO:Declaring metric variables
2023-07-31 10:05:51,184:INFO:Importing untrained model
2023-07-31 10:05:51,187:INFO:Extra Trees Classifier Imported successfully
2023-07-31 10:05:51,194:INFO:Starting cross validation
2023-07-31 10:05:51,235:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:05:54,738:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:05:54,743:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:05:54,823:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:05:54,828:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:05:55,919:INFO:Calculating mean and std
2023-07-31 10:05:55,922:INFO:Creating metrics dataframe
2023-07-31 10:05:56,169:INFO:Uploading results into container
2023-07-31 10:05:56,170:INFO:Uploading model into container now
2023-07-31 10:05:56,171:INFO:_master_model_container: 12
2023-07-31 10:05:56,171:INFO:_display_container: 2
2023-07-31 10:05:56,171:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 10:05:56,171:INFO:create_model() successfully completed......................................
2023-07-31 10:05:56,295:INFO:SubProcess create_model() end ==================================
2023-07-31 10:05:56,296:INFO:Creating metrics dataframe
2023-07-31 10:05:56,310:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 10:05:56,310:INFO:Total runtime is 1.9068121592203773 minutes
2023-07-31 10:05:56,314:INFO:SubProcess create_model() called ==================================
2023-07-31 10:05:56,315:INFO:Initializing create_model()
2023-07-31 10:05:56,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=lightgbm, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:05:56,315:INFO:Checking exceptions
2023-07-31 10:05:56,315:INFO:Importing libraries
2023-07-31 10:05:56,315:INFO:Copying training dataset
2023-07-31 10:05:56,382:INFO:Defining folds
2023-07-31 10:05:56,382:INFO:Declaring metric variables
2023-07-31 10:05:56,387:INFO:Importing untrained model
2023-07-31 10:05:56,391:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 10:05:56,401:INFO:Starting cross validation
2023-07-31 10:05:56,490:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:06:30,889:INFO:Calculating mean and std
2023-07-31 10:06:30,893:INFO:Creating metrics dataframe
2023-07-31 10:06:31,396:INFO:Uploading results into container
2023-07-31 10:06:31,397:INFO:Uploading model into container now
2023-07-31 10:06:31,398:INFO:_master_model_container: 13
2023-07-31 10:06:31,398:INFO:_display_container: 2
2023-07-31 10:06:31,399:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 10:06:31,399:INFO:create_model() successfully completed......................................
2023-07-31 10:06:31,576:INFO:SubProcess create_model() end ==================================
2023-07-31 10:06:31,576:INFO:Creating metrics dataframe
2023-07-31 10:06:31,592:INFO:Initializing Dummy Classifier
2023-07-31 10:06:31,592:INFO:Total runtime is 2.4948454499244686 minutes
2023-07-31 10:06:31,597:INFO:SubProcess create_model() called ==================================
2023-07-31 10:06:31,597:INFO:Initializing create_model()
2023-07-31 10:06:31,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=dummy, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd0a7c700>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:06:31,597:INFO:Checking exceptions
2023-07-31 10:06:31,597:INFO:Importing libraries
2023-07-31 10:06:31,597:INFO:Copying training dataset
2023-07-31 10:06:31,672:INFO:Defining folds
2023-07-31 10:06:31,672:INFO:Declaring metric variables
2023-07-31 10:06:31,677:INFO:Importing untrained model
2023-07-31 10:06:31,682:INFO:Dummy Classifier Imported successfully
2023-07-31 10:06:31,689:INFO:Starting cross validation
2023-07-31 10:06:31,734:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:06:35,474:INFO:Calculating mean and std
2023-07-31 10:06:35,476:INFO:Creating metrics dataframe
2023-07-31 10:06:35,737:INFO:Uploading results into container
2023-07-31 10:06:35,738:INFO:Uploading model into container now
2023-07-31 10:06:35,739:INFO:_master_model_container: 14
2023-07-31 10:06:35,739:INFO:_display_container: 2
2023-07-31 10:06:35,739:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 10:06:35,739:INFO:create_model() successfully completed......................................
2023-07-31 10:06:35,894:INFO:SubProcess create_model() end ==================================
2023-07-31 10:06:35,895:INFO:Creating metrics dataframe
2023-07-31 10:06:35,921:INFO:Initializing create_model()
2023-07-31 10:06:35,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd14e6460>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:06:35,921:INFO:Checking exceptions
2023-07-31 10:06:35,923:INFO:Importing libraries
2023-07-31 10:06:35,923:INFO:Copying training dataset
2023-07-31 10:06:36,000:INFO:Defining folds
2023-07-31 10:06:36,000:INFO:Declaring metric variables
2023-07-31 10:06:36,000:INFO:Importing untrained model
2023-07-31 10:06:36,000:INFO:Declaring custom model
2023-07-31 10:06:36,001:INFO:Ridge Classifier Imported successfully
2023-07-31 10:06:36,045:INFO:Cross validation set to False
2023-07-31 10:06:36,045:INFO:Fitting Model
2023-07-31 10:06:37,653:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 10:06:37,653:INFO:create_model() successfully completed......................................
2023-07-31 10:06:37,873:INFO:_master_model_container: 14
2023-07-31 10:06:37,873:INFO:_display_container: 2
2023-07-31 10:06:37,874:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 10:06:37,874:INFO:compare_models() successfully completed......................................
2023-07-31 10:06:41,160:INFO:Initializing set_config()
2023-07-31 10:06:41,160:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, variable=seed, value=42, kwargs={})
2023-07-31 10:06:41,161:INFO:Global variable: seed updated to 42
2023-07-31 10:06:41,161:INFO:set_config() successfully completed......................................
2023-07-31 10:06:41,311:INFO:PyCaret ClassificationExperiment
2023-07-31 10:06:41,311:INFO:Logging name: clf-default-name
2023-07-31 10:06:41,311:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 10:06:41,311:INFO:version 3.0.2
2023-07-31 10:06:41,311:INFO:Initializing setup()
2023-07-31 10:06:41,311:INFO:self.USI: fdd5
2023-07-31 10:06:41,311:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 10:06:41,311:INFO:Checking environment
2023-07-31 10:06:41,311:INFO:python_version: 3.9.16
2023-07-31 10:06:41,311:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 10:06:41,311:INFO:machine: x86_64
2023-07-31 10:06:41,311:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:06:41,311:INFO:Memory: svmem(total=67419119616, available=5263572992, percent=92.2, used=61262639104, free=385572864, active=58403954688, inactive=6295556096, buffers=57720832, cached=5713186816, shared=200740864, slab=1396162560)
2023-07-31 10:06:41,313:INFO:Physical Core: 28
2023-07-31 10:06:41,314:INFO:Logical Core: 56
2023-07-31 10:06:41,314:INFO:Checking libraries
2023-07-31 10:06:41,314:INFO:System:
2023-07-31 10:06:41,314:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 10:06:41,314:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 10:06:41,314:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:06:41,314:INFO:PyCaret required dependencies:
2023-07-31 10:06:41,314:INFO:                 pip: 23.0.1
2023-07-31 10:06:41,314:INFO:          setuptools: 66.0.0
2023-07-31 10:06:41,314:INFO:             pycaret: 3.0.2
2023-07-31 10:06:41,314:INFO:             IPython: 8.13.2
2023-07-31 10:06:41,314:INFO:          ipywidgets: 8.0.6
2023-07-31 10:06:41,314:INFO:                tqdm: 4.65.0
2023-07-31 10:06:41,314:INFO:               numpy: 1.23.5
2023-07-31 10:06:41,314:INFO:              pandas: 1.5.3
2023-07-31 10:06:41,314:INFO:              jinja2: 3.1.2
2023-07-31 10:06:41,314:INFO:               scipy: 1.10.1
2023-07-31 10:06:41,314:INFO:              joblib: 1.2.0
2023-07-31 10:06:41,314:INFO:             sklearn: 1.2.2
2023-07-31 10:06:41,314:INFO:                pyod: 1.0.9
2023-07-31 10:06:41,314:INFO:            imblearn: 0.10.1
2023-07-31 10:06:41,314:INFO:   category_encoders: 2.6.1
2023-07-31 10:06:41,314:INFO:            lightgbm: 3.3.5
2023-07-31 10:06:41,314:INFO:               numba: 0.57.0
2023-07-31 10:06:41,314:INFO:            requests: 2.28.1
2023-07-31 10:06:41,314:INFO:          matplotlib: 3.7.1
2023-07-31 10:06:41,314:INFO:          scikitplot: 0.3.7
2023-07-31 10:06:41,314:INFO:         yellowbrick: 1.5
2023-07-31 10:06:41,315:INFO:              plotly: 5.14.1
2023-07-31 10:06:41,315:INFO:             kaleido: 0.2.1
2023-07-31 10:06:41,315:INFO:         statsmodels: 0.14.0
2023-07-31 10:06:41,315:INFO:              sktime: 0.17.0
2023-07-31 10:06:41,315:INFO:               tbats: 1.1.3
2023-07-31 10:06:41,315:INFO:            pmdarima: 2.0.3
2023-07-31 10:06:41,315:INFO:              psutil: 5.9.5
2023-07-31 10:06:41,315:INFO:PyCaret optional dependencies:
2023-07-31 10:06:41,315:INFO:                shap: Not installed
2023-07-31 10:06:41,315:INFO:           interpret: Not installed
2023-07-31 10:06:41,315:INFO:                umap: Not installed
2023-07-31 10:06:41,315:INFO:    pandas_profiling: Not installed
2023-07-31 10:06:41,315:INFO:  explainerdashboard: Not installed
2023-07-31 10:06:41,315:INFO:             autoviz: Not installed
2023-07-31 10:06:41,315:INFO:           fairlearn: Not installed
2023-07-31 10:06:41,315:INFO:             xgboost: Not installed
2023-07-31 10:06:41,315:INFO:            catboost: Not installed
2023-07-31 10:06:41,315:INFO:              kmodes: Not installed
2023-07-31 10:06:41,315:INFO:             mlxtend: Not installed
2023-07-31 10:06:41,315:INFO:       statsforecast: Not installed
2023-07-31 10:06:41,315:INFO:        tune_sklearn: Not installed
2023-07-31 10:06:41,315:INFO:                 ray: Not installed
2023-07-31 10:06:41,315:INFO:            hyperopt: Not installed
2023-07-31 10:06:41,315:INFO:              optuna: Not installed
2023-07-31 10:06:41,315:INFO:               skopt: Not installed
2023-07-31 10:06:41,315:INFO:              mlflow: Not installed
2023-07-31 10:06:41,315:INFO:              gradio: Not installed
2023-07-31 10:06:41,315:INFO:             fastapi: Not installed
2023-07-31 10:06:41,315:INFO:             uvicorn: Not installed
2023-07-31 10:06:41,315:INFO:              m2cgen: Not installed
2023-07-31 10:06:41,315:INFO:           evidently: Not installed
2023-07-31 10:06:41,315:INFO:               fugue: Not installed
2023-07-31 10:06:41,316:INFO:           streamlit: Not installed
2023-07-31 10:06:41,316:INFO:             prophet: Not installed
2023-07-31 10:06:41,316:INFO:None
2023-07-31 10:06:41,316:INFO:Set up data.
2023-07-31 10:06:45,813:INFO:Set up train/test split.
2023-07-31 10:06:46,017:INFO:Set up index.
2023-07-31 10:06:46,018:INFO:Set up folding strategy.
2023-07-31 10:06:46,019:INFO:Assigning column types.
2023-07-31 10:06:46,168:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 10:06:46,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:06:46,214:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:06:46,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,243:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:06:46,289:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:06:46,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,318:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 10:06:46,364:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:06:46,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,439:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:06:46,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,468:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 10:06:46,542:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:46,619:INFO:Preparing preprocessing pipeline...
2023-07-31 10:06:46,644:INFO:Set up simple imputation.
2023-07-31 10:06:46,667:INFO:Set up column name cleaning.
2023-07-31 10:06:47,858:INFO:Finished creating preprocessing pipeline.
2023-07-31 10:06:47,928:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 10:06:47,928:INFO:Creating final display dataframe.
2023-07-31 10:06:51,176:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (742, 11886)
4        Transformed data shape      (742, 11886)
5   Transformed train set shape      (593, 11886)
6    Transformed test set shape      (149, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 4
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              fdd5
2023-07-31 10:06:51,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:51,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:51,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:51,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:06:51,327:INFO:setup() successfully completed in 10.17s...............
2023-07-31 10:06:51,334:INFO:Initializing compare_models()
2023-07-31 10:06:51,334:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 10:06:51,334:INFO:Checking exceptions
2023-07-31 10:06:51,428:INFO:Preparing display monitor
2023-07-31 10:06:51,451:INFO:Initializing Logistic Regression
2023-07-31 10:06:51,451:INFO:Total runtime is 3.4570693969726562e-06 minutes
2023-07-31 10:06:51,455:INFO:SubProcess create_model() called ==================================
2023-07-31 10:06:51,455:INFO:Initializing create_model()
2023-07-31 10:06:51,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=lr, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:06:51,455:INFO:Checking exceptions
2023-07-31 10:06:51,455:INFO:Importing libraries
2023-07-31 10:06:51,456:INFO:Copying training dataset
2023-07-31 10:06:51,596:INFO:Defining folds
2023-07-31 10:06:51,596:INFO:Declaring metric variables
2023-07-31 10:06:51,600:INFO:Importing untrained model
2023-07-31 10:06:51,604:INFO:Logistic Regression Imported successfully
2023-07-31 10:06:51,611:INFO:Starting cross validation
2023-07-31 10:06:51,655:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:06:59,278:INFO:Calculating mean and std
2023-07-31 10:06:59,280:INFO:Creating metrics dataframe
2023-07-31 10:06:59,797:INFO:Uploading results into container
2023-07-31 10:06:59,798:INFO:Uploading model into container now
2023-07-31 10:06:59,799:INFO:_master_model_container: 1
2023-07-31 10:06:59,799:INFO:_display_container: 2
2023-07-31 10:06:59,799:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:06:59,799:INFO:create_model() successfully completed......................................
2023-07-31 10:06:59,962:INFO:SubProcess create_model() end ==================================
2023-07-31 10:06:59,962:INFO:Creating metrics dataframe
2023-07-31 10:06:59,973:INFO:Initializing K Neighbors Classifier
2023-07-31 10:06:59,973:INFO:Total runtime is 0.14203506310780842 minutes
2023-07-31 10:06:59,977:INFO:SubProcess create_model() called ==================================
2023-07-31 10:06:59,977:INFO:Initializing create_model()
2023-07-31 10:06:59,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=knn, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:06:59,977:INFO:Checking exceptions
2023-07-31 10:06:59,977:INFO:Importing libraries
2023-07-31 10:06:59,978:INFO:Copying training dataset
2023-07-31 10:07:00,108:INFO:Defining folds
2023-07-31 10:07:00,108:INFO:Declaring metric variables
2023-07-31 10:07:00,112:INFO:Importing untrained model
2023-07-31 10:07:00,116:INFO:K Neighbors Classifier Imported successfully
2023-07-31 10:07:00,122:INFO:Starting cross validation
2023-07-31 10:07:00,163:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:07:02,037:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:07:03,213:INFO:Calculating mean and std
2023-07-31 10:07:03,215:INFO:Creating metrics dataframe
2023-07-31 10:07:03,453:INFO:Uploading results into container
2023-07-31 10:07:03,454:INFO:Uploading model into container now
2023-07-31 10:07:03,455:INFO:_master_model_container: 2
2023-07-31 10:07:03,455:INFO:_display_container: 2
2023-07-31 10:07:03,455:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 10:07:03,455:INFO:create_model() successfully completed......................................
2023-07-31 10:07:03,583:INFO:SubProcess create_model() end ==================================
2023-07-31 10:07:03,583:INFO:Creating metrics dataframe
2023-07-31 10:07:03,595:INFO:Initializing Naive Bayes
2023-07-31 10:07:03,595:INFO:Total runtime is 0.2023905038833618 minutes
2023-07-31 10:07:03,598:INFO:SubProcess create_model() called ==================================
2023-07-31 10:07:03,599:INFO:Initializing create_model()
2023-07-31 10:07:03,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=nb, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:07:03,599:INFO:Checking exceptions
2023-07-31 10:07:03,599:INFO:Importing libraries
2023-07-31 10:07:03,599:INFO:Copying training dataset
2023-07-31 10:07:03,732:INFO:Defining folds
2023-07-31 10:07:03,732:INFO:Declaring metric variables
2023-07-31 10:07:03,736:INFO:Importing untrained model
2023-07-31 10:07:03,740:INFO:Naive Bayes Imported successfully
2023-07-31 10:07:03,747:INFO:Starting cross validation
2023-07-31 10:07:03,788:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:07:05,727:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:07:05,759:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:07:05,812:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:07:06,659:INFO:Calculating mean and std
2023-07-31 10:07:06,661:INFO:Creating metrics dataframe
2023-07-31 10:07:06,894:INFO:Uploading results into container
2023-07-31 10:07:06,895:INFO:Uploading model into container now
2023-07-31 10:07:06,895:INFO:_master_model_container: 3
2023-07-31 10:07:06,895:INFO:_display_container: 2
2023-07-31 10:07:06,896:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 10:07:06,896:INFO:create_model() successfully completed......................................
2023-07-31 10:07:07,014:INFO:SubProcess create_model() end ==================================
2023-07-31 10:07:07,014:INFO:Creating metrics dataframe
2023-07-31 10:07:07,026:INFO:Initializing Decision Tree Classifier
2023-07-31 10:07:07,026:INFO:Total runtime is 0.2595788796742757 minutes
2023-07-31 10:07:07,030:INFO:SubProcess create_model() called ==================================
2023-07-31 10:07:07,030:INFO:Initializing create_model()
2023-07-31 10:07:07,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=dt, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:07:07,031:INFO:Checking exceptions
2023-07-31 10:07:07,031:INFO:Importing libraries
2023-07-31 10:07:07,031:INFO:Copying training dataset
2023-07-31 10:07:07,163:INFO:Defining folds
2023-07-31 10:07:07,163:INFO:Declaring metric variables
2023-07-31 10:07:07,167:INFO:Importing untrained model
2023-07-31 10:07:07,171:INFO:Decision Tree Classifier Imported successfully
2023-07-31 10:07:07,178:INFO:Starting cross validation
2023-07-31 10:07:07,219:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:07:11,148:INFO:Calculating mean and std
2023-07-31 10:07:11,152:INFO:Creating metrics dataframe
2023-07-31 10:07:11,669:INFO:Uploading results into container
2023-07-31 10:07:11,671:INFO:Uploading model into container now
2023-07-31 10:07:11,672:INFO:_master_model_container: 4
2023-07-31 10:07:11,672:INFO:_display_container: 2
2023-07-31 10:07:11,672:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 10:07:11,672:INFO:create_model() successfully completed......................................
2023-07-31 10:07:11,885:INFO:SubProcess create_model() end ==================================
2023-07-31 10:07:11,885:INFO:Creating metrics dataframe
2023-07-31 10:07:11,908:INFO:Initializing SVM - Linear Kernel
2023-07-31 10:07:11,908:INFO:Total runtime is 0.340943968296051 minutes
2023-07-31 10:07:11,914:INFO:SubProcess create_model() called ==================================
2023-07-31 10:07:11,915:INFO:Initializing create_model()
2023-07-31 10:07:11,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=svm, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:07:11,915:INFO:Checking exceptions
2023-07-31 10:07:11,916:INFO:Importing libraries
2023-07-31 10:07:11,916:INFO:Copying training dataset
2023-07-31 10:07:12,161:INFO:Defining folds
2023-07-31 10:07:12,161:INFO:Declaring metric variables
2023-07-31 10:07:12,168:INFO:Importing untrained model
2023-07-31 10:07:12,174:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 10:07:12,185:INFO:Starting cross validation
2023-07-31 10:07:12,232:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:07:14,580:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:07:14,616:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:07:14,664:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:07:15,193:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:07:15,204:INFO:Calculating mean and std
2023-07-31 10:07:15,207:INFO:Creating metrics dataframe
2023-07-31 10:07:15,748:INFO:Uploading results into container
2023-07-31 10:07:15,749:INFO:Uploading model into container now
2023-07-31 10:07:15,750:INFO:_master_model_container: 5
2023-07-31 10:07:15,750:INFO:_display_container: 2
2023-07-31 10:07:15,751:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 10:07:15,751:INFO:create_model() successfully completed......................................
2023-07-31 10:07:15,924:INFO:SubProcess create_model() end ==================================
2023-07-31 10:07:15,925:INFO:Creating metrics dataframe
2023-07-31 10:07:15,937:INFO:Initializing Ridge Classifier
2023-07-31 10:07:15,937:INFO:Total runtime is 0.40809175968170164 minutes
2023-07-31 10:07:15,940:INFO:SubProcess create_model() called ==================================
2023-07-31 10:07:15,941:INFO:Initializing create_model()
2023-07-31 10:07:15,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=ridge, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:07:15,941:INFO:Checking exceptions
2023-07-31 10:07:15,941:INFO:Importing libraries
2023-07-31 10:07:15,941:INFO:Copying training dataset
2023-07-31 10:07:16,082:INFO:Defining folds
2023-07-31 10:07:16,082:INFO:Declaring metric variables
2023-07-31 10:07:16,086:INFO:Importing untrained model
2023-07-31 10:07:16,090:INFO:Ridge Classifier Imported successfully
2023-07-31 10:07:16,097:INFO:Starting cross validation
2023-07-31 10:07:16,137:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:07:18,083:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:07:18,117:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:07:18,149:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:07:18,185:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:07:18,674:INFO:Calculating mean and std
2023-07-31 10:07:18,677:INFO:Creating metrics dataframe
2023-07-31 10:07:18,910:INFO:Uploading results into container
2023-07-31 10:07:18,911:INFO:Uploading model into container now
2023-07-31 10:07:18,912:INFO:_master_model_container: 6
2023-07-31 10:07:18,912:INFO:_display_container: 2
2023-07-31 10:07:18,912:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 10:07:18,913:INFO:create_model() successfully completed......................................
2023-07-31 10:07:19,076:INFO:SubProcess create_model() end ==================================
2023-07-31 10:07:19,076:INFO:Creating metrics dataframe
2023-07-31 10:07:19,089:INFO:Initializing Random Forest Classifier
2023-07-31 10:07:19,089:INFO:Total runtime is 0.460625151793162 minutes
2023-07-31 10:07:19,092:INFO:SubProcess create_model() called ==================================
2023-07-31 10:07:19,093:INFO:Initializing create_model()
2023-07-31 10:07:19,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=rf, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:07:19,093:INFO:Checking exceptions
2023-07-31 10:07:19,093:INFO:Importing libraries
2023-07-31 10:07:19,093:INFO:Copying training dataset
2023-07-31 10:07:19,236:INFO:Defining folds
2023-07-31 10:07:19,237:INFO:Declaring metric variables
2023-07-31 10:07:19,241:INFO:Importing untrained model
2023-07-31 10:07:19,245:INFO:Random Forest Classifier Imported successfully
2023-07-31 10:07:19,251:INFO:Starting cross validation
2023-07-31 10:07:19,290:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:07:21,683:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:07:21,702:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:07:21,762:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:07:22,833:INFO:Calculating mean and std
2023-07-31 10:07:22,836:INFO:Creating metrics dataframe
2023-07-31 10:07:23,084:INFO:Uploading results into container
2023-07-31 10:07:23,085:INFO:Uploading model into container now
2023-07-31 10:07:23,085:INFO:_master_model_container: 7
2023-07-31 10:07:23,086:INFO:_display_container: 2
2023-07-31 10:07:23,086:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 10:07:23,086:INFO:create_model() successfully completed......................................
2023-07-31 10:07:23,261:INFO:SubProcess create_model() end ==================================
2023-07-31 10:07:23,261:INFO:Creating metrics dataframe
2023-07-31 10:07:23,276:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 10:07:23,276:INFO:Total runtime is 0.5304189602533976 minutes
2023-07-31 10:07:23,281:INFO:SubProcess create_model() called ==================================
2023-07-31 10:07:23,281:INFO:Initializing create_model()
2023-07-31 10:07:23,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=qda, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:07:23,281:INFO:Checking exceptions
2023-07-31 10:07:23,281:INFO:Importing libraries
2023-07-31 10:07:23,281:INFO:Copying training dataset
2023-07-31 10:07:23,425:INFO:Defining folds
2023-07-31 10:07:23,425:INFO:Declaring metric variables
2023-07-31 10:07:23,430:INFO:Importing untrained model
2023-07-31 10:07:23,433:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 10:07:23,440:INFO:Starting cross validation
2023-07-31 10:07:23,481:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:07:24,863:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:07:24,942:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:07:24,985:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:07:25,001:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:07:27,751:INFO:Calculating mean and std
2023-07-31 10:07:27,755:INFO:Creating metrics dataframe
2023-07-31 10:07:28,024:INFO:Uploading results into container
2023-07-31 10:07:28,026:INFO:Uploading model into container now
2023-07-31 10:07:28,027:INFO:_master_model_container: 8
2023-07-31 10:07:28,027:INFO:_display_container: 2
2023-07-31 10:07:28,028:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 10:07:28,028:INFO:create_model() successfully completed......................................
2023-07-31 10:07:28,204:INFO:SubProcess create_model() end ==================================
2023-07-31 10:07:28,205:INFO:Creating metrics dataframe
2023-07-31 10:07:28,219:INFO:Initializing Ada Boost Classifier
2023-07-31 10:07:28,219:INFO:Total runtime is 0.6127911766370138 minutes
2023-07-31 10:07:28,222:INFO:SubProcess create_model() called ==================================
2023-07-31 10:07:28,223:INFO:Initializing create_model()
2023-07-31 10:07:28,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=ada, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:07:28,223:INFO:Checking exceptions
2023-07-31 10:07:28,223:INFO:Importing libraries
2023-07-31 10:07:28,223:INFO:Copying training dataset
2023-07-31 10:07:28,355:INFO:Defining folds
2023-07-31 10:07:28,355:INFO:Declaring metric variables
2023-07-31 10:07:28,359:INFO:Importing untrained model
2023-07-31 10:07:28,363:INFO:Ada Boost Classifier Imported successfully
2023-07-31 10:07:28,369:INFO:Starting cross validation
2023-07-31 10:07:28,434:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:07:59,068:INFO:Calculating mean and std
2023-07-31 10:07:59,071:INFO:Creating metrics dataframe
2023-07-31 10:07:59,595:INFO:Uploading results into container
2023-07-31 10:07:59,597:INFO:Uploading model into container now
2023-07-31 10:07:59,597:INFO:_master_model_container: 9
2023-07-31 10:07:59,597:INFO:_display_container: 2
2023-07-31 10:07:59,598:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 10:07:59,598:INFO:create_model() successfully completed......................................
2023-07-31 10:07:59,755:INFO:SubProcess create_model() end ==================================
2023-07-31 10:07:59,756:INFO:Creating metrics dataframe
2023-07-31 10:07:59,771:INFO:Initializing Gradient Boosting Classifier
2023-07-31 10:07:59,771:INFO:Total runtime is 1.138666252295176 minutes
2023-07-31 10:07:59,775:INFO:SubProcess create_model() called ==================================
2023-07-31 10:07:59,775:INFO:Initializing create_model()
2023-07-31 10:07:59,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=gbc, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:07:59,776:INFO:Checking exceptions
2023-07-31 10:07:59,776:INFO:Importing libraries
2023-07-31 10:07:59,776:INFO:Copying training dataset
2023-07-31 10:07:59,909:INFO:Defining folds
2023-07-31 10:07:59,909:INFO:Declaring metric variables
2023-07-31 10:07:59,914:INFO:Importing untrained model
2023-07-31 10:07:59,917:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 10:07:59,924:INFO:Starting cross validation
2023-07-31 10:07:59,967:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:09:59,801:INFO:Calculating mean and std
2023-07-31 10:09:59,804:INFO:Creating metrics dataframe
2023-07-31 10:10:00,113:INFO:Uploading results into container
2023-07-31 10:10:00,115:INFO:Uploading model into container now
2023-07-31 10:10:00,116:INFO:_master_model_container: 10
2023-07-31 10:10:00,116:INFO:_display_container: 2
2023-07-31 10:10:00,116:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 10:10:00,117:INFO:create_model() successfully completed......................................
2023-07-31 10:10:00,272:INFO:SubProcess create_model() end ==================================
2023-07-31 10:10:00,272:INFO:Creating metrics dataframe
2023-07-31 10:10:00,287:INFO:Initializing Linear Discriminant Analysis
2023-07-31 10:10:00,287:INFO:Total runtime is 3.147262970606486 minutes
2023-07-31 10:10:00,291:INFO:SubProcess create_model() called ==================================
2023-07-31 10:10:00,291:INFO:Initializing create_model()
2023-07-31 10:10:00,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=lda, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:10:00,291:INFO:Checking exceptions
2023-07-31 10:10:00,291:INFO:Importing libraries
2023-07-31 10:10:00,291:INFO:Copying training dataset
2023-07-31 10:10:00,422:INFO:Defining folds
2023-07-31 10:10:00,422:INFO:Declaring metric variables
2023-07-31 10:10:00,426:INFO:Importing untrained model
2023-07-31 10:10:00,430:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:10:00,437:INFO:Starting cross validation
2023-07-31 10:10:00,478:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:10:05,475:INFO:Calculating mean and std
2023-07-31 10:10:05,479:INFO:Creating metrics dataframe
2023-07-31 10:10:05,964:INFO:Uploading results into container
2023-07-31 10:10:05,965:INFO:Uploading model into container now
2023-07-31 10:10:05,966:INFO:_master_model_container: 11
2023-07-31 10:10:05,966:INFO:_display_container: 2
2023-07-31 10:10:05,966:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:10:05,966:INFO:create_model() successfully completed......................................
2023-07-31 10:10:06,109:INFO:SubProcess create_model() end ==================================
2023-07-31 10:10:06,109:INFO:Creating metrics dataframe
2023-07-31 10:10:06,124:INFO:Initializing Extra Trees Classifier
2023-07-31 10:10:06,124:INFO:Total runtime is 3.2445518175760903 minutes
2023-07-31 10:10:06,128:INFO:SubProcess create_model() called ==================================
2023-07-31 10:10:06,129:INFO:Initializing create_model()
2023-07-31 10:10:06,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=et, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:10:06,129:INFO:Checking exceptions
2023-07-31 10:10:06,129:INFO:Importing libraries
2023-07-31 10:10:06,129:INFO:Copying training dataset
2023-07-31 10:10:06,259:INFO:Defining folds
2023-07-31 10:10:06,259:INFO:Declaring metric variables
2023-07-31 10:10:06,264:INFO:Importing untrained model
2023-07-31 10:10:06,268:INFO:Extra Trees Classifier Imported successfully
2023-07-31 10:10:06,275:INFO:Starting cross validation
2023-07-31 10:10:06,317:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:10:08,650:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:10:08,696:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:10:08,852:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:10:09,850:INFO:Calculating mean and std
2023-07-31 10:10:09,854:INFO:Creating metrics dataframe
2023-07-31 10:10:10,118:INFO:Uploading results into container
2023-07-31 10:10:10,119:INFO:Uploading model into container now
2023-07-31 10:10:10,120:INFO:_master_model_container: 12
2023-07-31 10:10:10,120:INFO:_display_container: 2
2023-07-31 10:10:10,120:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 10:10:10,121:INFO:create_model() successfully completed......................................
2023-07-31 10:10:10,286:INFO:SubProcess create_model() end ==================================
2023-07-31 10:10:10,286:INFO:Creating metrics dataframe
2023-07-31 10:10:10,301:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 10:10:10,301:INFO:Total runtime is 3.3141642014185586 minutes
2023-07-31 10:10:10,305:INFO:SubProcess create_model() called ==================================
2023-07-31 10:10:10,305:INFO:Initializing create_model()
2023-07-31 10:10:10,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=lightgbm, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:10:10,305:INFO:Checking exceptions
2023-07-31 10:10:10,305:INFO:Importing libraries
2023-07-31 10:10:10,305:INFO:Copying training dataset
2023-07-31 10:10:10,442:INFO:Defining folds
2023-07-31 10:10:10,442:INFO:Declaring metric variables
2023-07-31 10:10:10,446:INFO:Importing untrained model
2023-07-31 10:10:10,450:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 10:10:10,456:INFO:Starting cross validation
2023-07-31 10:10:10,498:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:11:12,343:INFO:Calculating mean and std
2023-07-31 10:11:12,347:INFO:Creating metrics dataframe
2023-07-31 10:11:12,873:INFO:Uploading results into container
2023-07-31 10:11:12,874:INFO:Uploading model into container now
2023-07-31 10:11:12,874:INFO:_master_model_container: 13
2023-07-31 10:11:12,874:INFO:_display_container: 2
2023-07-31 10:11:12,875:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 10:11:12,875:INFO:create_model() successfully completed......................................
2023-07-31 10:11:13,028:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:13,028:INFO:Creating metrics dataframe
2023-07-31 10:11:13,043:INFO:Initializing Dummy Classifier
2023-07-31 10:11:13,043:INFO:Total runtime is 4.359868391354879 minutes
2023-07-31 10:11:13,047:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:13,047:INFO:Initializing create_model()
2023-07-31 10:11:13,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=dummy, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd14bfcd0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:13,048:INFO:Checking exceptions
2023-07-31 10:11:13,048:INFO:Importing libraries
2023-07-31 10:11:13,048:INFO:Copying training dataset
2023-07-31 10:11:13,180:INFO:Defining folds
2023-07-31 10:11:13,180:INFO:Declaring metric variables
2023-07-31 10:11:13,185:INFO:Importing untrained model
2023-07-31 10:11:13,189:INFO:Dummy Classifier Imported successfully
2023-07-31 10:11:13,196:INFO:Starting cross validation
2023-07-31 10:11:13,238:INFO:Cross validating with KFold(n_splits=4, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:11:15,213:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:11:15,237:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:11:15,265:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:11:15,729:INFO:Calculating mean and std
2023-07-31 10:11:15,732:INFO:Creating metrics dataframe
2023-07-31 10:11:15,969:INFO:Uploading results into container
2023-07-31 10:11:15,970:INFO:Uploading model into container now
2023-07-31 10:11:15,971:INFO:_master_model_container: 14
2023-07-31 10:11:15,971:INFO:_display_container: 2
2023-07-31 10:11:15,971:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 10:11:15,971:INFO:create_model() successfully completed......................................
2023-07-31 10:11:16,096:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:16,096:INFO:Creating metrics dataframe
2023-07-31 10:11:16,120:INFO:Initializing create_model()
2023-07-31 10:11:16,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b0f9a0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:16,120:INFO:Checking exceptions
2023-07-31 10:11:16,122:INFO:Importing libraries
2023-07-31 10:11:16,122:INFO:Copying training dataset
2023-07-31 10:11:16,252:INFO:Defining folds
2023-07-31 10:11:16,252:INFO:Declaring metric variables
2023-07-31 10:11:16,252:INFO:Importing untrained model
2023-07-31 10:11:16,252:INFO:Declaring custom model
2023-07-31 10:11:16,253:INFO:Logistic Regression Imported successfully
2023-07-31 10:11:16,294:INFO:Cross validation set to False
2023-07-31 10:11:16,294:INFO:Fitting Model
2023-07-31 10:11:26,384:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:11:26,384:INFO:create_model() successfully completed......................................
2023-07-31 10:11:26,593:INFO:_master_model_container: 14
2023-07-31 10:11:26,593:INFO:_display_container: 2
2023-07-31 10:11:26,593:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:11:26,593:INFO:compare_models() successfully completed......................................
2023-07-31 10:11:26,680:INFO:Initializing set_config()
2023-07-31 10:11:26,680:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, variable=seed, value=42, kwargs={})
2023-07-31 10:11:26,680:INFO:Global variable: seed updated to 42
2023-07-31 10:11:26,680:INFO:set_config() successfully completed......................................
2023-07-31 10:11:26,819:INFO:PyCaret ClassificationExperiment
2023-07-31 10:11:26,819:INFO:Logging name: clf-default-name
2023-07-31 10:11:26,819:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 10:11:26,819:INFO:version 3.0.2
2023-07-31 10:11:26,819:INFO:Initializing setup()
2023-07-31 10:11:26,819:INFO:self.USI: 26f6
2023-07-31 10:11:26,819:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 10:11:26,819:INFO:Checking environment
2023-07-31 10:11:26,819:INFO:python_version: 3.9.16
2023-07-31 10:11:26,819:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 10:11:26,820:INFO:machine: x86_64
2023-07-31 10:11:26,820:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:11:26,820:INFO:Memory: svmem(total=67419119616, available=7635292160, percent=88.7, used=58866520064, free=4480319488, active=55409729536, inactive=5106012160, buffers=55365632, cached=4016914432, shared=224763904, slab=1393586176)
2023-07-31 10:11:26,822:INFO:Physical Core: 28
2023-07-31 10:11:26,822:INFO:Logical Core: 56
2023-07-31 10:11:26,822:INFO:Checking libraries
2023-07-31 10:11:26,822:INFO:System:
2023-07-31 10:11:26,822:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 10:11:26,822:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 10:11:26,822:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:11:26,822:INFO:PyCaret required dependencies:
2023-07-31 10:11:26,822:INFO:                 pip: 23.0.1
2023-07-31 10:11:26,822:INFO:          setuptools: 66.0.0
2023-07-31 10:11:26,822:INFO:             pycaret: 3.0.2
2023-07-31 10:11:26,822:INFO:             IPython: 8.13.2
2023-07-31 10:11:26,822:INFO:          ipywidgets: 8.0.6
2023-07-31 10:11:26,822:INFO:                tqdm: 4.65.0
2023-07-31 10:11:26,822:INFO:               numpy: 1.23.5
2023-07-31 10:11:26,822:INFO:              pandas: 1.5.3
2023-07-31 10:11:26,822:INFO:              jinja2: 3.1.2
2023-07-31 10:11:26,822:INFO:               scipy: 1.10.1
2023-07-31 10:11:26,822:INFO:              joblib: 1.2.0
2023-07-31 10:11:26,822:INFO:             sklearn: 1.2.2
2023-07-31 10:11:26,822:INFO:                pyod: 1.0.9
2023-07-31 10:11:26,822:INFO:            imblearn: 0.10.1
2023-07-31 10:11:26,822:INFO:   category_encoders: 2.6.1
2023-07-31 10:11:26,822:INFO:            lightgbm: 3.3.5
2023-07-31 10:11:26,822:INFO:               numba: 0.57.0
2023-07-31 10:11:26,823:INFO:            requests: 2.28.1
2023-07-31 10:11:26,823:INFO:          matplotlib: 3.7.1
2023-07-31 10:11:26,823:INFO:          scikitplot: 0.3.7
2023-07-31 10:11:26,823:INFO:         yellowbrick: 1.5
2023-07-31 10:11:26,823:INFO:              plotly: 5.14.1
2023-07-31 10:11:26,823:INFO:             kaleido: 0.2.1
2023-07-31 10:11:26,823:INFO:         statsmodels: 0.14.0
2023-07-31 10:11:26,823:INFO:              sktime: 0.17.0
2023-07-31 10:11:26,823:INFO:               tbats: 1.1.3
2023-07-31 10:11:26,823:INFO:            pmdarima: 2.0.3
2023-07-31 10:11:26,823:INFO:              psutil: 5.9.5
2023-07-31 10:11:26,823:INFO:PyCaret optional dependencies:
2023-07-31 10:11:26,823:INFO:                shap: Not installed
2023-07-31 10:11:26,823:INFO:           interpret: Not installed
2023-07-31 10:11:26,823:INFO:                umap: Not installed
2023-07-31 10:11:26,823:INFO:    pandas_profiling: Not installed
2023-07-31 10:11:26,823:INFO:  explainerdashboard: Not installed
2023-07-31 10:11:26,823:INFO:             autoviz: Not installed
2023-07-31 10:11:26,823:INFO:           fairlearn: Not installed
2023-07-31 10:11:26,823:INFO:             xgboost: Not installed
2023-07-31 10:11:26,823:INFO:            catboost: Not installed
2023-07-31 10:11:26,823:INFO:              kmodes: Not installed
2023-07-31 10:11:26,823:INFO:             mlxtend: Not installed
2023-07-31 10:11:26,823:INFO:       statsforecast: Not installed
2023-07-31 10:11:26,823:INFO:        tune_sklearn: Not installed
2023-07-31 10:11:26,823:INFO:                 ray: Not installed
2023-07-31 10:11:26,823:INFO:            hyperopt: Not installed
2023-07-31 10:11:26,823:INFO:              optuna: Not installed
2023-07-31 10:11:26,823:INFO:               skopt: Not installed
2023-07-31 10:11:26,823:INFO:              mlflow: Not installed
2023-07-31 10:11:26,823:INFO:              gradio: Not installed
2023-07-31 10:11:26,823:INFO:             fastapi: Not installed
2023-07-31 10:11:26,823:INFO:             uvicorn: Not installed
2023-07-31 10:11:26,823:INFO:              m2cgen: Not installed
2023-07-31 10:11:26,824:INFO:           evidently: Not installed
2023-07-31 10:11:26,824:INFO:               fugue: Not installed
2023-07-31 10:11:26,824:INFO:           streamlit: Not installed
2023-07-31 10:11:26,824:INFO:             prophet: Not installed
2023-07-31 10:11:26,824:INFO:None
2023-07-31 10:11:26,824:INFO:Set up data.
2023-07-31 10:11:26,909:INFO:Set up train/test split.
2023-07-31 10:11:26,916:INFO:Set up index.
2023-07-31 10:11:26,916:INFO:Set up folding strategy.
2023-07-31 10:11:26,917:INFO:Assigning column types.
2023-07-31 10:11:26,921:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 10:11:26,966:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:11:26,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:11:26,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:26,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,042:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:11:27,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:11:27,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,072:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 10:11:27,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:11:27,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:11:27,221:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,222:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 10:11:27,303:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,379:INFO:Preparing preprocessing pipeline...
2023-07-31 10:11:27,381:INFO:Set up simple imputation.
2023-07-31 10:11:27,415:INFO:Finished creating preprocessing pipeline.
2023-07-31 10:11:27,421:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-07-31 10:11:27,421:INFO:Creating final display dataframe.
2023-07-31 10:11:27,562:INFO:Setup _display_container:                     Description             Value
0                    Session id                44
1                        Target             group
2                   Target type            Binary
3           Original data shape        (742, 294)
4        Transformed data shape        (742, 294)
5   Transformed train set shape        (593, 294)
6    Transformed test set shape        (149, 294)
7              Numeric features               293
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 4
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              26f6
2023-07-31 10:11:27,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:11:27,714:INFO:setup() successfully completed in 1.03s...............
2023-07-31 10:11:27,721:INFO:Initializing compare_models()
2023-07-31 10:11:27,721:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, include=None, fold=None, round=4, cross_validation=False, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': False, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 10:11:27,721:INFO:Checking exceptions
2023-07-31 10:11:27,728:INFO:Preparing display monitor
2023-07-31 10:11:27,754:INFO:Initializing Logistic Regression
2023-07-31 10:11:27,754:INFO:Total runtime is 3.4570693969726562e-06 minutes
2023-07-31 10:11:27,758:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:27,758:INFO:Initializing create_model()
2023-07-31 10:11:27,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=lr, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:27,758:INFO:Checking exceptions
2023-07-31 10:11:27,758:INFO:Importing libraries
2023-07-31 10:11:27,758:INFO:Copying training dataset
2023-07-31 10:11:27,764:INFO:Defining folds
2023-07-31 10:11:27,764:INFO:Declaring metric variables
2023-07-31 10:11:27,768:INFO:Importing untrained model
2023-07-31 10:11:27,772:INFO:Logistic Regression Imported successfully
2023-07-31 10:11:27,776:INFO:Cross validation set to False
2023-07-31 10:11:27,777:INFO:Fitting Model
2023-07-31 10:11:27,888:INFO:Initializing predict_model()
2023-07-31 10:11:27,889:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=44,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fbc829d0>)
2023-07-31 10:11:27,889:INFO:Checking exceptions
2023-07-31 10:11:27,889:INFO:Preloading libraries
2023-07-31 10:11:28,271:INFO:_display_container: 2
2023-07-31 10:11:28,416:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:11:28,416:INFO:create_model() successfully completed......................................
2023-07-31 10:11:28,608:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:28,609:INFO:Creating metrics dataframe
2023-07-31 10:11:28,621:INFO:Initializing K Neighbors Classifier
2023-07-31 10:11:28,621:INFO:Total runtime is 0.014454702536265055 minutes
2023-07-31 10:11:28,625:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:28,625:INFO:Initializing create_model()
2023-07-31 10:11:28,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=knn, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:28,625:INFO:Checking exceptions
2023-07-31 10:11:28,625:INFO:Importing libraries
2023-07-31 10:11:28,625:INFO:Copying training dataset
2023-07-31 10:11:28,632:INFO:Defining folds
2023-07-31 10:11:28,632:INFO:Declaring metric variables
2023-07-31 10:11:28,635:INFO:Importing untrained model
2023-07-31 10:11:28,639:INFO:K Neighbors Classifier Imported successfully
2023-07-31 10:11:28,645:INFO:Cross validation set to False
2023-07-31 10:11:28,645:INFO:Fitting Model
2023-07-31 10:11:28,687:INFO:Initializing predict_model()
2023-07-31 10:11:28,687:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faae1ca0>)
2023-07-31 10:11:28,687:INFO:Checking exceptions
2023-07-31 10:11:28,687:INFO:Preloading libraries
2023-07-31 10:11:29,054:INFO:_display_container: 2
2023-07-31 10:11:29,188:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 10:11:29,189:INFO:create_model() successfully completed......................................
2023-07-31 10:11:29,347:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:29,348:INFO:Creating metrics dataframe
2023-07-31 10:11:29,360:INFO:Initializing Naive Bayes
2023-07-31 10:11:29,360:INFO:Total runtime is 0.02677402893702189 minutes
2023-07-31 10:11:29,364:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:29,364:INFO:Initializing create_model()
2023-07-31 10:11:29,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=nb, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:29,364:INFO:Checking exceptions
2023-07-31 10:11:29,364:INFO:Importing libraries
2023-07-31 10:11:29,364:INFO:Copying training dataset
2023-07-31 10:11:29,370:INFO:Defining folds
2023-07-31 10:11:29,371:INFO:Declaring metric variables
2023-07-31 10:11:29,375:INFO:Importing untrained model
2023-07-31 10:11:29,378:INFO:Naive Bayes Imported successfully
2023-07-31 10:11:29,383:INFO:Cross validation set to False
2023-07-31 10:11:29,384:INFO:Fitting Model
2023-07-31 10:11:29,426:INFO:Initializing predict_model()
2023-07-31 10:11:29,426:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f9439d30>)
2023-07-31 10:11:29,426:INFO:Checking exceptions
2023-07-31 10:11:29,426:INFO:Preloading libraries
2023-07-31 10:11:29,677:INFO:_display_container: 2
2023-07-31 10:11:29,817:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 10:11:29,817:INFO:create_model() successfully completed......................................
2023-07-31 10:11:29,984:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:29,984:INFO:Creating metrics dataframe
2023-07-31 10:11:29,997:INFO:Initializing Decision Tree Classifier
2023-07-31 10:11:29,997:INFO:Total runtime is 0.03739093939463298 minutes
2023-07-31 10:11:30,001:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:30,001:INFO:Initializing create_model()
2023-07-31 10:11:30,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=dt, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:30,001:INFO:Checking exceptions
2023-07-31 10:11:30,001:INFO:Importing libraries
2023-07-31 10:11:30,001:INFO:Copying training dataset
2023-07-31 10:11:30,008:INFO:Defining folds
2023-07-31 10:11:30,008:INFO:Declaring metric variables
2023-07-31 10:11:30,013:INFO:Importing untrained model
2023-07-31 10:11:30,018:INFO:Decision Tree Classifier Imported successfully
2023-07-31 10:11:30,023:INFO:Cross validation set to False
2023-07-31 10:11:30,023:INFO:Fitting Model
2023-07-31 10:11:30,132:INFO:Initializing predict_model()
2023-07-31 10:11:30,133:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=44, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faab6c10>)
2023-07-31 10:11:30,133:INFO:Checking exceptions
2023-07-31 10:11:30,133:INFO:Preloading libraries
2023-07-31 10:11:30,400:INFO:_display_container: 2
2023-07-31 10:11:30,546:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=44, splitter='best')
2023-07-31 10:11:30,547:INFO:create_model() successfully completed......................................
2023-07-31 10:11:30,696:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:30,697:INFO:Creating metrics dataframe
2023-07-31 10:11:30,709:INFO:Initializing SVM - Linear Kernel
2023-07-31 10:11:30,709:INFO:Total runtime is 0.049259130160013834 minutes
2023-07-31 10:11:30,713:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:30,713:INFO:Initializing create_model()
2023-07-31 10:11:30,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=svm, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:30,713:INFO:Checking exceptions
2023-07-31 10:11:30,713:INFO:Importing libraries
2023-07-31 10:11:30,713:INFO:Copying training dataset
2023-07-31 10:11:30,719:INFO:Defining folds
2023-07-31 10:11:30,719:INFO:Declaring metric variables
2023-07-31 10:11:30,723:INFO:Importing untrained model
2023-07-31 10:11:30,727:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 10:11:30,732:INFO:Cross validation set to False
2023-07-31 10:11:30,732:INFO:Fitting Model
2023-07-31 10:11:30,784:INFO:Initializing predict_model()
2023-07-31 10:11:30,784:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('actual_estimator',
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=44,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f95b7ee0>)
2023-07-31 10:11:30,784:INFO:Checking exceptions
2023-07-31 10:11:30,784:INFO:Preloading libraries
2023-07-31 10:11:31,053:INFO:_display_container: 2
2023-07-31 10:11:31,191:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=44, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 10:11:31,192:INFO:create_model() successfully completed......................................
2023-07-31 10:11:31,315:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:31,315:INFO:Creating metrics dataframe
2023-07-31 10:11:31,340:INFO:Initializing Ridge Classifier
2023-07-31 10:11:31,340:INFO:Total runtime is 0.059780863920847575 minutes
2023-07-31 10:11:31,347:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:31,348:INFO:Initializing create_model()
2023-07-31 10:11:31,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=ridge, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:31,348:INFO:Checking exceptions
2023-07-31 10:11:31,348:INFO:Importing libraries
2023-07-31 10:11:31,349:INFO:Copying training dataset
2023-07-31 10:11:31,359:INFO:Defining folds
2023-07-31 10:11:31,360:INFO:Declaring metric variables
2023-07-31 10:11:31,367:INFO:Importing untrained model
2023-07-31 10:11:31,371:INFO:Ridge Classifier Imported successfully
2023-07-31 10:11:31,377:INFO:Cross validation set to False
2023-07-31 10:11:31,377:INFO:Fitting Model
2023-07-31 10:11:31,720:INFO:Initializing predict_model()
2023-07-31 10:11:31,720:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=44, solver='auto',
                                 tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f90b8af0>)
2023-07-31 10:11:31,720:INFO:Checking exceptions
2023-07-31 10:11:31,720:INFO:Preloading libraries
2023-07-31 10:11:31,988:INFO:_display_container: 2
2023-07-31 10:11:32,170:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=44, solver='auto',
                tol=0.0001)
2023-07-31 10:11:32,171:INFO:create_model() successfully completed......................................
2023-07-31 10:11:32,314:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:32,314:INFO:Creating metrics dataframe
2023-07-31 10:11:32,327:INFO:Initializing Random Forest Classifier
2023-07-31 10:11:32,327:INFO:Total runtime is 0.07622454961140951 minutes
2023-07-31 10:11:32,331:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:32,331:INFO:Initializing create_model()
2023-07-31 10:11:32,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=rf, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:32,331:INFO:Checking exceptions
2023-07-31 10:11:32,331:INFO:Importing libraries
2023-07-31 10:11:32,331:INFO:Copying training dataset
2023-07-31 10:11:32,337:INFO:Defining folds
2023-07-31 10:11:32,337:INFO:Declaring metric variables
2023-07-31 10:11:32,341:INFO:Importing untrained model
2023-07-31 10:11:32,344:INFO:Random Forest Classifier Imported successfully
2023-07-31 10:11:32,349:INFO:Cross validation set to False
2023-07-31 10:11:32,349:INFO:Fitting Model
2023-07-31 10:11:33,024:INFO:Initializing predict_model()
2023-07-31 10:11:33,024:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=44,
                                        verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f9439a60>)
2023-07-31 10:11:33,024:INFO:Checking exceptions
2023-07-31 10:11:33,024:INFO:Preloading libraries
2023-07-31 10:11:33,412:INFO:_display_container: 2
2023-07-31 10:11:33,577:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=44, verbose=0, warm_start=False)
2023-07-31 10:11:33,577:INFO:create_model() successfully completed......................................
2023-07-31 10:11:33,731:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:33,731:INFO:Creating metrics dataframe
2023-07-31 10:11:33,744:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 10:11:33,745:INFO:Total runtime is 0.09985087315241496 minutes
2023-07-31 10:11:33,748:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:33,749:INFO:Initializing create_model()
2023-07-31 10:11:33,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=qda, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:33,749:INFO:Checking exceptions
2023-07-31 10:11:33,749:INFO:Importing libraries
2023-07-31 10:11:33,749:INFO:Copying training dataset
2023-07-31 10:11:33,755:INFO:Defining folds
2023-07-31 10:11:33,756:INFO:Declaring metric variables
2023-07-31 10:11:33,760:INFO:Importing untrained model
2023-07-31 10:11:33,763:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 10:11:33,769:INFO:Cross validation set to False
2023-07-31 10:11:33,769:INFO:Fitting Model
2023-07-31 10:11:33,870:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:11:34,102:INFO:Initializing predict_model()
2023-07-31 10:11:34,102:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f99a5c10>)
2023-07-31 10:11:34,102:INFO:Checking exceptions
2023-07-31 10:11:34,102:INFO:Preloading libraries
2023-07-31 10:11:34,365:INFO:_display_container: 2
2023-07-31 10:11:34,502:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 10:11:34,503:INFO:create_model() successfully completed......................................
2023-07-31 10:11:34,617:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:34,617:INFO:Creating metrics dataframe
2023-07-31 10:11:34,630:INFO:Initializing Ada Boost Classifier
2023-07-31 10:11:34,631:INFO:Total runtime is 0.11461738348007203 minutes
2023-07-31 10:11:34,634:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:34,634:INFO:Initializing create_model()
2023-07-31 10:11:34,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=ada, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:34,634:INFO:Checking exceptions
2023-07-31 10:11:34,635:INFO:Importing libraries
2023-07-31 10:11:34,635:INFO:Copying training dataset
2023-07-31 10:11:34,641:INFO:Defining folds
2023-07-31 10:11:34,641:INFO:Declaring metric variables
2023-07-31 10:11:34,645:INFO:Importing untrained model
2023-07-31 10:11:34,649:INFO:Ada Boost Classifier Imported successfully
2023-07-31 10:11:34,655:INFO:Cross validation set to False
2023-07-31 10:11:34,655:INFO:Fitting Model
2023-07-31 10:11:35,783:INFO:Initializing predict_model()
2023-07-31 10:11:35,783:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=44))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f99a5310>)
2023-07-31 10:11:35,783:INFO:Checking exceptions
2023-07-31 10:11:35,783:INFO:Preloading libraries
2023-07-31 10:11:36,027:INFO:_display_container: 2
2023-07-31 10:11:36,157:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=44)
2023-07-31 10:11:36,157:INFO:create_model() successfully completed......................................
2023-07-31 10:11:36,323:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:36,323:INFO:Creating metrics dataframe
2023-07-31 10:11:36,337:INFO:Initializing Gradient Boosting Classifier
2023-07-31 10:11:36,337:INFO:Total runtime is 0.14305818875630696 minutes
2023-07-31 10:11:36,341:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:36,341:INFO:Initializing create_model()
2023-07-31 10:11:36,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=gbc, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:36,341:INFO:Checking exceptions
2023-07-31 10:11:36,341:INFO:Importing libraries
2023-07-31 10:11:36,341:INFO:Copying training dataset
2023-07-31 10:11:36,347:INFO:Defining folds
2023-07-31 10:11:36,348:INFO:Declaring metric variables
2023-07-31 10:11:36,352:INFO:Importing untrained model
2023-07-31 10:11:36,355:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 10:11:36,360:INFO:Cross validation set to False
2023-07-31 10:11:36,360:INFO:Fitting Model
2023-07-31 10:11:40,592:INFO:Initializing predict_model()
2023-07-31 10:11:40,592:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=44, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f9439f70>)
2023-07-31 10:11:40,592:INFO:Checking exceptions
2023-07-31 10:11:40,592:INFO:Preloading libraries
2023-07-31 10:11:40,816:INFO:_display_container: 2
2023-07-31 10:11:40,962:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=44, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 10:11:40,962:INFO:create_model() successfully completed......................................
2023-07-31 10:11:41,092:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:41,092:INFO:Creating metrics dataframe
2023-07-31 10:11:41,107:INFO:Initializing Linear Discriminant Analysis
2023-07-31 10:11:41,107:INFO:Total runtime is 0.22256417671839396 minutes
2023-07-31 10:11:41,112:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:41,113:INFO:Initializing create_model()
2023-07-31 10:11:41,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=lda, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:41,113:INFO:Checking exceptions
2023-07-31 10:11:41,113:INFO:Importing libraries
2023-07-31 10:11:41,113:INFO:Copying training dataset
2023-07-31 10:11:41,120:INFO:Defining folds
2023-07-31 10:11:41,120:INFO:Declaring metric variables
2023-07-31 10:11:41,125:INFO:Importing untrained model
2023-07-31 10:11:41,130:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:11:41,135:INFO:Cross validation set to False
2023-07-31 10:11:41,135:INFO:Fitting Model
2023-07-31 10:11:41,513:INFO:Initializing predict_model()
2023-07-31 10:11:41,513:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faae1280>)
2023-07-31 10:11:41,513:INFO:Checking exceptions
2023-07-31 10:11:41,514:INFO:Preloading libraries
2023-07-31 10:11:41,799:INFO:_display_container: 2
2023-07-31 10:11:41,944:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:11:41,944:INFO:create_model() successfully completed......................................
2023-07-31 10:11:42,070:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:42,070:INFO:Creating metrics dataframe
2023-07-31 10:11:42,084:INFO:Initializing Extra Trees Classifier
2023-07-31 10:11:42,084:INFO:Total runtime is 0.23884567419687908 minutes
2023-07-31 10:11:42,088:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:42,088:INFO:Initializing create_model()
2023-07-31 10:11:42,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=et, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:42,088:INFO:Checking exceptions
2023-07-31 10:11:42,089:INFO:Importing libraries
2023-07-31 10:11:42,089:INFO:Copying training dataset
2023-07-31 10:11:42,095:INFO:Defining folds
2023-07-31 10:11:42,095:INFO:Declaring metric variables
2023-07-31 10:11:42,099:INFO:Importing untrained model
2023-07-31 10:11:42,103:INFO:Extra Trees Classifier Imported successfully
2023-07-31 10:11:42,107:INFO:Cross validation set to False
2023-07-31 10:11:42,107:INFO:Fitting Model
2023-07-31 10:11:42,662:INFO:Initializing predict_model()
2023-07-31 10:11:42,662:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=44,
                                      verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faae1ca0>)
2023-07-31 10:11:42,663:INFO:Checking exceptions
2023-07-31 10:11:42,663:INFO:Preloading libraries
2023-07-31 10:11:43,027:INFO:_display_container: 2
2023-07-31 10:11:43,174:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=44, verbose=0, warm_start=False)
2023-07-31 10:11:43,174:INFO:create_model() successfully completed......................................
2023-07-31 10:11:43,301:INFO:SubProcess create_model() end ==================================
2023-07-31 10:11:43,302:INFO:Creating metrics dataframe
2023-07-31 10:11:43,316:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 10:11:43,316:INFO:Total runtime is 0.2593771696090698 minutes
2023-07-31 10:11:43,320:INFO:SubProcess create_model() called ==================================
2023-07-31 10:11:43,320:INFO:Initializing create_model()
2023-07-31 10:11:43,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=lightgbm, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:11:43,320:INFO:Checking exceptions
2023-07-31 10:11:43,320:INFO:Importing libraries
2023-07-31 10:11:43,321:INFO:Copying training dataset
2023-07-31 10:11:43,327:INFO:Defining folds
2023-07-31 10:11:43,328:INFO:Declaring metric variables
2023-07-31 10:11:43,331:INFO:Importing untrained model
2023-07-31 10:11:43,335:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 10:11:43,340:INFO:Cross validation set to False
2023-07-31 10:11:43,340:INFO:Fitting Model
2023-07-31 10:12:24,757:INFO:Initializing predict_model()
2023-07-31 10:12:24,757:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=44,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f95b78b0>)
2023-07-31 10:12:24,758:INFO:Checking exceptions
2023-07-31 10:12:24,758:INFO:Preloading libraries
2023-07-31 10:12:25,102:INFO:_display_container: 2
2023-07-31 10:12:25,297:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=44, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 10:12:25,297:INFO:create_model() successfully completed......................................
2023-07-31 10:12:25,462:INFO:SubProcess create_model() end ==================================
2023-07-31 10:12:25,462:INFO:Creating metrics dataframe
2023-07-31 10:12:25,480:INFO:Initializing Dummy Classifier
2023-07-31 10:12:25,480:INFO:Total runtime is 0.9621155341466268 minutes
2023-07-31 10:12:25,485:INFO:SubProcess create_model() called ==================================
2023-07-31 10:12:25,486:INFO:Initializing create_model()
2023-07-31 10:12:25,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=dummy, fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f90ab190>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:12:25,486:INFO:Checking exceptions
2023-07-31 10:12:25,486:INFO:Importing libraries
2023-07-31 10:12:25,486:INFO:Copying training dataset
2023-07-31 10:12:25,494:INFO:Defining folds
2023-07-31 10:12:25,494:INFO:Declaring metric variables
2023-07-31 10:12:25,499:INFO:Importing untrained model
2023-07-31 10:12:25,505:INFO:Dummy Classifier Imported successfully
2023-07-31 10:12:25,512:INFO:Cross validation set to False
2023-07-31 10:12:25,512:INFO:Fitting Model
2023-07-31 10:12:25,558:INFO:Initializing predict_model()
2023-07-31 10:12:25,558:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DummyClassifier(constant=None, random_state=44,
                                 strategy='prior'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fbe95430>)
2023-07-31 10:12:25,558:INFO:Checking exceptions
2023-07-31 10:12:25,558:INFO:Preloading libraries
2023-07-31 10:12:25,808:INFO:_display_container: 2
2023-07-31 10:12:25,955:INFO:DummyClassifier(constant=None, random_state=44, strategy='prior')
2023-07-31 10:12:25,955:INFO:create_model() successfully completed......................................
2023-07-31 10:12:26,116:INFO:SubProcess create_model() end ==================================
2023-07-31 10:12:26,116:INFO:Creating metrics dataframe
2023-07-31 10:12:26,148:INFO:Initializing create_model()
2023-07-31 10:12:26,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f956ea30>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=4, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:12:26,148:INFO:Checking exceptions
2023-07-31 10:12:26,151:INFO:Importing libraries
2023-07-31 10:12:26,151:INFO:Copying training dataset
2023-07-31 10:12:26,158:INFO:Defining folds
2023-07-31 10:12:26,158:INFO:Declaring metric variables
2023-07-31 10:12:26,158:INFO:Importing untrained model
2023-07-31 10:12:26,158:INFO:Declaring custom model
2023-07-31 10:12:26,159:INFO:Logistic Regression Imported successfully
2023-07-31 10:12:26,160:INFO:Cross validation set to False
2023-07-31 10:12:26,160:INFO:Fitting Model
2023-07-31 10:12:26,471:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:12:26,471:INFO:create_model() successfully completed......................................
2023-07-31 10:12:26,674:INFO:_master_model_container: 0
2023-07-31 10:12:26,674:INFO:_display_container: 2
2023-07-31 10:12:26,675:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:12:26,675:INFO:compare_models() successfully completed......................................
2023-07-31 10:33:55,847:INFO:Initializing set_config()
2023-07-31 10:33:55,863:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, variable=seed, value=42, kwargs={})
2023-07-31 10:33:55,863:INFO:Global variable: seed updated to 42
2023-07-31 10:33:55,863:INFO:set_config() successfully completed......................................
2023-07-31 10:33:55,999:INFO:PyCaret ClassificationExperiment
2023-07-31 10:33:55,999:INFO:Logging name: clf-default-name
2023-07-31 10:33:55,999:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 10:33:55,999:INFO:version 3.0.2
2023-07-31 10:33:55,999:INFO:Initializing setup()
2023-07-31 10:33:55,999:INFO:self.USI: 4630
2023-07-31 10:33:55,999:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 10:33:55,999:INFO:Checking environment
2023-07-31 10:33:55,999:INFO:python_version: 3.9.16
2023-07-31 10:33:55,999:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 10:33:55,999:INFO:machine: x86_64
2023-07-31 10:33:55,999:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:33:56,000:INFO:Memory: svmem(total=67419119616, available=23037157376, percent=65.8, used=43506233344, free=19196301312, active=40029171712, inactive=5854679040, buffers=59113472, cached=4657471488, shared=181407744, slab=1359994880)
2023-07-31 10:33:56,001:INFO:Physical Core: 28
2023-07-31 10:33:56,001:INFO:Logical Core: 56
2023-07-31 10:33:56,001:INFO:Checking libraries
2023-07-31 10:33:56,001:INFO:System:
2023-07-31 10:33:56,001:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 10:33:56,001:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 10:33:56,002:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:33:56,002:INFO:PyCaret required dependencies:
2023-07-31 10:33:56,002:INFO:                 pip: 23.0.1
2023-07-31 10:33:56,002:INFO:          setuptools: 66.0.0
2023-07-31 10:33:56,002:INFO:             pycaret: 3.0.2
2023-07-31 10:33:56,002:INFO:             IPython: 8.13.2
2023-07-31 10:33:56,002:INFO:          ipywidgets: 8.0.6
2023-07-31 10:33:56,002:INFO:                tqdm: 4.65.0
2023-07-31 10:33:56,002:INFO:               numpy: 1.23.5
2023-07-31 10:33:56,002:INFO:              pandas: 1.5.3
2023-07-31 10:33:56,002:INFO:              jinja2: 3.1.2
2023-07-31 10:33:56,002:INFO:               scipy: 1.10.1
2023-07-31 10:33:56,002:INFO:              joblib: 1.2.0
2023-07-31 10:33:56,002:INFO:             sklearn: 1.2.2
2023-07-31 10:33:56,002:INFO:                pyod: 1.0.9
2023-07-31 10:33:56,002:INFO:            imblearn: 0.10.1
2023-07-31 10:33:56,002:INFO:   category_encoders: 2.6.1
2023-07-31 10:33:56,002:INFO:            lightgbm: 3.3.5
2023-07-31 10:33:56,002:INFO:               numba: 0.57.0
2023-07-31 10:33:56,002:INFO:            requests: 2.28.1
2023-07-31 10:33:56,002:INFO:          matplotlib: 3.7.1
2023-07-31 10:33:56,002:INFO:          scikitplot: 0.3.7
2023-07-31 10:33:56,002:INFO:         yellowbrick: 1.5
2023-07-31 10:33:56,002:INFO:              plotly: 5.14.1
2023-07-31 10:33:56,002:INFO:             kaleido: 0.2.1
2023-07-31 10:33:56,002:INFO:         statsmodels: 0.14.0
2023-07-31 10:33:56,002:INFO:              sktime: 0.17.0
2023-07-31 10:33:56,002:INFO:               tbats: 1.1.3
2023-07-31 10:33:56,002:INFO:            pmdarima: 2.0.3
2023-07-31 10:33:56,002:INFO:              psutil: 5.9.5
2023-07-31 10:33:56,002:INFO:PyCaret optional dependencies:
2023-07-31 10:33:56,003:INFO:                shap: Not installed
2023-07-31 10:33:56,003:INFO:           interpret: Not installed
2023-07-31 10:33:56,003:INFO:                umap: Not installed
2023-07-31 10:33:56,003:INFO:    pandas_profiling: Not installed
2023-07-31 10:33:56,003:INFO:  explainerdashboard: Not installed
2023-07-31 10:33:56,003:INFO:             autoviz: Not installed
2023-07-31 10:33:56,003:INFO:           fairlearn: Not installed
2023-07-31 10:33:56,003:INFO:             xgboost: Not installed
2023-07-31 10:33:56,003:INFO:            catboost: Not installed
2023-07-31 10:33:56,003:INFO:              kmodes: Not installed
2023-07-31 10:33:56,003:INFO:             mlxtend: Not installed
2023-07-31 10:33:56,003:INFO:       statsforecast: Not installed
2023-07-31 10:33:56,003:INFO:        tune_sklearn: Not installed
2023-07-31 10:33:56,003:INFO:                 ray: Not installed
2023-07-31 10:33:56,003:INFO:            hyperopt: Not installed
2023-07-31 10:33:56,003:INFO:              optuna: Not installed
2023-07-31 10:33:56,003:INFO:               skopt: Not installed
2023-07-31 10:33:56,003:INFO:              mlflow: Not installed
2023-07-31 10:33:56,003:INFO:              gradio: Not installed
2023-07-31 10:33:56,003:INFO:             fastapi: Not installed
2023-07-31 10:33:56,003:INFO:             uvicorn: Not installed
2023-07-31 10:33:56,003:INFO:              m2cgen: Not installed
2023-07-31 10:33:56,003:INFO:           evidently: Not installed
2023-07-31 10:33:56,003:INFO:               fugue: Not installed
2023-07-31 10:33:56,003:INFO:           streamlit: Not installed
2023-07-31 10:33:56,003:INFO:             prophet: Not installed
2023-07-31 10:33:56,003:INFO:None
2023-07-31 10:33:56,003:INFO:Set up data.
2023-07-31 10:34:00,820:INFO:Set up train/test split.
2023-07-31 10:34:01,052:INFO:Set up index.
2023-07-31 10:34:01,053:INFO:Set up folding strategy.
2023-07-31 10:34:01,055:INFO:Assigning column types.
2023-07-31 10:34:01,186:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 10:34:01,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:34:01,235:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:34:01,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,316:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:34:01,317:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:34:01,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,351:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 10:34:01,399:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:34:01,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,479:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:34:01,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,511:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 10:34:01,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:01,674:INFO:Preparing preprocessing pipeline...
2023-07-31 10:34:01,699:INFO:Set up simple imputation.
2023-07-31 10:34:01,718:INFO:Set up column name cleaning.
2023-07-31 10:34:02,831:INFO:Finished creating preprocessing pipeline.
2023-07-31 10:34:02,899:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 10:34:02,899:INFO:Creating final display dataframe.
2023-07-31 10:34:05,824:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (421, 11886)
4        Transformed data shape      (421, 11886)
5   Transformed train set shape      (378, 11886)
6    Transformed test set shape       (43, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4630
2023-07-31 10:34:05,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:05,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:05,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:05,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:34:05,980:INFO:setup() successfully completed in 10.12s...............
2023-07-31 10:34:05,987:INFO:Initializing compare_models()
2023-07-31 10:34:05,987:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 10:34:05,987:INFO:Checking exceptions
2023-07-31 10:34:06,065:INFO:Preparing display monitor
2023-07-31 10:34:06,091:INFO:Initializing Logistic Regression
2023-07-31 10:34:06,091:INFO:Total runtime is 2.845128377278646e-06 minutes
2023-07-31 10:34:06,094:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:06,094:INFO:Initializing create_model()
2023-07-31 10:34:06,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:06,095:INFO:Checking exceptions
2023-07-31 10:34:06,095:INFO:Importing libraries
2023-07-31 10:34:06,095:INFO:Copying training dataset
2023-07-31 10:34:06,185:INFO:Defining folds
2023-07-31 10:34:06,185:INFO:Declaring metric variables
2023-07-31 10:34:06,189:INFO:Importing untrained model
2023-07-31 10:34:06,193:INFO:Logistic Regression Imported successfully
2023-07-31 10:34:06,199:INFO:Starting cross validation
2023-07-31 10:34:06,241:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:34:16,681:INFO:Calculating mean and std
2023-07-31 10:34:16,685:INFO:Creating metrics dataframe
2023-07-31 10:34:17,143:INFO:Uploading results into container
2023-07-31 10:34:17,144:INFO:Uploading model into container now
2023-07-31 10:34:17,145:INFO:_master_model_container: 1
2023-07-31 10:34:17,145:INFO:_display_container: 2
2023-07-31 10:34:17,146:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:34:17,146:INFO:create_model() successfully completed......................................
2023-07-31 10:34:17,327:INFO:SubProcess create_model() end ==================================
2023-07-31 10:34:17,327:INFO:Creating metrics dataframe
2023-07-31 10:34:17,338:INFO:Initializing K Neighbors Classifier
2023-07-31 10:34:17,338:INFO:Total runtime is 0.1874580224355062 minutes
2023-07-31 10:34:17,342:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:17,342:INFO:Initializing create_model()
2023-07-31 10:34:17,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:17,342:INFO:Checking exceptions
2023-07-31 10:34:17,342:INFO:Importing libraries
2023-07-31 10:34:17,342:INFO:Copying training dataset
2023-07-31 10:34:17,421:INFO:Defining folds
2023-07-31 10:34:17,421:INFO:Declaring metric variables
2023-07-31 10:34:17,425:INFO:Importing untrained model
2023-07-31 10:34:17,429:INFO:K Neighbors Classifier Imported successfully
2023-07-31 10:34:17,435:INFO:Starting cross validation
2023-07-31 10:34:17,477:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:34:21,978:INFO:Calculating mean and std
2023-07-31 10:34:21,982:INFO:Creating metrics dataframe
2023-07-31 10:34:22,176:INFO:Uploading results into container
2023-07-31 10:34:22,177:INFO:Uploading model into container now
2023-07-31 10:34:22,178:INFO:_master_model_container: 2
2023-07-31 10:34:22,178:INFO:_display_container: 2
2023-07-31 10:34:22,178:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 10:34:22,178:INFO:create_model() successfully completed......................................
2023-07-31 10:34:22,327:INFO:SubProcess create_model() end ==================================
2023-07-31 10:34:22,327:INFO:Creating metrics dataframe
2023-07-31 10:34:22,339:INFO:Initializing Naive Bayes
2023-07-31 10:34:22,339:INFO:Total runtime is 0.2708087245623271 minutes
2023-07-31 10:34:22,343:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:22,343:INFO:Initializing create_model()
2023-07-31 10:34:22,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:22,343:INFO:Checking exceptions
2023-07-31 10:34:22,343:INFO:Importing libraries
2023-07-31 10:34:22,343:INFO:Copying training dataset
2023-07-31 10:34:22,411:INFO:Defining folds
2023-07-31 10:34:22,412:INFO:Declaring metric variables
2023-07-31 10:34:22,416:INFO:Importing untrained model
2023-07-31 10:34:22,419:INFO:Naive Bayes Imported successfully
2023-07-31 10:34:22,426:INFO:Starting cross validation
2023-07-31 10:34:22,468:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:34:26,915:INFO:Calculating mean and std
2023-07-31 10:34:26,918:INFO:Creating metrics dataframe
2023-07-31 10:34:27,109:INFO:Uploading results into container
2023-07-31 10:34:27,110:INFO:Uploading model into container now
2023-07-31 10:34:27,110:INFO:_master_model_container: 3
2023-07-31 10:34:27,110:INFO:_display_container: 2
2023-07-31 10:34:27,111:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 10:34:27,111:INFO:create_model() successfully completed......................................
2023-07-31 10:34:27,251:INFO:SubProcess create_model() end ==================================
2023-07-31 10:34:27,251:INFO:Creating metrics dataframe
2023-07-31 10:34:27,263:INFO:Initializing Decision Tree Classifier
2023-07-31 10:34:27,263:INFO:Total runtime is 0.352881920337677 minutes
2023-07-31 10:34:27,267:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:27,267:INFO:Initializing create_model()
2023-07-31 10:34:27,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:27,267:INFO:Checking exceptions
2023-07-31 10:34:27,268:INFO:Importing libraries
2023-07-31 10:34:27,268:INFO:Copying training dataset
2023-07-31 10:34:27,339:INFO:Defining folds
2023-07-31 10:34:27,340:INFO:Declaring metric variables
2023-07-31 10:34:27,344:INFO:Importing untrained model
2023-07-31 10:34:27,348:INFO:Decision Tree Classifier Imported successfully
2023-07-31 10:34:27,354:INFO:Starting cross validation
2023-07-31 10:34:27,396:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:34:32,394:INFO:Calculating mean and std
2023-07-31 10:34:32,396:INFO:Creating metrics dataframe
2023-07-31 10:34:32,857:INFO:Uploading results into container
2023-07-31 10:34:32,858:INFO:Uploading model into container now
2023-07-31 10:34:32,859:INFO:_master_model_container: 4
2023-07-31 10:34:32,859:INFO:_display_container: 2
2023-07-31 10:34:32,859:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 10:34:32,859:INFO:create_model() successfully completed......................................
2023-07-31 10:34:32,979:INFO:SubProcess create_model() end ==================================
2023-07-31 10:34:32,979:INFO:Creating metrics dataframe
2023-07-31 10:34:32,991:INFO:Initializing SVM - Linear Kernel
2023-07-31 10:34:32,991:INFO:Total runtime is 0.4483471075693766 minutes
2023-07-31 10:34:32,995:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:32,995:INFO:Initializing create_model()
2023-07-31 10:34:32,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:32,995:INFO:Checking exceptions
2023-07-31 10:34:32,995:INFO:Importing libraries
2023-07-31 10:34:32,995:INFO:Copying training dataset
2023-07-31 10:34:33,065:INFO:Defining folds
2023-07-31 10:34:33,065:INFO:Declaring metric variables
2023-07-31 10:34:33,069:INFO:Importing untrained model
2023-07-31 10:34:33,073:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 10:34:33,080:INFO:Starting cross validation
2023-07-31 10:34:33,122:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:34:36,473:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:34:36,496:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:34:36,498:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:34:36,558:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:34:36,562:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:34:36,599:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:34:36,631:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:36,648:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:34:36,731:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:34:37,429:INFO:Calculating mean and std
2023-07-31 10:34:37,432:INFO:Creating metrics dataframe
2023-07-31 10:34:37,878:INFO:Uploading results into container
2023-07-31 10:34:37,880:INFO:Uploading model into container now
2023-07-31 10:34:37,881:INFO:_master_model_container: 5
2023-07-31 10:34:37,881:INFO:_display_container: 2
2023-07-31 10:34:37,882:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 10:34:37,882:INFO:create_model() successfully completed......................................
2023-07-31 10:34:38,030:INFO:SubProcess create_model() end ==================================
2023-07-31 10:34:38,030:INFO:Creating metrics dataframe
2023-07-31 10:34:38,044:INFO:Initializing Ridge Classifier
2023-07-31 10:34:38,044:INFO:Total runtime is 0.5325649897257487 minutes
2023-07-31 10:34:38,049:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:38,049:INFO:Initializing create_model()
2023-07-31 10:34:38,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:38,049:INFO:Checking exceptions
2023-07-31 10:34:38,050:INFO:Importing libraries
2023-07-31 10:34:38,050:INFO:Copying training dataset
2023-07-31 10:34:38,141:INFO:Defining folds
2023-07-31 10:34:38,141:INFO:Declaring metric variables
2023-07-31 10:34:38,146:INFO:Importing untrained model
2023-07-31 10:34:38,150:INFO:Ridge Classifier Imported successfully
2023-07-31 10:34:38,158:INFO:Starting cross validation
2023-07-31 10:34:38,200:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:34:41,322:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:41,348:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:34:41,356:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:34:41,392:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:34:41,396:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:34:41,403:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:34:41,418:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:34:41,428:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:34:41,456:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:34:42,272:INFO:Calculating mean and std
2023-07-31 10:34:42,274:INFO:Creating metrics dataframe
2023-07-31 10:34:42,757:INFO:Uploading results into container
2023-07-31 10:34:42,758:INFO:Uploading model into container now
2023-07-31 10:34:42,759:INFO:_master_model_container: 6
2023-07-31 10:34:42,759:INFO:_display_container: 2
2023-07-31 10:34:42,760:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 10:34:42,760:INFO:create_model() successfully completed......................................
2023-07-31 10:34:42,917:INFO:SubProcess create_model() end ==================================
2023-07-31 10:34:42,917:INFO:Creating metrics dataframe
2023-07-31 10:34:42,931:INFO:Initializing Random Forest Classifier
2023-07-31 10:34:42,931:INFO:Total runtime is 0.6140070239702861 minutes
2023-07-31 10:34:42,935:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:42,935:INFO:Initializing create_model()
2023-07-31 10:34:42,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:42,935:INFO:Checking exceptions
2023-07-31 10:34:42,935:INFO:Importing libraries
2023-07-31 10:34:42,935:INFO:Copying training dataset
2023-07-31 10:34:43,003:INFO:Defining folds
2023-07-31 10:34:43,004:INFO:Declaring metric variables
2023-07-31 10:34:43,008:INFO:Importing untrained model
2023-07-31 10:34:43,012:INFO:Random Forest Classifier Imported successfully
2023-07-31 10:34:43,019:INFO:Starting cross validation
2023-07-31 10:34:43,061:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:34:46,650:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:46,661:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:46,727:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:46,728:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:46,740:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:46,757:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:46,858:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:47,127:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:34:48,311:INFO:Calculating mean and std
2023-07-31 10:34:48,313:INFO:Creating metrics dataframe
2023-07-31 10:34:48,789:INFO:Uploading results into container
2023-07-31 10:34:48,790:INFO:Uploading model into container now
2023-07-31 10:34:48,790:INFO:_master_model_container: 7
2023-07-31 10:34:48,790:INFO:_display_container: 2
2023-07-31 10:34:48,791:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 10:34:48,791:INFO:create_model() successfully completed......................................
2023-07-31 10:34:48,909:INFO:SubProcess create_model() end ==================================
2023-07-31 10:34:48,909:INFO:Creating metrics dataframe
2023-07-31 10:34:48,922:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 10:34:48,922:INFO:Total runtime is 0.7138577580451966 minutes
2023-07-31 10:34:48,926:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:48,926:INFO:Initializing create_model()
2023-07-31 10:34:48,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:48,926:INFO:Checking exceptions
2023-07-31 10:34:48,926:INFO:Importing libraries
2023-07-31 10:34:48,926:INFO:Copying training dataset
2023-07-31 10:34:48,989:INFO:Defining folds
2023-07-31 10:34:48,989:INFO:Declaring metric variables
2023-07-31 10:34:48,993:INFO:Importing untrained model
2023-07-31 10:34:48,996:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 10:34:49,003:INFO:Starting cross validation
2023-07-31 10:34:49,045:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:34:49,793:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:34:49,814:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:34:49,829:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:34:49,911:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:34:49,923:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:34:50,029:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:34:50,121:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:34:50,366:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:34:53,825:INFO:Calculating mean and std
2023-07-31 10:34:53,827:INFO:Creating metrics dataframe
2023-07-31 10:34:54,318:INFO:Uploading results into container
2023-07-31 10:34:54,319:INFO:Uploading model into container now
2023-07-31 10:34:54,319:INFO:_master_model_container: 8
2023-07-31 10:34:54,319:INFO:_display_container: 2
2023-07-31 10:34:54,319:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 10:34:54,320:INFO:create_model() successfully completed......................................
2023-07-31 10:34:54,471:INFO:SubProcess create_model() end ==================================
2023-07-31 10:34:54,471:INFO:Creating metrics dataframe
2023-07-31 10:34:54,487:INFO:Initializing Ada Boost Classifier
2023-07-31 10:34:54,487:INFO:Total runtime is 0.8066104610761007 minutes
2023-07-31 10:34:54,492:INFO:SubProcess create_model() called ==================================
2023-07-31 10:34:54,492:INFO:Initializing create_model()
2023-07-31 10:34:54,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:34:54,492:INFO:Checking exceptions
2023-07-31 10:34:54,493:INFO:Importing libraries
2023-07-31 10:34:54,493:INFO:Copying training dataset
2023-07-31 10:34:54,597:INFO:Defining folds
2023-07-31 10:34:54,597:INFO:Declaring metric variables
2023-07-31 10:34:54,603:INFO:Importing untrained model
2023-07-31 10:34:54,609:INFO:Ada Boost Classifier Imported successfully
2023-07-31 10:34:54,619:INFO:Starting cross validation
2023-07-31 10:34:54,671:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:35:17,154:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:35:17,535:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:35:17,735:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:35:17,768:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:35:18,806:INFO:Calculating mean and std
2023-07-31 10:35:18,809:INFO:Creating metrics dataframe
2023-07-31 10:35:19,003:INFO:Uploading results into container
2023-07-31 10:35:19,004:INFO:Uploading model into container now
2023-07-31 10:35:19,005:INFO:_master_model_container: 9
2023-07-31 10:35:19,005:INFO:_display_container: 2
2023-07-31 10:35:19,005:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 10:35:19,005:INFO:create_model() successfully completed......................................
2023-07-31 10:35:19,137:INFO:SubProcess create_model() end ==================================
2023-07-31 10:35:19,138:INFO:Creating metrics dataframe
2023-07-31 10:35:19,151:INFO:Initializing Gradient Boosting Classifier
2023-07-31 10:35:19,151:INFO:Total runtime is 1.217680569489797 minutes
2023-07-31 10:35:19,155:INFO:SubProcess create_model() called ==================================
2023-07-31 10:35:19,155:INFO:Initializing create_model()
2023-07-31 10:35:19,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:35:19,155:INFO:Checking exceptions
2023-07-31 10:35:19,155:INFO:Importing libraries
2023-07-31 10:35:19,155:INFO:Copying training dataset
2023-07-31 10:35:19,217:INFO:Defining folds
2023-07-31 10:35:19,217:INFO:Declaring metric variables
2023-07-31 10:35:19,221:INFO:Importing untrained model
2023-07-31 10:35:19,225:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 10:35:19,231:INFO:Starting cross validation
2023-07-31 10:35:19,273:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:36:03,198:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:29,001:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:29,008:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:29,167:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:29,254:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:29,416:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:30,370:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:31,680:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:32,176:INFO:Calculating mean and std
2023-07-31 10:36:32,179:INFO:Creating metrics dataframe
2023-07-31 10:36:32,638:INFO:Uploading results into container
2023-07-31 10:36:32,640:INFO:Uploading model into container now
2023-07-31 10:36:32,641:INFO:_master_model_container: 10
2023-07-31 10:36:32,641:INFO:_display_container: 2
2023-07-31 10:36:32,641:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 10:36:32,642:INFO:create_model() successfully completed......................................
2023-07-31 10:36:32,786:INFO:SubProcess create_model() end ==================================
2023-07-31 10:36:32,786:INFO:Creating metrics dataframe
2023-07-31 10:36:32,800:INFO:Initializing Linear Discriminant Analysis
2023-07-31 10:36:32,800:INFO:Total runtime is 2.445166051387787 minutes
2023-07-31 10:36:32,804:INFO:SubProcess create_model() called ==================================
2023-07-31 10:36:32,804:INFO:Initializing create_model()
2023-07-31 10:36:32,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:36:32,805:INFO:Checking exceptions
2023-07-31 10:36:32,805:INFO:Importing libraries
2023-07-31 10:36:32,805:INFO:Copying training dataset
2023-07-31 10:36:32,870:INFO:Defining folds
2023-07-31 10:36:32,870:INFO:Declaring metric variables
2023-07-31 10:36:32,875:INFO:Importing untrained model
2023-07-31 10:36:32,878:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:36:32,886:INFO:Starting cross validation
2023-07-31 10:36:32,927:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:36:38,067:INFO:Calculating mean and std
2023-07-31 10:36:38,070:INFO:Creating metrics dataframe
2023-07-31 10:36:38,266:INFO:Uploading results into container
2023-07-31 10:36:38,267:INFO:Uploading model into container now
2023-07-31 10:36:38,268:INFO:_master_model_container: 11
2023-07-31 10:36:38,268:INFO:_display_container: 2
2023-07-31 10:36:38,269:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:36:38,269:INFO:create_model() successfully completed......................................
2023-07-31 10:36:38,416:INFO:SubProcess create_model() end ==================================
2023-07-31 10:36:38,416:INFO:Creating metrics dataframe
2023-07-31 10:36:38,440:INFO:Initializing Extra Trees Classifier
2023-07-31 10:36:38,440:INFO:Total runtime is 2.5391594052314757 minutes
2023-07-31 10:36:38,444:INFO:SubProcess create_model() called ==================================
2023-07-31 10:36:38,444:INFO:Initializing create_model()
2023-07-31 10:36:38,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:36:38,444:INFO:Checking exceptions
2023-07-31 10:36:38,444:INFO:Importing libraries
2023-07-31 10:36:38,444:INFO:Copying training dataset
2023-07-31 10:36:38,512:INFO:Defining folds
2023-07-31 10:36:38,512:INFO:Declaring metric variables
2023-07-31 10:36:38,516:INFO:Importing untrained model
2023-07-31 10:36:38,520:INFO:Extra Trees Classifier Imported successfully
2023-07-31 10:36:38,527:INFO:Starting cross validation
2023-07-31 10:36:38,568:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:36:41,329:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:41,337:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:41,517:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:41,650:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:41,736:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:41,858:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:42,046:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:42,660:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:36:43,406:INFO:Calculating mean and std
2023-07-31 10:36:43,408:INFO:Creating metrics dataframe
2023-07-31 10:36:43,628:INFO:Uploading results into container
2023-07-31 10:36:43,629:INFO:Uploading model into container now
2023-07-31 10:36:43,630:INFO:_master_model_container: 12
2023-07-31 10:36:43,630:INFO:_display_container: 2
2023-07-31 10:36:43,630:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 10:36:43,631:INFO:create_model() successfully completed......................................
2023-07-31 10:36:43,756:INFO:SubProcess create_model() end ==================================
2023-07-31 10:36:43,756:INFO:Creating metrics dataframe
2023-07-31 10:36:43,770:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 10:36:43,770:INFO:Total runtime is 2.6279889424641927 minutes
2023-07-31 10:36:43,773:INFO:SubProcess create_model() called ==================================
2023-07-31 10:36:43,774:INFO:Initializing create_model()
2023-07-31 10:36:43,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:36:43,774:INFO:Checking exceptions
2023-07-31 10:36:43,774:INFO:Importing libraries
2023-07-31 10:36:43,774:INFO:Copying training dataset
2023-07-31 10:36:43,836:INFO:Defining folds
2023-07-31 10:36:43,836:INFO:Declaring metric variables
2023-07-31 10:36:43,840:INFO:Importing untrained model
2023-07-31 10:36:43,844:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 10:36:43,851:INFO:Starting cross validation
2023-07-31 10:36:43,892:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:37:27,432:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:37:44,086:INFO:Calculating mean and std
2023-07-31 10:37:44,093:INFO:Creating metrics dataframe
2023-07-31 10:37:44,327:INFO:Uploading results into container
2023-07-31 10:37:44,329:INFO:Uploading model into container now
2023-07-31 10:37:44,329:INFO:_master_model_container: 13
2023-07-31 10:37:44,330:INFO:_display_container: 2
2023-07-31 10:37:44,330:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 10:37:44,330:INFO:create_model() successfully completed......................................
2023-07-31 10:37:44,646:INFO:SubProcess create_model() end ==================================
2023-07-31 10:37:44,646:INFO:Creating metrics dataframe
2023-07-31 10:37:44,662:INFO:Initializing Dummy Classifier
2023-07-31 10:37:44,662:INFO:Total runtime is 3.6428567091623942 minutes
2023-07-31 10:37:44,665:INFO:SubProcess create_model() called ==================================
2023-07-31 10:37:44,666:INFO:Initializing create_model()
2023-07-31 10:37:44,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1502070>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:37:44,666:INFO:Checking exceptions
2023-07-31 10:37:44,666:INFO:Importing libraries
2023-07-31 10:37:44,666:INFO:Copying training dataset
2023-07-31 10:37:44,734:INFO:Defining folds
2023-07-31 10:37:44,734:INFO:Declaring metric variables
2023-07-31 10:37:44,738:INFO:Importing untrained model
2023-07-31 10:37:44,742:INFO:Dummy Classifier Imported successfully
2023-07-31 10:37:44,748:INFO:Starting cross validation
2023-07-31 10:37:44,789:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:37:47,771:INFO:Calculating mean and std
2023-07-31 10:37:47,773:INFO:Creating metrics dataframe
2023-07-31 10:37:47,928:INFO:Uploading results into container
2023-07-31 10:37:47,929:INFO:Uploading model into container now
2023-07-31 10:37:47,929:INFO:_master_model_container: 14
2023-07-31 10:37:47,930:INFO:_display_container: 2
2023-07-31 10:37:47,930:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 10:37:47,930:INFO:create_model() successfully completed......................................
2023-07-31 10:37:48,041:INFO:SubProcess create_model() end ==================================
2023-07-31 10:37:48,041:INFO:Creating metrics dataframe
2023-07-31 10:37:48,064:INFO:Initializing create_model()
2023-07-31 10:37:48,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd151ce20>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:37:48,064:INFO:Checking exceptions
2023-07-31 10:37:48,066:INFO:Importing libraries
2023-07-31 10:37:48,066:INFO:Copying training dataset
2023-07-31 10:37:48,127:INFO:Defining folds
2023-07-31 10:37:48,127:INFO:Declaring metric variables
2023-07-31 10:37:48,127:INFO:Importing untrained model
2023-07-31 10:37:48,127:INFO:Declaring custom model
2023-07-31 10:37:48,128:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:37:48,164:INFO:Cross validation set to False
2023-07-31 10:37:48,164:INFO:Fitting Model
2023-07-31 10:37:50,789:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:37:50,789:INFO:create_model() successfully completed......................................
2023-07-31 10:37:50,987:INFO:_master_model_container: 14
2023-07-31 10:37:50,987:INFO:_display_container: 2
2023-07-31 10:37:50,987:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:37:50,987:INFO:compare_models() successfully completed......................................
2023-07-31 10:37:54,646:INFO:Initializing set_config()
2023-07-31 10:37:54,647:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, variable=seed, value=42, kwargs={})
2023-07-31 10:37:54,648:INFO:Global variable: seed updated to 42
2023-07-31 10:37:54,648:INFO:set_config() successfully completed......................................
2023-07-31 10:37:54,801:INFO:PyCaret ClassificationExperiment
2023-07-31 10:37:54,801:INFO:Logging name: clf-default-name
2023-07-31 10:37:54,801:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 10:37:54,801:INFO:version 3.0.2
2023-07-31 10:37:54,801:INFO:Initializing setup()
2023-07-31 10:37:54,801:INFO:self.USI: 2789
2023-07-31 10:37:54,801:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 10:37:54,801:INFO:Checking environment
2023-07-31 10:37:54,801:INFO:python_version: 3.9.16
2023-07-31 10:37:54,801:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 10:37:54,801:INFO:machine: x86_64
2023-07-31 10:37:54,802:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:37:54,802:INFO:Memory: svmem(total=67419119616, available=18321604608, percent=72.8, used=48200908800, free=17625067520, active=42771398656, inactive=4701442048, buffers=40714240, cached=1552429056, shared=202440704, slab=1307226112)
2023-07-31 10:37:54,805:INFO:Physical Core: 28
2023-07-31 10:37:54,805:INFO:Logical Core: 56
2023-07-31 10:37:54,805:INFO:Checking libraries
2023-07-31 10:37:54,805:INFO:System:
2023-07-31 10:37:54,805:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 10:37:54,805:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 10:37:54,805:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:37:54,805:INFO:PyCaret required dependencies:
2023-07-31 10:37:54,805:INFO:                 pip: 23.0.1
2023-07-31 10:37:54,805:INFO:          setuptools: 66.0.0
2023-07-31 10:37:54,805:INFO:             pycaret: 3.0.2
2023-07-31 10:37:54,806:INFO:             IPython: 8.13.2
2023-07-31 10:37:54,806:INFO:          ipywidgets: 8.0.6
2023-07-31 10:37:54,806:INFO:                tqdm: 4.65.0
2023-07-31 10:37:54,806:INFO:               numpy: 1.23.5
2023-07-31 10:37:54,806:INFO:              pandas: 1.5.3
2023-07-31 10:37:54,806:INFO:              jinja2: 3.1.2
2023-07-31 10:37:54,806:INFO:               scipy: 1.10.1
2023-07-31 10:37:54,806:INFO:              joblib: 1.2.0
2023-07-31 10:37:54,806:INFO:             sklearn: 1.2.2
2023-07-31 10:37:54,806:INFO:                pyod: 1.0.9
2023-07-31 10:37:54,806:INFO:            imblearn: 0.10.1
2023-07-31 10:37:54,806:INFO:   category_encoders: 2.6.1
2023-07-31 10:37:54,806:INFO:            lightgbm: 3.3.5
2023-07-31 10:37:54,806:INFO:               numba: 0.57.0
2023-07-31 10:37:54,806:INFO:            requests: 2.28.1
2023-07-31 10:37:54,806:INFO:          matplotlib: 3.7.1
2023-07-31 10:37:54,806:INFO:          scikitplot: 0.3.7
2023-07-31 10:37:54,806:INFO:         yellowbrick: 1.5
2023-07-31 10:37:54,806:INFO:              plotly: 5.14.1
2023-07-31 10:37:54,806:INFO:             kaleido: 0.2.1
2023-07-31 10:37:54,806:INFO:         statsmodels: 0.14.0
2023-07-31 10:37:54,806:INFO:              sktime: 0.17.0
2023-07-31 10:37:54,806:INFO:               tbats: 1.1.3
2023-07-31 10:37:54,806:INFO:            pmdarima: 2.0.3
2023-07-31 10:37:54,806:INFO:              psutil: 5.9.5
2023-07-31 10:37:54,806:INFO:PyCaret optional dependencies:
2023-07-31 10:37:54,806:INFO:                shap: Not installed
2023-07-31 10:37:54,806:INFO:           interpret: Not installed
2023-07-31 10:37:54,806:INFO:                umap: Not installed
2023-07-31 10:37:54,806:INFO:    pandas_profiling: Not installed
2023-07-31 10:37:54,807:INFO:  explainerdashboard: Not installed
2023-07-31 10:37:54,807:INFO:             autoviz: Not installed
2023-07-31 10:37:54,807:INFO:           fairlearn: Not installed
2023-07-31 10:37:54,807:INFO:             xgboost: Not installed
2023-07-31 10:37:54,807:INFO:            catboost: Not installed
2023-07-31 10:37:54,807:INFO:              kmodes: Not installed
2023-07-31 10:37:54,807:INFO:             mlxtend: Not installed
2023-07-31 10:37:54,807:INFO:       statsforecast: Not installed
2023-07-31 10:37:54,807:INFO:        tune_sklearn: Not installed
2023-07-31 10:37:54,807:INFO:                 ray: Not installed
2023-07-31 10:37:54,807:INFO:            hyperopt: Not installed
2023-07-31 10:37:54,807:INFO:              optuna: Not installed
2023-07-31 10:37:54,807:INFO:               skopt: Not installed
2023-07-31 10:37:54,807:INFO:              mlflow: Not installed
2023-07-31 10:37:54,807:INFO:              gradio: Not installed
2023-07-31 10:37:54,807:INFO:             fastapi: Not installed
2023-07-31 10:37:54,807:INFO:             uvicorn: Not installed
2023-07-31 10:37:54,807:INFO:              m2cgen: Not installed
2023-07-31 10:37:54,807:INFO:           evidently: Not installed
2023-07-31 10:37:54,807:INFO:               fugue: Not installed
2023-07-31 10:37:54,807:INFO:           streamlit: Not installed
2023-07-31 10:37:54,807:INFO:             prophet: Not installed
2023-07-31 10:37:54,807:INFO:None
2023-07-31 10:37:54,807:INFO:Set up data.
2023-07-31 10:37:58,925:INFO:Set up train/test split.
2023-07-31 10:37:59,102:INFO:Set up index.
2023-07-31 10:37:59,103:INFO:Set up folding strategy.
2023-07-31 10:37:59,103:INFO:Assigning column types.
2023-07-31 10:37:59,226:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 10:37:59,271:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:37:59,272:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:37:59,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:37:59,345:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:37:59,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,374:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 10:37:59,420:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:37:59,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,495:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:37:59,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,523:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 10:37:59,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:37:59,671:INFO:Preparing preprocessing pipeline...
2023-07-31 10:37:59,693:INFO:Set up simple imputation.
2023-07-31 10:37:59,712:INFO:Set up column name cleaning.
2023-07-31 10:38:00,839:INFO:Finished creating preprocessing pipeline.
2023-07-31 10:38:00,914:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 10:38:00,914:INFO:Creating final display dataframe.
2023-07-31 10:38:04,411:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (742, 11886)
4        Transformed data shape      (742, 11886)
5   Transformed train set shape      (667, 11886)
6    Transformed test set shape       (75, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              2789
2023-07-31 10:38:04,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:38:04,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:38:04,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:38:04,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:38:04,645:INFO:setup() successfully completed in 10.0s...............
2023-07-31 10:38:04,652:INFO:Initializing compare_models()
2023-07-31 10:38:04,652:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 10:38:04,652:INFO:Checking exceptions
2023-07-31 10:38:04,749:INFO:Preparing display monitor
2023-07-31 10:38:04,774:INFO:Initializing Logistic Regression
2023-07-31 10:38:04,774:INFO:Total runtime is 3.039836883544922e-06 minutes
2023-07-31 10:38:04,777:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:04,778:INFO:Initializing create_model()
2023-07-31 10:38:04,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:04,778:INFO:Checking exceptions
2023-07-31 10:38:04,778:INFO:Importing libraries
2023-07-31 10:38:04,778:INFO:Copying training dataset
2023-07-31 10:38:04,925:INFO:Defining folds
2023-07-31 10:38:04,925:INFO:Declaring metric variables
2023-07-31 10:38:04,929:INFO:Importing untrained model
2023-07-31 10:38:04,933:INFO:Logistic Regression Imported successfully
2023-07-31 10:38:04,940:INFO:Starting cross validation
2023-07-31 10:38:04,986:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:38:15,999:INFO:Calculating mean and std
2023-07-31 10:38:16,005:INFO:Creating metrics dataframe
2023-07-31 10:38:16,473:INFO:Uploading results into container
2023-07-31 10:38:16,475:INFO:Uploading model into container now
2023-07-31 10:38:16,483:INFO:_master_model_container: 1
2023-07-31 10:38:16,483:INFO:_display_container: 2
2023-07-31 10:38:16,484:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:38:16,484:INFO:create_model() successfully completed......................................
2023-07-31 10:38:16,691:INFO:SubProcess create_model() end ==================================
2023-07-31 10:38:16,691:INFO:Creating metrics dataframe
2023-07-31 10:38:16,702:INFO:Initializing K Neighbors Classifier
2023-07-31 10:38:16,702:INFO:Total runtime is 0.19880483945210775 minutes
2023-07-31 10:38:16,706:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:16,706:INFO:Initializing create_model()
2023-07-31 10:38:16,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:16,706:INFO:Checking exceptions
2023-07-31 10:38:16,706:INFO:Importing libraries
2023-07-31 10:38:16,707:INFO:Copying training dataset
2023-07-31 10:38:16,860:INFO:Defining folds
2023-07-31 10:38:16,860:INFO:Declaring metric variables
2023-07-31 10:38:16,866:INFO:Importing untrained model
2023-07-31 10:38:16,870:INFO:K Neighbors Classifier Imported successfully
2023-07-31 10:38:16,876:INFO:Starting cross validation
2023-07-31 10:38:16,919:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:38:20,489:INFO:Calculating mean and std
2023-07-31 10:38:20,493:INFO:Creating metrics dataframe
2023-07-31 10:38:20,713:INFO:Uploading results into container
2023-07-31 10:38:20,715:INFO:Uploading model into container now
2023-07-31 10:38:20,716:INFO:_master_model_container: 2
2023-07-31 10:38:20,716:INFO:_display_container: 2
2023-07-31 10:38:20,717:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 10:38:20,717:INFO:create_model() successfully completed......................................
2023-07-31 10:38:20,887:INFO:SubProcess create_model() end ==================================
2023-07-31 10:38:20,888:INFO:Creating metrics dataframe
2023-07-31 10:38:20,900:INFO:Initializing Naive Bayes
2023-07-31 10:38:20,901:INFO:Total runtime is 0.26877973874409994 minutes
2023-07-31 10:38:20,905:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:20,905:INFO:Initializing create_model()
2023-07-31 10:38:20,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:20,905:INFO:Checking exceptions
2023-07-31 10:38:20,905:INFO:Importing libraries
2023-07-31 10:38:20,905:INFO:Copying training dataset
2023-07-31 10:38:21,051:INFO:Defining folds
2023-07-31 10:38:21,051:INFO:Declaring metric variables
2023-07-31 10:38:21,055:INFO:Importing untrained model
2023-07-31 10:38:21,059:INFO:Naive Bayes Imported successfully
2023-07-31 10:38:21,066:INFO:Starting cross validation
2023-07-31 10:38:21,115:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:38:24,771:INFO:Calculating mean and std
2023-07-31 10:38:24,775:INFO:Creating metrics dataframe
2023-07-31 10:38:24,982:INFO:Uploading results into container
2023-07-31 10:38:24,983:INFO:Uploading model into container now
2023-07-31 10:38:24,983:INFO:_master_model_container: 3
2023-07-31 10:38:24,983:INFO:_display_container: 2
2023-07-31 10:38:24,984:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 10:38:24,984:INFO:create_model() successfully completed......................................
2023-07-31 10:38:25,146:INFO:SubProcess create_model() end ==================================
2023-07-31 10:38:25,147:INFO:Creating metrics dataframe
2023-07-31 10:38:25,159:INFO:Initializing Decision Tree Classifier
2023-07-31 10:38:25,159:INFO:Total runtime is 0.339753524462382 minutes
2023-07-31 10:38:25,163:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:25,163:INFO:Initializing create_model()
2023-07-31 10:38:25,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:25,163:INFO:Checking exceptions
2023-07-31 10:38:25,163:INFO:Importing libraries
2023-07-31 10:38:25,163:INFO:Copying training dataset
2023-07-31 10:38:25,307:INFO:Defining folds
2023-07-31 10:38:25,307:INFO:Declaring metric variables
2023-07-31 10:38:25,311:INFO:Importing untrained model
2023-07-31 10:38:25,315:INFO:Decision Tree Classifier Imported successfully
2023-07-31 10:38:25,322:INFO:Starting cross validation
2023-07-31 10:38:25,364:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:38:30,355:INFO:Calculating mean and std
2023-07-31 10:38:30,358:INFO:Creating metrics dataframe
2023-07-31 10:38:30,569:INFO:Uploading results into container
2023-07-31 10:38:30,570:INFO:Uploading model into container now
2023-07-31 10:38:30,570:INFO:_master_model_container: 4
2023-07-31 10:38:30,571:INFO:_display_container: 2
2023-07-31 10:38:30,571:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 10:38:30,571:INFO:create_model() successfully completed......................................
2023-07-31 10:38:30,704:INFO:SubProcess create_model() end ==================================
2023-07-31 10:38:30,704:INFO:Creating metrics dataframe
2023-07-31 10:38:30,717:INFO:Initializing SVM - Linear Kernel
2023-07-31 10:38:30,717:INFO:Total runtime is 0.4323875029881795 minutes
2023-07-31 10:38:30,721:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:30,721:INFO:Initializing create_model()
2023-07-31 10:38:30,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:30,721:INFO:Checking exceptions
2023-07-31 10:38:30,722:INFO:Importing libraries
2023-07-31 10:38:30,722:INFO:Copying training dataset
2023-07-31 10:38:30,864:INFO:Defining folds
2023-07-31 10:38:30,864:INFO:Declaring metric variables
2023-07-31 10:38:30,868:INFO:Importing untrained model
2023-07-31 10:38:30,872:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 10:38:30,879:INFO:Starting cross validation
2023-07-31 10:38:30,922:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:38:33,324:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:38:33,380:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:38:33,389:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:38:33,390:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:38:33,397:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:38:33,462:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:38:33,609:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:38:33,720:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:38:33,886:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 10:38:34,411:INFO:Calculating mean and std
2023-07-31 10:38:34,416:INFO:Creating metrics dataframe
2023-07-31 10:38:34,642:INFO:Uploading results into container
2023-07-31 10:38:34,644:INFO:Uploading model into container now
2023-07-31 10:38:34,644:INFO:_master_model_container: 5
2023-07-31 10:38:34,645:INFO:_display_container: 2
2023-07-31 10:38:34,645:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 10:38:34,645:INFO:create_model() successfully completed......................................
2023-07-31 10:38:34,813:INFO:SubProcess create_model() end ==================================
2023-07-31 10:38:34,813:INFO:Creating metrics dataframe
2023-07-31 10:38:34,826:INFO:Initializing Ridge Classifier
2023-07-31 10:38:34,827:INFO:Total runtime is 0.5008800665537516 minutes
2023-07-31 10:38:34,831:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:34,831:INFO:Initializing create_model()
2023-07-31 10:38:34,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:34,831:INFO:Checking exceptions
2023-07-31 10:38:34,831:INFO:Importing libraries
2023-07-31 10:38:34,831:INFO:Copying training dataset
2023-07-31 10:38:34,973:INFO:Defining folds
2023-07-31 10:38:34,973:INFO:Declaring metric variables
2023-07-31 10:38:34,978:INFO:Importing untrained model
2023-07-31 10:38:34,981:INFO:Ridge Classifier Imported successfully
2023-07-31 10:38:34,989:INFO:Starting cross validation
2023-07-31 10:38:35,031:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:38:35,962:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.85249e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-07-31 10:38:36,314:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.77794e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-07-31 10:38:36,327:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.82598e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-07-31 10:38:37,209:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:38:37,330:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:38:37,332:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:38:37,369:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:38:37,386:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:38:37,429:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:38:37,598:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:38:37,609:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 10:38:38,331:INFO:Calculating mean and std
2023-07-31 10:38:38,332:INFO:Creating metrics dataframe
2023-07-31 10:38:38,594:INFO:Uploading results into container
2023-07-31 10:38:38,595:INFO:Uploading model into container now
2023-07-31 10:38:38,596:INFO:_master_model_container: 6
2023-07-31 10:38:38,596:INFO:_display_container: 2
2023-07-31 10:38:38,596:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 10:38:38,596:INFO:create_model() successfully completed......................................
2023-07-31 10:38:38,748:INFO:SubProcess create_model() end ==================================
2023-07-31 10:38:38,748:INFO:Creating metrics dataframe
2023-07-31 10:38:38,761:INFO:Initializing Random Forest Classifier
2023-07-31 10:38:38,761:INFO:Total runtime is 0.566458253065745 minutes
2023-07-31 10:38:38,765:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:38,765:INFO:Initializing create_model()
2023-07-31 10:38:38,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:38,766:INFO:Checking exceptions
2023-07-31 10:38:38,766:INFO:Importing libraries
2023-07-31 10:38:38,766:INFO:Copying training dataset
2023-07-31 10:38:38,908:INFO:Defining folds
2023-07-31 10:38:38,908:INFO:Declaring metric variables
2023-07-31 10:38:38,913:INFO:Importing untrained model
2023-07-31 10:38:38,917:INFO:Random Forest Classifier Imported successfully
2023-07-31 10:38:38,924:INFO:Starting cross validation
2023-07-31 10:38:38,965:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:38:41,796:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:38:41,871:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:38:41,874:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:38:41,904:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:38:41,914:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:38:41,926:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:38:41,941:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:38:43,268:INFO:Calculating mean and std
2023-07-31 10:38:43,270:INFO:Creating metrics dataframe
2023-07-31 10:38:43,745:INFO:Uploading results into container
2023-07-31 10:38:43,746:INFO:Uploading model into container now
2023-07-31 10:38:43,747:INFO:_master_model_container: 7
2023-07-31 10:38:43,747:INFO:_display_container: 2
2023-07-31 10:38:43,747:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 10:38:43,747:INFO:create_model() successfully completed......................................
2023-07-31 10:38:43,862:INFO:SubProcess create_model() end ==================================
2023-07-31 10:38:43,862:INFO:Creating metrics dataframe
2023-07-31 10:38:43,874:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 10:38:43,874:INFO:Total runtime is 0.65166787703832 minutes
2023-07-31 10:38:43,877:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:43,878:INFO:Initializing create_model()
2023-07-31 10:38:43,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:43,878:INFO:Checking exceptions
2023-07-31 10:38:43,878:INFO:Importing libraries
2023-07-31 10:38:43,878:INFO:Copying training dataset
2023-07-31 10:38:44,007:INFO:Defining folds
2023-07-31 10:38:44,007:INFO:Declaring metric variables
2023-07-31 10:38:44,011:INFO:Importing untrained model
2023-07-31 10:38:44,015:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 10:38:44,021:INFO:Starting cross validation
2023-07-31 10:38:44,059:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:38:45,703:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:38:45,707:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:38:45,802:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:38:46,067:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:38:46,088:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:38:46,101:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:38:46,232:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:38:46,255:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:38:49,624:INFO:Calculating mean and std
2023-07-31 10:38:49,628:INFO:Creating metrics dataframe
2023-07-31 10:38:50,098:INFO:Uploading results into container
2023-07-31 10:38:50,099:INFO:Uploading model into container now
2023-07-31 10:38:50,100:INFO:_master_model_container: 8
2023-07-31 10:38:50,100:INFO:_display_container: 2
2023-07-31 10:38:50,101:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 10:38:50,101:INFO:create_model() successfully completed......................................
2023-07-31 10:38:50,267:INFO:SubProcess create_model() end ==================================
2023-07-31 10:38:50,267:INFO:Creating metrics dataframe
2023-07-31 10:38:50,281:INFO:Initializing Ada Boost Classifier
2023-07-31 10:38:50,282:INFO:Total runtime is 0.7584620594978333 minutes
2023-07-31 10:38:50,285:INFO:SubProcess create_model() called ==================================
2023-07-31 10:38:50,286:INFO:Initializing create_model()
2023-07-31 10:38:50,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:38:50,286:INFO:Checking exceptions
2023-07-31 10:38:50,286:INFO:Importing libraries
2023-07-31 10:38:50,286:INFO:Copying training dataset
2023-07-31 10:38:50,425:INFO:Defining folds
2023-07-31 10:38:50,425:INFO:Declaring metric variables
2023-07-31 10:38:50,430:INFO:Importing untrained model
2023-07-31 10:38:50,433:INFO:Ada Boost Classifier Imported successfully
2023-07-31 10:38:50,441:INFO:Starting cross validation
2023-07-31 10:38:50,484:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:39:31,853:INFO:Calculating mean and std
2023-07-31 10:39:31,857:INFO:Creating metrics dataframe
2023-07-31 10:39:32,300:INFO:Uploading results into container
2023-07-31 10:39:32,301:INFO:Uploading model into container now
2023-07-31 10:39:32,302:INFO:_master_model_container: 9
2023-07-31 10:39:32,302:INFO:_display_container: 2
2023-07-31 10:39:32,302:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 10:39:32,303:INFO:create_model() successfully completed......................................
2023-07-31 10:39:32,452:INFO:SubProcess create_model() end ==================================
2023-07-31 10:39:32,452:INFO:Creating metrics dataframe
2023-07-31 10:39:32,466:INFO:Initializing Gradient Boosting Classifier
2023-07-31 10:39:32,466:INFO:Total runtime is 1.4615400393803915 minutes
2023-07-31 10:39:32,470:INFO:SubProcess create_model() called ==================================
2023-07-31 10:39:32,470:INFO:Initializing create_model()
2023-07-31 10:39:32,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:39:32,470:INFO:Checking exceptions
2023-07-31 10:39:32,471:INFO:Importing libraries
2023-07-31 10:39:32,471:INFO:Copying training dataset
2023-07-31 10:39:32,607:INFO:Defining folds
2023-07-31 10:39:32,607:INFO:Declaring metric variables
2023-07-31 10:39:32,611:INFO:Importing untrained model
2023-07-31 10:39:32,615:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 10:39:32,622:INFO:Starting cross validation
2023-07-31 10:39:32,662:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:42:09,099:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:11,893:INFO:Calculating mean and std
2023-07-31 10:42:11,898:INFO:Creating metrics dataframe
2023-07-31 10:42:12,320:INFO:Uploading results into container
2023-07-31 10:42:12,321:INFO:Uploading model into container now
2023-07-31 10:42:12,322:INFO:_master_model_container: 10
2023-07-31 10:42:12,322:INFO:_display_container: 2
2023-07-31 10:42:12,322:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 10:42:12,323:INFO:create_model() successfully completed......................................
2023-07-31 10:42:12,503:INFO:SubProcess create_model() end ==================================
2023-07-31 10:42:12,503:INFO:Creating metrics dataframe
2023-07-31 10:42:12,518:INFO:Initializing Linear Discriminant Analysis
2023-07-31 10:42:12,519:INFO:Total runtime is 4.129077740510305 minutes
2023-07-31 10:42:12,523:INFO:SubProcess create_model() called ==================================
2023-07-31 10:42:12,523:INFO:Initializing create_model()
2023-07-31 10:42:12,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:42:12,523:INFO:Checking exceptions
2023-07-31 10:42:12,523:INFO:Importing libraries
2023-07-31 10:42:12,523:INFO:Copying training dataset
2023-07-31 10:42:12,667:INFO:Defining folds
2023-07-31 10:42:12,667:INFO:Declaring metric variables
2023-07-31 10:42:12,672:INFO:Importing untrained model
2023-07-31 10:42:12,676:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:42:12,683:INFO:Starting cross validation
2023-07-31 10:42:12,725:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:42:19,309:INFO:Calculating mean and std
2023-07-31 10:42:19,312:INFO:Creating metrics dataframe
2023-07-31 10:42:19,757:INFO:Uploading results into container
2023-07-31 10:42:19,758:INFO:Uploading model into container now
2023-07-31 10:42:19,759:INFO:_master_model_container: 11
2023-07-31 10:42:19,759:INFO:_display_container: 2
2023-07-31 10:42:19,759:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:42:19,759:INFO:create_model() successfully completed......................................
2023-07-31 10:42:19,874:INFO:SubProcess create_model() end ==================================
2023-07-31 10:42:19,874:INFO:Creating metrics dataframe
2023-07-31 10:42:19,888:INFO:Initializing Extra Trees Classifier
2023-07-31 10:42:19,888:INFO:Total runtime is 4.251905278364818 minutes
2023-07-31 10:42:19,892:INFO:SubProcess create_model() called ==================================
2023-07-31 10:42:19,892:INFO:Initializing create_model()
2023-07-31 10:42:19,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:42:19,892:INFO:Checking exceptions
2023-07-31 10:42:19,892:INFO:Importing libraries
2023-07-31 10:42:19,892:INFO:Copying training dataset
2023-07-31 10:42:20,034:INFO:Defining folds
2023-07-31 10:42:20,034:INFO:Declaring metric variables
2023-07-31 10:42:20,038:INFO:Importing untrained model
2023-07-31 10:42:20,042:INFO:Extra Trees Classifier Imported successfully
2023-07-31 10:42:20,048:INFO:Starting cross validation
2023-07-31 10:42:20,089:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:42:22,460:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:22,489:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:22,559:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:22,565:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:22,570:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:22,572:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:22,593:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:22,670:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 10:42:24,007:INFO:Calculating mean and std
2023-07-31 10:42:24,009:INFO:Creating metrics dataframe
2023-07-31 10:42:24,163:INFO:Uploading results into container
2023-07-31 10:42:24,164:INFO:Uploading model into container now
2023-07-31 10:42:24,164:INFO:_master_model_container: 12
2023-07-31 10:42:24,164:INFO:_display_container: 2
2023-07-31 10:42:24,165:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 10:42:24,165:INFO:create_model() successfully completed......................................
2023-07-31 10:42:24,288:INFO:SubProcess create_model() end ==================================
2023-07-31 10:42:24,289:INFO:Creating metrics dataframe
2023-07-31 10:42:24,303:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 10:42:24,303:INFO:Total runtime is 4.325482447942099 minutes
2023-07-31 10:42:24,306:INFO:SubProcess create_model() called ==================================
2023-07-31 10:42:24,307:INFO:Initializing create_model()
2023-07-31 10:42:24,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:42:24,307:INFO:Checking exceptions
2023-07-31 10:42:24,307:INFO:Importing libraries
2023-07-31 10:42:24,307:INFO:Copying training dataset
2023-07-31 10:42:24,442:INFO:Defining folds
2023-07-31 10:42:24,442:INFO:Declaring metric variables
2023-07-31 10:42:24,446:INFO:Importing untrained model
2023-07-31 10:42:24,450:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 10:42:24,456:INFO:Starting cross validation
2023-07-31 10:42:24,498:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:44:18,127:INFO:Calculating mean and std
2023-07-31 10:44:18,132:INFO:Creating metrics dataframe
2023-07-31 10:44:18,570:INFO:Uploading results into container
2023-07-31 10:44:18,571:INFO:Uploading model into container now
2023-07-31 10:44:18,571:INFO:_master_model_container: 13
2023-07-31 10:44:18,572:INFO:_display_container: 2
2023-07-31 10:44:18,572:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 10:44:18,572:INFO:create_model() successfully completed......................................
2023-07-31 10:44:18,737:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:18,737:INFO:Creating metrics dataframe
2023-07-31 10:44:18,752:INFO:Initializing Dummy Classifier
2023-07-31 10:44:18,753:INFO:Total runtime is 6.232978586355846 minutes
2023-07-31 10:44:18,756:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:18,757:INFO:Initializing create_model()
2023-07-31 10:44:18,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd151c100>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:18,757:INFO:Checking exceptions
2023-07-31 10:44:18,757:INFO:Importing libraries
2023-07-31 10:44:18,757:INFO:Copying training dataset
2023-07-31 10:44:18,896:INFO:Defining folds
2023-07-31 10:44:18,896:INFO:Declaring metric variables
2023-07-31 10:44:18,901:INFO:Importing untrained model
2023-07-31 10:44:18,904:INFO:Dummy Classifier Imported successfully
2023-07-31 10:44:18,911:INFO:Starting cross validation
2023-07-31 10:44:18,954:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 10:44:21,472:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:44:21,522:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:44:21,600:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:44:21,621:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 10:44:22,284:INFO:Calculating mean and std
2023-07-31 10:44:22,288:INFO:Creating metrics dataframe
2023-07-31 10:44:22,719:INFO:Uploading results into container
2023-07-31 10:44:22,720:INFO:Uploading model into container now
2023-07-31 10:44:22,721:INFO:_master_model_container: 14
2023-07-31 10:44:22,721:INFO:_display_container: 2
2023-07-31 10:44:22,722:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 10:44:22,722:INFO:create_model() successfully completed......................................
2023-07-31 10:44:22,872:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:22,872:INFO:Creating metrics dataframe
2023-07-31 10:44:22,897:INFO:Initializing create_model()
2023-07-31 10:44:22,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9692700>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:22,897:INFO:Checking exceptions
2023-07-31 10:44:22,899:INFO:Importing libraries
2023-07-31 10:44:22,899:INFO:Copying training dataset
2023-07-31 10:44:23,036:INFO:Defining folds
2023-07-31 10:44:23,036:INFO:Declaring metric variables
2023-07-31 10:44:23,037:INFO:Importing untrained model
2023-07-31 10:44:23,037:INFO:Declaring custom model
2023-07-31 10:44:23,037:INFO:Logistic Regression Imported successfully
2023-07-31 10:44:23,077:INFO:Cross validation set to False
2023-07-31 10:44:23,077:INFO:Fitting Model
2023-07-31 10:44:26,710:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:44:26,710:INFO:create_model() successfully completed......................................
2023-07-31 10:44:26,871:INFO:_master_model_container: 14
2023-07-31 10:44:26,871:INFO:_display_container: 2
2023-07-31 10:44:26,872:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:44:26,872:INFO:compare_models() successfully completed......................................
2023-07-31 10:44:26,950:INFO:Initializing set_config()
2023-07-31 10:44:26,951:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, variable=seed, value=42, kwargs={})
2023-07-31 10:44:26,951:INFO:Global variable: seed updated to 42
2023-07-31 10:44:26,951:INFO:set_config() successfully completed......................................
2023-07-31 10:44:27,066:INFO:PyCaret ClassificationExperiment
2023-07-31 10:44:27,066:INFO:Logging name: clf-default-name
2023-07-31 10:44:27,067:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 10:44:27,067:INFO:version 3.0.2
2023-07-31 10:44:27,067:INFO:Initializing setup()
2023-07-31 10:44:27,067:INFO:self.USI: d1e1
2023-07-31 10:44:27,067:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 10:44:27,067:INFO:Checking environment
2023-07-31 10:44:27,067:INFO:python_version: 3.9.16
2023-07-31 10:44:27,067:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 10:44:27,067:INFO:machine: x86_64
2023-07-31 10:44:27,067:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:44:27,067:INFO:Memory: svmem(total=67419119616, available=16495374336, percent=75.5, used=50014052352, free=12857556992, active=45778128896, inactive=6478659584, buffers=53678080, cached=4493832192, shared=215797760, slab=1369038848)
2023-07-31 10:44:27,069:INFO:Physical Core: 28
2023-07-31 10:44:27,069:INFO:Logical Core: 56
2023-07-31 10:44:27,069:INFO:Checking libraries
2023-07-31 10:44:27,069:INFO:System:
2023-07-31 10:44:27,069:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 10:44:27,069:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 10:44:27,069:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 10:44:27,069:INFO:PyCaret required dependencies:
2023-07-31 10:44:27,069:INFO:                 pip: 23.0.1
2023-07-31 10:44:27,069:INFO:          setuptools: 66.0.0
2023-07-31 10:44:27,069:INFO:             pycaret: 3.0.2
2023-07-31 10:44:27,069:INFO:             IPython: 8.13.2
2023-07-31 10:44:27,069:INFO:          ipywidgets: 8.0.6
2023-07-31 10:44:27,069:INFO:                tqdm: 4.65.0
2023-07-31 10:44:27,069:INFO:               numpy: 1.23.5
2023-07-31 10:44:27,069:INFO:              pandas: 1.5.3
2023-07-31 10:44:27,069:INFO:              jinja2: 3.1.2
2023-07-31 10:44:27,069:INFO:               scipy: 1.10.1
2023-07-31 10:44:27,069:INFO:              joblib: 1.2.0
2023-07-31 10:44:27,069:INFO:             sklearn: 1.2.2
2023-07-31 10:44:27,069:INFO:                pyod: 1.0.9
2023-07-31 10:44:27,069:INFO:            imblearn: 0.10.1
2023-07-31 10:44:27,069:INFO:   category_encoders: 2.6.1
2023-07-31 10:44:27,069:INFO:            lightgbm: 3.3.5
2023-07-31 10:44:27,069:INFO:               numba: 0.57.0
2023-07-31 10:44:27,069:INFO:            requests: 2.28.1
2023-07-31 10:44:27,069:INFO:          matplotlib: 3.7.1
2023-07-31 10:44:27,069:INFO:          scikitplot: 0.3.7
2023-07-31 10:44:27,069:INFO:         yellowbrick: 1.5
2023-07-31 10:44:27,069:INFO:              plotly: 5.14.1
2023-07-31 10:44:27,070:INFO:             kaleido: 0.2.1
2023-07-31 10:44:27,070:INFO:         statsmodels: 0.14.0
2023-07-31 10:44:27,070:INFO:              sktime: 0.17.0
2023-07-31 10:44:27,070:INFO:               tbats: 1.1.3
2023-07-31 10:44:27,070:INFO:            pmdarima: 2.0.3
2023-07-31 10:44:27,070:INFO:              psutil: 5.9.5
2023-07-31 10:44:27,070:INFO:PyCaret optional dependencies:
2023-07-31 10:44:27,070:INFO:                shap: Not installed
2023-07-31 10:44:27,070:INFO:           interpret: Not installed
2023-07-31 10:44:27,070:INFO:                umap: Not installed
2023-07-31 10:44:27,070:INFO:    pandas_profiling: Not installed
2023-07-31 10:44:27,070:INFO:  explainerdashboard: Not installed
2023-07-31 10:44:27,070:INFO:             autoviz: Not installed
2023-07-31 10:44:27,070:INFO:           fairlearn: Not installed
2023-07-31 10:44:27,070:INFO:             xgboost: Not installed
2023-07-31 10:44:27,070:INFO:            catboost: Not installed
2023-07-31 10:44:27,070:INFO:              kmodes: Not installed
2023-07-31 10:44:27,070:INFO:             mlxtend: Not installed
2023-07-31 10:44:27,070:INFO:       statsforecast: Not installed
2023-07-31 10:44:27,070:INFO:        tune_sklearn: Not installed
2023-07-31 10:44:27,070:INFO:                 ray: Not installed
2023-07-31 10:44:27,070:INFO:            hyperopt: Not installed
2023-07-31 10:44:27,070:INFO:              optuna: Not installed
2023-07-31 10:44:27,070:INFO:               skopt: Not installed
2023-07-31 10:44:27,070:INFO:              mlflow: Not installed
2023-07-31 10:44:27,070:INFO:              gradio: Not installed
2023-07-31 10:44:27,070:INFO:             fastapi: Not installed
2023-07-31 10:44:27,070:INFO:             uvicorn: Not installed
2023-07-31 10:44:27,070:INFO:              m2cgen: Not installed
2023-07-31 10:44:27,070:INFO:           evidently: Not installed
2023-07-31 10:44:27,070:INFO:               fugue: Not installed
2023-07-31 10:44:27,070:INFO:           streamlit: Not installed
2023-07-31 10:44:27,070:INFO:             prophet: Not installed
2023-07-31 10:44:27,070:INFO:None
2023-07-31 10:44:27,070:INFO:Set up data.
2023-07-31 10:44:27,151:INFO:Set up train/test split.
2023-07-31 10:44:27,159:INFO:Set up index.
2023-07-31 10:44:27,159:INFO:Set up folding strategy.
2023-07-31 10:44:27,159:INFO:Assigning column types.
2023-07-31 10:44:27,163:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 10:44:27,204:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:44:27,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:44:27,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,271:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 10:44:27,272:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:44:27,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,297:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 10:44:27,338:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:44:27,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,405:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 10:44:27,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,431:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 10:44:27,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,565:INFO:Preparing preprocessing pipeline...
2023-07-31 10:44:27,568:INFO:Set up simple imputation.
2023-07-31 10:44:27,598:INFO:Finished creating preprocessing pipeline.
2023-07-31 10:44:27,603:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-07-31 10:44:27,603:INFO:Creating final display dataframe.
2023-07-31 10:44:27,719:INFO:Setup _display_container:                     Description             Value
0                    Session id                44
1                        Target             group
2                   Target type            Binary
3           Original data shape        (742, 294)
4        Transformed data shape        (742, 294)
5   Transformed train set shape        (667, 294)
6    Transformed test set shape         (75, 294)
7              Numeric features               293
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d1e1
2023-07-31 10:44:27,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 10:44:27,861:INFO:setup() successfully completed in 0.91s...............
2023-07-31 10:44:27,867:INFO:Initializing compare_models()
2023-07-31 10:44:27,867:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, include=None, fold=None, round=4, cross_validation=False, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': False, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 10:44:27,867:INFO:Checking exceptions
2023-07-31 10:44:27,873:INFO:Preparing display monitor
2023-07-31 10:44:27,894:INFO:Initializing Logistic Regression
2023-07-31 10:44:27,895:INFO:Total runtime is 2.566973368326823e-06 minutes
2023-07-31 10:44:27,898:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:27,898:INFO:Initializing create_model()
2023-07-31 10:44:27,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:27,898:INFO:Checking exceptions
2023-07-31 10:44:27,898:INFO:Importing libraries
2023-07-31 10:44:27,899:INFO:Copying training dataset
2023-07-31 10:44:27,905:INFO:Defining folds
2023-07-31 10:44:27,905:INFO:Declaring metric variables
2023-07-31 10:44:27,909:INFO:Importing untrained model
2023-07-31 10:44:27,912:INFO:Logistic Regression Imported successfully
2023-07-31 10:44:27,917:INFO:Cross validation set to False
2023-07-31 10:44:27,917:INFO:Fitting Model
2023-07-31 10:44:28,040:INFO:Initializing predict_model()
2023-07-31 10:44:28,040:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=44,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd1f3d310>)
2023-07-31 10:44:28,040:INFO:Checking exceptions
2023-07-31 10:44:28,040:INFO:Preloading libraries
2023-07-31 10:44:28,367:INFO:_display_container: 2
2023-07-31 10:44:28,478:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:44:28,478:INFO:create_model() successfully completed......................................
2023-07-31 10:44:28,591:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:28,591:INFO:Creating metrics dataframe
2023-07-31 10:44:28,600:INFO:Initializing K Neighbors Classifier
2023-07-31 10:44:28,600:INFO:Total runtime is 0.011765873432159424 minutes
2023-07-31 10:44:28,603:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:28,604:INFO:Initializing create_model()
2023-07-31 10:44:28,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:28,604:INFO:Checking exceptions
2023-07-31 10:44:28,604:INFO:Importing libraries
2023-07-31 10:44:28,604:INFO:Copying training dataset
2023-07-31 10:44:28,609:INFO:Defining folds
2023-07-31 10:44:28,609:INFO:Declaring metric variables
2023-07-31 10:44:28,612:INFO:Importing untrained model
2023-07-31 10:44:28,616:INFO:K Neighbors Classifier Imported successfully
2023-07-31 10:44:28,620:INFO:Cross validation set to False
2023-07-31 10:44:28,620:INFO:Fitting Model
2023-07-31 10:44:28,660:INFO:Initializing predict_model()
2023-07-31 10:44:28,660:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fa8f1700>)
2023-07-31 10:44:28,660:INFO:Checking exceptions
2023-07-31 10:44:28,660:INFO:Preloading libraries
2023-07-31 10:44:29,050:INFO:_display_container: 2
2023-07-31 10:44:29,170:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 10:44:29,171:INFO:create_model() successfully completed......................................
2023-07-31 10:44:29,287:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:29,287:INFO:Creating metrics dataframe
2023-07-31 10:44:29,298:INFO:Initializing Naive Bayes
2023-07-31 10:44:29,299:INFO:Total runtime is 0.023402726650238036 minutes
2023-07-31 10:44:29,302:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:29,302:INFO:Initializing create_model()
2023-07-31 10:44:29,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:29,303:INFO:Checking exceptions
2023-07-31 10:44:29,303:INFO:Importing libraries
2023-07-31 10:44:29,303:INFO:Copying training dataset
2023-07-31 10:44:29,309:INFO:Defining folds
2023-07-31 10:44:29,309:INFO:Declaring metric variables
2023-07-31 10:44:29,313:INFO:Importing untrained model
2023-07-31 10:44:29,317:INFO:Naive Bayes Imported successfully
2023-07-31 10:44:29,321:INFO:Cross validation set to False
2023-07-31 10:44:29,321:INFO:Fitting Model
2023-07-31 10:44:29,367:INFO:Initializing predict_model()
2023-07-31 10:44:29,367:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fa8f1c10>)
2023-07-31 10:44:29,367:INFO:Checking exceptions
2023-07-31 10:44:29,368:INFO:Preloading libraries
2023-07-31 10:44:29,577:INFO:_display_container: 2
2023-07-31 10:44:29,690:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 10:44:29,690:INFO:create_model() successfully completed......................................
2023-07-31 10:44:29,807:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:29,807:INFO:Creating metrics dataframe
2023-07-31 10:44:29,819:INFO:Initializing Decision Tree Classifier
2023-07-31 10:44:29,819:INFO:Total runtime is 0.03207603295644124 minutes
2023-07-31 10:44:29,822:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:29,823:INFO:Initializing create_model()
2023-07-31 10:44:29,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:29,823:INFO:Checking exceptions
2023-07-31 10:44:29,823:INFO:Importing libraries
2023-07-31 10:44:29,823:INFO:Copying training dataset
2023-07-31 10:44:29,830:INFO:Defining folds
2023-07-31 10:44:29,830:INFO:Declaring metric variables
2023-07-31 10:44:29,833:INFO:Importing untrained model
2023-07-31 10:44:29,837:INFO:Decision Tree Classifier Imported successfully
2023-07-31 10:44:29,842:INFO:Cross validation set to False
2023-07-31 10:44:29,842:INFO:Fitting Model
2023-07-31 10:44:29,921:INFO:Initializing predict_model()
2023-07-31 10:44:29,921:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=44, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fa8fc310>)
2023-07-31 10:44:29,921:INFO:Checking exceptions
2023-07-31 10:44:29,921:INFO:Preloading libraries
2023-07-31 10:44:30,117:INFO:_display_container: 2
2023-07-31 10:44:30,228:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=44, splitter='best')
2023-07-31 10:44:30,228:INFO:create_model() successfully completed......................................
2023-07-31 10:44:30,342:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:30,342:INFO:Creating metrics dataframe
2023-07-31 10:44:30,354:INFO:Initializing SVM - Linear Kernel
2023-07-31 10:44:30,354:INFO:Total runtime is 0.04099393288294474 minutes
2023-07-31 10:44:30,357:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:30,358:INFO:Initializing create_model()
2023-07-31 10:44:30,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:30,358:INFO:Checking exceptions
2023-07-31 10:44:30,358:INFO:Importing libraries
2023-07-31 10:44:30,358:INFO:Copying training dataset
2023-07-31 10:44:30,365:INFO:Defining folds
2023-07-31 10:44:30,365:INFO:Declaring metric variables
2023-07-31 10:44:30,368:INFO:Importing untrained model
2023-07-31 10:44:30,372:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 10:44:30,377:INFO:Cross validation set to False
2023-07-31 10:44:30,377:INFO:Fitting Model
2023-07-31 10:44:30,435:INFO:Initializing predict_model()
2023-07-31 10:44:30,435:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('actual_estimator',
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=44,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd1378f70>)
2023-07-31 10:44:30,435:INFO:Checking exceptions
2023-07-31 10:44:30,435:INFO:Preloading libraries
2023-07-31 10:44:30,679:INFO:_display_container: 2
2023-07-31 10:44:30,794:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=44, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 10:44:30,794:INFO:create_model() successfully completed......................................
2023-07-31 10:44:30,910:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:30,911:INFO:Creating metrics dataframe
2023-07-31 10:44:30,923:INFO:Initializing Ridge Classifier
2023-07-31 10:44:30,923:INFO:Total runtime is 0.05047380129496257 minutes
2023-07-31 10:44:30,926:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:30,927:INFO:Initializing create_model()
2023-07-31 10:44:30,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:30,927:INFO:Checking exceptions
2023-07-31 10:44:30,927:INFO:Importing libraries
2023-07-31 10:44:30,927:INFO:Copying training dataset
2023-07-31 10:44:30,933:INFO:Defining folds
2023-07-31 10:44:30,933:INFO:Declaring metric variables
2023-07-31 10:44:30,937:INFO:Importing untrained model
2023-07-31 10:44:30,940:INFO:Ridge Classifier Imported successfully
2023-07-31 10:44:30,945:INFO:Cross validation set to False
2023-07-31 10:44:30,945:INFO:Fitting Model
2023-07-31 10:44:31,031:INFO:Initializing predict_model()
2023-07-31 10:44:31,031:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=44, solver='auto',
                                 tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faad43a0>)
2023-07-31 10:44:31,031:INFO:Checking exceptions
2023-07-31 10:44:31,031:INFO:Preloading libraries
2023-07-31 10:44:31,325:INFO:_display_container: 2
2023-07-31 10:44:31,435:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=44, solver='auto',
                tol=0.0001)
2023-07-31 10:44:31,435:INFO:create_model() successfully completed......................................
2023-07-31 10:44:31,600:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:31,600:INFO:Creating metrics dataframe
2023-07-31 10:44:31,613:INFO:Initializing Random Forest Classifier
2023-07-31 10:44:31,613:INFO:Total runtime is 0.06197696924209595 minutes
2023-07-31 10:44:31,616:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:31,617:INFO:Initializing create_model()
2023-07-31 10:44:31,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:31,617:INFO:Checking exceptions
2023-07-31 10:44:31,617:INFO:Importing libraries
2023-07-31 10:44:31,617:INFO:Copying training dataset
2023-07-31 10:44:31,624:INFO:Defining folds
2023-07-31 10:44:31,624:INFO:Declaring metric variables
2023-07-31 10:44:31,627:INFO:Importing untrained model
2023-07-31 10:44:31,631:INFO:Random Forest Classifier Imported successfully
2023-07-31 10:44:31,635:INFO:Cross validation set to False
2023-07-31 10:44:31,635:INFO:Fitting Model
2023-07-31 10:44:32,252:INFO:Initializing predict_model()
2023-07-31 10:44:32,252:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=44,
                                        verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f998cca0>)
2023-07-31 10:44:32,252:INFO:Checking exceptions
2023-07-31 10:44:32,252:INFO:Preloading libraries
2023-07-31 10:44:32,611:INFO:_display_container: 2
2023-07-31 10:44:32,723:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=44, verbose=0, warm_start=False)
2023-07-31 10:44:32,723:INFO:create_model() successfully completed......................................
2023-07-31 10:44:32,876:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:32,876:INFO:Creating metrics dataframe
2023-07-31 10:44:32,890:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 10:44:32,890:INFO:Total runtime is 0.08325695991516113 minutes
2023-07-31 10:44:32,894:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:32,894:INFO:Initializing create_model()
2023-07-31 10:44:32,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:32,894:INFO:Checking exceptions
2023-07-31 10:44:32,894:INFO:Importing libraries
2023-07-31 10:44:32,894:INFO:Copying training dataset
2023-07-31 10:44:32,900:INFO:Defining folds
2023-07-31 10:44:32,901:INFO:Declaring metric variables
2023-07-31 10:44:32,905:INFO:Importing untrained model
2023-07-31 10:44:32,908:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 10:44:32,913:INFO:Cross validation set to False
2023-07-31 10:44:32,913:INFO:Fitting Model
2023-07-31 10:44:33,015:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 10:44:33,242:INFO:Initializing predict_model()
2023-07-31 10:44:33,242:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f904f700>)
2023-07-31 10:44:33,243:INFO:Checking exceptions
2023-07-31 10:44:33,243:INFO:Preloading libraries
2023-07-31 10:44:33,534:INFO:_display_container: 2
2023-07-31 10:44:33,642:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 10:44:33,642:INFO:create_model() successfully completed......................................
2023-07-31 10:44:33,793:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:33,793:INFO:Creating metrics dataframe
2023-07-31 10:44:33,807:INFO:Initializing Ada Boost Classifier
2023-07-31 10:44:33,808:INFO:Total runtime is 0.09855338335037231 minutes
2023-07-31 10:44:33,811:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:33,812:INFO:Initializing create_model()
2023-07-31 10:44:33,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:33,812:INFO:Checking exceptions
2023-07-31 10:44:33,812:INFO:Importing libraries
2023-07-31 10:44:33,812:INFO:Copying training dataset
2023-07-31 10:44:33,818:INFO:Defining folds
2023-07-31 10:44:33,818:INFO:Declaring metric variables
2023-07-31 10:44:33,822:INFO:Importing untrained model
2023-07-31 10:44:33,826:INFO:Ada Boost Classifier Imported successfully
2023-07-31 10:44:33,831:INFO:Cross validation set to False
2023-07-31 10:44:33,831:INFO:Fitting Model
2023-07-31 10:44:34,977:INFO:Initializing predict_model()
2023-07-31 10:44:34,978:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=44))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f998ce50>)
2023-07-31 10:44:34,978:INFO:Checking exceptions
2023-07-31 10:44:34,978:INFO:Preloading libraries
2023-07-31 10:44:35,228:INFO:_display_container: 2
2023-07-31 10:44:35,340:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=44)
2023-07-31 10:44:35,340:INFO:create_model() successfully completed......................................
2023-07-31 10:44:35,501:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:35,502:INFO:Creating metrics dataframe
2023-07-31 10:44:35,515:INFO:Initializing Gradient Boosting Classifier
2023-07-31 10:44:35,516:INFO:Total runtime is 0.12702032725016277 minutes
2023-07-31 10:44:35,519:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:35,520:INFO:Initializing create_model()
2023-07-31 10:44:35,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:35,520:INFO:Checking exceptions
2023-07-31 10:44:35,520:INFO:Importing libraries
2023-07-31 10:44:35,520:INFO:Copying training dataset
2023-07-31 10:44:35,526:INFO:Defining folds
2023-07-31 10:44:35,526:INFO:Declaring metric variables
2023-07-31 10:44:35,530:INFO:Importing untrained model
2023-07-31 10:44:35,534:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 10:44:35,539:INFO:Cross validation set to False
2023-07-31 10:44:35,539:INFO:Fitting Model
2023-07-31 10:44:39,285:INFO:Initializing predict_model()
2023-07-31 10:44:39,285:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=44, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f904da60>)
2023-07-31 10:44:39,285:INFO:Checking exceptions
2023-07-31 10:44:39,285:INFO:Preloading libraries
2023-07-31 10:44:39,821:INFO:_display_container: 2
2023-07-31 10:44:39,955:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=44, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 10:44:39,956:INFO:create_model() successfully completed......................................
2023-07-31 10:44:40,321:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:40,321:INFO:Creating metrics dataframe
2023-07-31 10:44:40,338:INFO:Initializing Linear Discriminant Analysis
2023-07-31 10:44:40,338:INFO:Total runtime is 0.20739930868148804 minutes
2023-07-31 10:44:40,343:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:40,344:INFO:Initializing create_model()
2023-07-31 10:44:40,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:40,344:INFO:Checking exceptions
2023-07-31 10:44:40,344:INFO:Importing libraries
2023-07-31 10:44:40,344:INFO:Copying training dataset
2023-07-31 10:44:40,352:INFO:Defining folds
2023-07-31 10:44:40,352:INFO:Declaring metric variables
2023-07-31 10:44:40,358:INFO:Importing untrained model
2023-07-31 10:44:40,363:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 10:44:40,369:INFO:Cross validation set to False
2023-07-31 10:44:40,369:INFO:Fitting Model
2023-07-31 10:44:40,946:INFO:Initializing predict_model()
2023-07-31 10:44:40,946:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f9a2b700>)
2023-07-31 10:44:40,946:INFO:Checking exceptions
2023-07-31 10:44:40,946:INFO:Preloading libraries
2023-07-31 10:44:41,472:INFO:_display_container: 2
2023-07-31 10:44:41,600:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 10:44:41,600:INFO:create_model() successfully completed......................................
2023-07-31 10:44:41,888:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:41,889:INFO:Creating metrics dataframe
2023-07-31 10:44:41,904:INFO:Initializing Extra Trees Classifier
2023-07-31 10:44:41,904:INFO:Total runtime is 0.2334959308306376 minutes
2023-07-31 10:44:41,908:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:41,909:INFO:Initializing create_model()
2023-07-31 10:44:41,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:41,909:INFO:Checking exceptions
2023-07-31 10:44:41,909:INFO:Importing libraries
2023-07-31 10:44:41,909:INFO:Copying training dataset
2023-07-31 10:44:41,915:INFO:Defining folds
2023-07-31 10:44:41,916:INFO:Declaring metric variables
2023-07-31 10:44:41,920:INFO:Importing untrained model
2023-07-31 10:44:41,924:INFO:Extra Trees Classifier Imported successfully
2023-07-31 10:44:41,929:INFO:Cross validation set to False
2023-07-31 10:44:41,929:INFO:Fitting Model
2023-07-31 10:44:42,523:INFO:Initializing predict_model()
2023-07-31 10:44:42,523:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=44,
                                      verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fa8f1280>)
2023-07-31 10:44:42,523:INFO:Checking exceptions
2023-07-31 10:44:42,524:INFO:Preloading libraries
2023-07-31 10:44:42,902:INFO:_display_container: 2
2023-07-31 10:44:43,024:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=44, verbose=0, warm_start=False)
2023-07-31 10:44:43,024:INFO:create_model() successfully completed......................................
2023-07-31 10:44:43,146:INFO:SubProcess create_model() end ==================================
2023-07-31 10:44:43,146:INFO:Creating metrics dataframe
2023-07-31 10:44:43,161:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 10:44:43,161:INFO:Total runtime is 0.25444282293319703 minutes
2023-07-31 10:44:43,165:INFO:SubProcess create_model() called ==================================
2023-07-31 10:44:43,165:INFO:Initializing create_model()
2023-07-31 10:44:43,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:44:43,165:INFO:Checking exceptions
2023-07-31 10:44:43,165:INFO:Importing libraries
2023-07-31 10:44:43,165:INFO:Copying training dataset
2023-07-31 10:44:43,172:INFO:Defining folds
2023-07-31 10:44:43,172:INFO:Declaring metric variables
2023-07-31 10:44:43,176:INFO:Importing untrained model
2023-07-31 10:44:43,179:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 10:44:43,184:INFO:Cross validation set to False
2023-07-31 10:44:43,184:INFO:Fitting Model
2023-07-31 10:45:26,377:INFO:Initializing predict_model()
2023-07-31 10:45:26,377:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=44,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f904db80>)
2023-07-31 10:45:26,378:INFO:Checking exceptions
2023-07-31 10:45:26,378:INFO:Preloading libraries
2023-07-31 10:45:26,740:INFO:_display_container: 2
2023-07-31 10:45:26,880:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=44, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 10:45:26,880:INFO:create_model() successfully completed......................................
2023-07-31 10:45:27,059:INFO:SubProcess create_model() end ==================================
2023-07-31 10:45:27,060:INFO:Creating metrics dataframe
2023-07-31 10:45:27,075:INFO:Initializing Dummy Classifier
2023-07-31 10:45:27,075:INFO:Total runtime is 0.9863465825716655 minutes
2023-07-31 10:45:27,079:INFO:SubProcess create_model() called ==================================
2023-07-31 10:45:27,079:INFO:Initializing create_model()
2023-07-31 10:45:27,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd150d340>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:45:27,080:INFO:Checking exceptions
2023-07-31 10:45:27,080:INFO:Importing libraries
2023-07-31 10:45:27,080:INFO:Copying training dataset
2023-07-31 10:45:27,087:INFO:Defining folds
2023-07-31 10:45:27,088:INFO:Declaring metric variables
2023-07-31 10:45:27,092:INFO:Importing untrained model
2023-07-31 10:45:27,095:INFO:Dummy Classifier Imported successfully
2023-07-31 10:45:27,100:INFO:Cross validation set to False
2023-07-31 10:45:27,101:INFO:Fitting Model
2023-07-31 10:45:27,144:INFO:Initializing predict_model()
2023-07-31 10:45:27,144:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DummyClassifier(constant=None, random_state=44,
                                 strategy='prior'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faad44c0>)
2023-07-31 10:45:27,144:INFO:Checking exceptions
2023-07-31 10:45:27,144:INFO:Preloading libraries
2023-07-31 10:45:27,410:INFO:_display_container: 2
2023-07-31 10:45:27,533:INFO:DummyClassifier(constant=None, random_state=44, strategy='prior')
2023-07-31 10:45:27,533:INFO:create_model() successfully completed......................................
2023-07-31 10:45:27,718:INFO:SubProcess create_model() end ==================================
2023-07-31 10:45:27,718:INFO:Creating metrics dataframe
2023-07-31 10:45:27,744:INFO:Initializing create_model()
2023-07-31 10:45:27,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9134790>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 10:45:27,744:INFO:Checking exceptions
2023-07-31 10:45:27,746:INFO:Importing libraries
2023-07-31 10:45:27,747:INFO:Copying training dataset
2023-07-31 10:45:27,753:INFO:Defining folds
2023-07-31 10:45:27,753:INFO:Declaring metric variables
2023-07-31 10:45:27,754:INFO:Importing untrained model
2023-07-31 10:45:27,754:INFO:Declaring custom model
2023-07-31 10:45:27,755:INFO:Logistic Regression Imported successfully
2023-07-31 10:45:27,756:INFO:Cross validation set to False
2023-07-31 10:45:27,756:INFO:Fitting Model
2023-07-31 10:45:28,049:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:45:28,049:INFO:create_model() successfully completed......................................
2023-07-31 10:45:28,239:INFO:_master_model_container: 0
2023-07-31 10:45:28,239:INFO:_display_container: 2
2023-07-31 10:45:28,240:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 10:45:28,240:INFO:compare_models() successfully completed......................................
2023-07-31 14:33:46,812:INFO:Initializing set_config()
2023-07-31 14:33:46,812:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, variable=seed, value=42, kwargs={})
2023-07-31 14:33:46,812:INFO:Global variable: seed updated to 42
2023-07-31 14:33:46,813:INFO:set_config() successfully completed......................................
2023-07-31 14:33:46,931:INFO:PyCaret ClassificationExperiment
2023-07-31 14:33:46,931:INFO:Logging name: clf-default-name
2023-07-31 14:33:46,932:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 14:33:46,932:INFO:version 3.0.2
2023-07-31 14:33:46,932:INFO:Initializing setup()
2023-07-31 14:33:46,932:INFO:self.USI: 71a3
2023-07-31 14:33:46,932:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 14:33:46,932:INFO:Checking environment
2023-07-31 14:33:46,932:INFO:python_version: 3.9.16
2023-07-31 14:33:46,932:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 14:33:46,932:INFO:machine: x86_64
2023-07-31 14:33:46,932:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:33:46,932:INFO:Memory: svmem(total=67419119616, available=35563487232, percent=47.3, used=30938361856, free=26925809664, active=31965630464, inactive=6158577664, buffers=114356224, cached=9440591872, shared=223301632, slab=1429069824)
2023-07-31 14:33:46,934:INFO:Physical Core: 28
2023-07-31 14:33:46,934:INFO:Logical Core: 56
2023-07-31 14:33:46,934:INFO:Checking libraries
2023-07-31 14:33:46,934:INFO:System:
2023-07-31 14:33:46,934:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 14:33:46,934:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 14:33:46,934:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:33:46,934:INFO:PyCaret required dependencies:
2023-07-31 14:33:46,934:INFO:                 pip: 23.0.1
2023-07-31 14:33:46,934:INFO:          setuptools: 66.0.0
2023-07-31 14:33:46,934:INFO:             pycaret: 3.0.2
2023-07-31 14:33:46,934:INFO:             IPython: 8.13.2
2023-07-31 14:33:46,934:INFO:          ipywidgets: 8.0.6
2023-07-31 14:33:46,934:INFO:                tqdm: 4.65.0
2023-07-31 14:33:46,934:INFO:               numpy: 1.23.5
2023-07-31 14:33:46,934:INFO:              pandas: 1.5.3
2023-07-31 14:33:46,934:INFO:              jinja2: 3.1.2
2023-07-31 14:33:46,934:INFO:               scipy: 1.10.1
2023-07-31 14:33:46,934:INFO:              joblib: 1.2.0
2023-07-31 14:33:46,934:INFO:             sklearn: 1.2.2
2023-07-31 14:33:46,935:INFO:                pyod: 1.0.9
2023-07-31 14:33:46,935:INFO:            imblearn: 0.10.1
2023-07-31 14:33:46,935:INFO:   category_encoders: 2.6.1
2023-07-31 14:33:46,935:INFO:            lightgbm: 3.3.5
2023-07-31 14:33:46,935:INFO:               numba: 0.57.0
2023-07-31 14:33:46,935:INFO:            requests: 2.28.1
2023-07-31 14:33:46,935:INFO:          matplotlib: 3.7.1
2023-07-31 14:33:46,935:INFO:          scikitplot: 0.3.7
2023-07-31 14:33:46,935:INFO:         yellowbrick: 1.5
2023-07-31 14:33:46,935:INFO:              plotly: 5.14.1
2023-07-31 14:33:46,935:INFO:             kaleido: 0.2.1
2023-07-31 14:33:46,935:INFO:         statsmodels: 0.14.0
2023-07-31 14:33:46,935:INFO:              sktime: 0.17.0
2023-07-31 14:33:46,935:INFO:               tbats: 1.1.3
2023-07-31 14:33:46,935:INFO:            pmdarima: 2.0.3
2023-07-31 14:33:46,935:INFO:              psutil: 5.9.5
2023-07-31 14:33:46,935:INFO:PyCaret optional dependencies:
2023-07-31 14:33:46,935:INFO:                shap: Not installed
2023-07-31 14:33:46,935:INFO:           interpret: Not installed
2023-07-31 14:33:46,935:INFO:                umap: Not installed
2023-07-31 14:33:46,935:INFO:    pandas_profiling: Not installed
2023-07-31 14:33:46,935:INFO:  explainerdashboard: Not installed
2023-07-31 14:33:46,935:INFO:             autoviz: Not installed
2023-07-31 14:33:46,935:INFO:           fairlearn: Not installed
2023-07-31 14:33:46,935:INFO:             xgboost: Not installed
2023-07-31 14:33:46,935:INFO:            catboost: Not installed
2023-07-31 14:33:46,935:INFO:              kmodes: Not installed
2023-07-31 14:33:46,935:INFO:             mlxtend: Not installed
2023-07-31 14:33:46,935:INFO:       statsforecast: Not installed
2023-07-31 14:33:46,935:INFO:        tune_sklearn: Not installed
2023-07-31 14:33:46,935:INFO:                 ray: Not installed
2023-07-31 14:33:46,935:INFO:            hyperopt: Not installed
2023-07-31 14:33:46,935:INFO:              optuna: Not installed
2023-07-31 14:33:46,935:INFO:               skopt: Not installed
2023-07-31 14:33:46,935:INFO:              mlflow: Not installed
2023-07-31 14:33:46,936:INFO:              gradio: Not installed
2023-07-31 14:33:46,936:INFO:             fastapi: Not installed
2023-07-31 14:33:46,936:INFO:             uvicorn: Not installed
2023-07-31 14:33:46,936:INFO:              m2cgen: Not installed
2023-07-31 14:33:46,936:INFO:           evidently: Not installed
2023-07-31 14:33:46,936:INFO:               fugue: Not installed
2023-07-31 14:33:46,936:INFO:           streamlit: Not installed
2023-07-31 14:33:46,936:INFO:             prophet: Not installed
2023-07-31 14:33:46,936:INFO:None
2023-07-31 14:33:46,936:INFO:Set up data.
2023-07-31 14:33:50,742:INFO:Set up train/test split.
2023-07-31 14:33:50,895:INFO:Set up index.
2023-07-31 14:33:50,896:INFO:Set up folding strategy.
2023-07-31 14:33:50,896:INFO:Assigning column types.
2023-07-31 14:33:50,963:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 14:33:51,006:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:33:51,007:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:33:51,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:33:51,078:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:33:51,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,106:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 14:33:51,150:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:33:51,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,222:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:33:51,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,250:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 14:33:51,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:51,393:INFO:Preparing preprocessing pipeline...
2023-07-31 14:33:51,408:INFO:Set up simple imputation.
2023-07-31 14:33:51,422:INFO:Set up column name cleaning.
2023-07-31 14:33:52,397:INFO:Finished creating preprocessing pipeline.
2023-07-31 14:33:52,465:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 14:33:52,465:INFO:Creating final display dataframe.
2023-07-31 14:33:55,298:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (421, 11886)
4        Transformed data shape      (421, 11886)
5   Transformed train set shape      (357, 11886)
6    Transformed test set shape       (64, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              71a3
2023-07-31 14:33:55,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:55,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:55,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:55,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:33:55,441:INFO:setup() successfully completed in 8.63s...............
2023-07-31 14:33:55,446:INFO:Initializing compare_models()
2023-07-31 14:33:55,446:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 14:33:55,446:INFO:Checking exceptions
2023-07-31 14:33:55,499:INFO:Preparing display monitor
2023-07-31 14:33:55,523:INFO:Initializing Logistic Regression
2023-07-31 14:33:55,523:INFO:Total runtime is 3.345807393391927e-06 minutes
2023-07-31 14:33:55,526:INFO:SubProcess create_model() called ==================================
2023-07-31 14:33:55,526:INFO:Initializing create_model()
2023-07-31 14:33:55,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:33:55,526:INFO:Checking exceptions
2023-07-31 14:33:55,527:INFO:Importing libraries
2023-07-31 14:33:55,527:INFO:Copying training dataset
2023-07-31 14:33:55,599:INFO:Defining folds
2023-07-31 14:33:55,599:INFO:Declaring metric variables
2023-07-31 14:33:55,603:INFO:Importing untrained model
2023-07-31 14:33:55,607:INFO:Logistic Regression Imported successfully
2023-07-31 14:33:55,614:INFO:Starting cross validation
2023-07-31 14:33:55,656:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:34:03,572:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:05,464:INFO:Calculating mean and std
2023-07-31 14:34:05,467:INFO:Creating metrics dataframe
2023-07-31 14:34:05,918:INFO:Uploading results into container
2023-07-31 14:34:05,920:INFO:Uploading model into container now
2023-07-31 14:34:05,921:INFO:_master_model_container: 1
2023-07-31 14:34:05,922:INFO:_display_container: 2
2023-07-31 14:34:05,923:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:34:05,923:INFO:create_model() successfully completed......................................
2023-07-31 14:34:06,114:INFO:SubProcess create_model() end ==================================
2023-07-31 14:34:06,114:INFO:Creating metrics dataframe
2023-07-31 14:34:06,126:INFO:Initializing K Neighbors Classifier
2023-07-31 14:34:06,126:INFO:Total runtime is 0.17673282623291015 minutes
2023-07-31 14:34:06,130:INFO:SubProcess create_model() called ==================================
2023-07-31 14:34:06,131:INFO:Initializing create_model()
2023-07-31 14:34:06,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:34:06,131:INFO:Checking exceptions
2023-07-31 14:34:06,131:INFO:Importing libraries
2023-07-31 14:34:06,131:INFO:Copying training dataset
2023-07-31 14:34:06,203:INFO:Defining folds
2023-07-31 14:34:06,203:INFO:Declaring metric variables
2023-07-31 14:34:06,208:INFO:Importing untrained model
2023-07-31 14:34:06,212:INFO:K Neighbors Classifier Imported successfully
2023-07-31 14:34:06,220:INFO:Starting cross validation
2023-07-31 14:34:06,263:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:34:09,612:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:09,775:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:11,162:INFO:Calculating mean and std
2023-07-31 14:34:11,165:INFO:Creating metrics dataframe
2023-07-31 14:34:11,355:INFO:Uploading results into container
2023-07-31 14:34:11,356:INFO:Uploading model into container now
2023-07-31 14:34:11,357:INFO:_master_model_container: 2
2023-07-31 14:34:11,357:INFO:_display_container: 2
2023-07-31 14:34:11,357:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 14:34:11,357:INFO:create_model() successfully completed......................................
2023-07-31 14:34:11,499:INFO:SubProcess create_model() end ==================================
2023-07-31 14:34:11,499:INFO:Creating metrics dataframe
2023-07-31 14:34:11,511:INFO:Initializing Naive Bayes
2023-07-31 14:34:11,512:INFO:Total runtime is 0.26648505131403605 minutes
2023-07-31 14:34:11,515:INFO:SubProcess create_model() called ==================================
2023-07-31 14:34:11,516:INFO:Initializing create_model()
2023-07-31 14:34:11,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:34:11,516:INFO:Checking exceptions
2023-07-31 14:34:11,516:INFO:Importing libraries
2023-07-31 14:34:11,516:INFO:Copying training dataset
2023-07-31 14:34:11,587:INFO:Defining folds
2023-07-31 14:34:11,587:INFO:Declaring metric variables
2023-07-31 14:34:11,591:INFO:Importing untrained model
2023-07-31 14:34:11,595:INFO:Naive Bayes Imported successfully
2023-07-31 14:34:11,602:INFO:Starting cross validation
2023-07-31 14:34:11,643:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:34:14,799:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:14,859:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:16,088:INFO:Calculating mean and std
2023-07-31 14:34:16,090:INFO:Creating metrics dataframe
2023-07-31 14:34:16,313:INFO:Uploading results into container
2023-07-31 14:34:16,314:INFO:Uploading model into container now
2023-07-31 14:34:16,314:INFO:_master_model_container: 3
2023-07-31 14:34:16,314:INFO:_display_container: 2
2023-07-31 14:34:16,314:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 14:34:16,314:INFO:create_model() successfully completed......................................
2023-07-31 14:34:16,451:INFO:SubProcess create_model() end ==================================
2023-07-31 14:34:16,451:INFO:Creating metrics dataframe
2023-07-31 14:34:16,464:INFO:Initializing Decision Tree Classifier
2023-07-31 14:34:16,465:INFO:Total runtime is 0.34903473059336343 minutes
2023-07-31 14:34:16,469:INFO:SubProcess create_model() called ==================================
2023-07-31 14:34:16,469:INFO:Initializing create_model()
2023-07-31 14:34:16,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:34:16,470:INFO:Checking exceptions
2023-07-31 14:34:16,470:INFO:Importing libraries
2023-07-31 14:34:16,470:INFO:Copying training dataset
2023-07-31 14:34:16,541:INFO:Defining folds
2023-07-31 14:34:16,542:INFO:Declaring metric variables
2023-07-31 14:34:16,547:INFO:Importing untrained model
2023-07-31 14:34:16,552:INFO:Decision Tree Classifier Imported successfully
2023-07-31 14:34:16,560:INFO:Starting cross validation
2023-07-31 14:34:16,604:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:34:20,358:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:20,480:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:21,477:INFO:Calculating mean and std
2023-07-31 14:34:21,480:INFO:Creating metrics dataframe
2023-07-31 14:34:21,656:INFO:Uploading results into container
2023-07-31 14:34:21,657:INFO:Uploading model into container now
2023-07-31 14:34:21,657:INFO:_master_model_container: 4
2023-07-31 14:34:21,658:INFO:_display_container: 2
2023-07-31 14:34:21,658:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 14:34:21,658:INFO:create_model() successfully completed......................................
2023-07-31 14:34:21,783:INFO:SubProcess create_model() end ==================================
2023-07-31 14:34:21,783:INFO:Creating metrics dataframe
2023-07-31 14:34:21,795:INFO:Initializing SVM - Linear Kernel
2023-07-31 14:34:21,796:INFO:Total runtime is 0.4378848592440287 minutes
2023-07-31 14:34:21,799:INFO:SubProcess create_model() called ==================================
2023-07-31 14:34:21,799:INFO:Initializing create_model()
2023-07-31 14:34:21,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:34:21,800:INFO:Checking exceptions
2023-07-31 14:34:21,800:INFO:Importing libraries
2023-07-31 14:34:21,800:INFO:Copying training dataset
2023-07-31 14:34:21,867:INFO:Defining folds
2023-07-31 14:34:21,867:INFO:Declaring metric variables
2023-07-31 14:34:21,871:INFO:Importing untrained model
2023-07-31 14:34:21,874:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 14:34:21,881:INFO:Starting cross validation
2023-07-31 14:34:21,923:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:34:25,168:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:34:25,190:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:34:25,211:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:34:25,227:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:34:25,258:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:34:25,337:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:34:26,288:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:34:26,403:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:34:26,427:INFO:Calculating mean and std
2023-07-31 14:34:26,431:INFO:Creating metrics dataframe
2023-07-31 14:34:26,887:INFO:Uploading results into container
2023-07-31 14:34:26,888:INFO:Uploading model into container now
2023-07-31 14:34:26,889:INFO:_master_model_container: 5
2023-07-31 14:34:26,889:INFO:_display_container: 2
2023-07-31 14:34:26,889:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 14:34:26,890:INFO:create_model() successfully completed......................................
2023-07-31 14:34:27,055:INFO:SubProcess create_model() end ==================================
2023-07-31 14:34:27,056:INFO:Creating metrics dataframe
2023-07-31 14:34:27,068:INFO:Initializing Ridge Classifier
2023-07-31 14:34:27,068:INFO:Total runtime is 0.5257611632347107 minutes
2023-07-31 14:34:27,072:INFO:SubProcess create_model() called ==================================
2023-07-31 14:34:27,072:INFO:Initializing create_model()
2023-07-31 14:34:27,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:34:27,072:INFO:Checking exceptions
2023-07-31 14:34:27,072:INFO:Importing libraries
2023-07-31 14:34:27,073:INFO:Copying training dataset
2023-07-31 14:34:27,138:INFO:Defining folds
2023-07-31 14:34:27,138:INFO:Declaring metric variables
2023-07-31 14:34:27,142:INFO:Importing untrained model
2023-07-31 14:34:27,146:INFO:Ridge Classifier Imported successfully
2023-07-31 14:34:27,152:INFO:Starting cross validation
2023-07-31 14:34:27,194:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:34:30,345:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:34:30,347:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:34:30,359:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:34:30,400:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:34:30,401:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:34:30,420:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:30,430:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:34:30,506:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:34:30,509:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:34:31,390:INFO:Calculating mean and std
2023-07-31 14:34:31,393:INFO:Creating metrics dataframe
2023-07-31 14:34:31,600:INFO:Uploading results into container
2023-07-31 14:34:31,601:INFO:Uploading model into container now
2023-07-31 14:34:31,601:INFO:_master_model_container: 6
2023-07-31 14:34:31,601:INFO:_display_container: 2
2023-07-31 14:34:31,602:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 14:34:31,602:INFO:create_model() successfully completed......................................
2023-07-31 14:34:31,718:INFO:SubProcess create_model() end ==================================
2023-07-31 14:34:31,718:INFO:Creating metrics dataframe
2023-07-31 14:34:31,731:INFO:Initializing Random Forest Classifier
2023-07-31 14:34:31,731:INFO:Total runtime is 0.6034764369328817 minutes
2023-07-31 14:34:31,735:INFO:SubProcess create_model() called ==================================
2023-07-31 14:34:31,735:INFO:Initializing create_model()
2023-07-31 14:34:31,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:34:31,736:INFO:Checking exceptions
2023-07-31 14:34:31,736:INFO:Importing libraries
2023-07-31 14:34:31,736:INFO:Copying training dataset
2023-07-31 14:34:31,808:INFO:Defining folds
2023-07-31 14:34:31,809:INFO:Declaring metric variables
2023-07-31 14:34:31,813:INFO:Importing untrained model
2023-07-31 14:34:31,818:INFO:Random Forest Classifier Imported successfully
2023-07-31 14:34:31,825:INFO:Starting cross validation
2023-07-31 14:34:31,872:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:34:35,448:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:35,471:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:35,487:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:35,572:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:35,592:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:35,607:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:35,611:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:35,775:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:37,190:INFO:Calculating mean and std
2023-07-31 14:34:37,193:INFO:Creating metrics dataframe
2023-07-31 14:34:37,380:INFO:Uploading results into container
2023-07-31 14:34:37,381:INFO:Uploading model into container now
2023-07-31 14:34:37,381:INFO:_master_model_container: 7
2023-07-31 14:34:37,382:INFO:_display_container: 2
2023-07-31 14:34:37,382:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 14:34:37,382:INFO:create_model() successfully completed......................................
2023-07-31 14:34:37,505:INFO:SubProcess create_model() end ==================================
2023-07-31 14:34:37,505:INFO:Creating metrics dataframe
2023-07-31 14:34:37,518:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 14:34:37,518:INFO:Total runtime is 0.6999214649200439 minutes
2023-07-31 14:34:37,521:INFO:SubProcess create_model() called ==================================
2023-07-31 14:34:37,522:INFO:Initializing create_model()
2023-07-31 14:34:37,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:34:37,522:INFO:Checking exceptions
2023-07-31 14:34:37,522:INFO:Importing libraries
2023-07-31 14:34:37,522:INFO:Copying training dataset
2023-07-31 14:34:37,588:INFO:Defining folds
2023-07-31 14:34:37,588:INFO:Declaring metric variables
2023-07-31 14:34:37,592:INFO:Importing untrained model
2023-07-31 14:34:37,596:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 14:34:37,603:INFO:Starting cross validation
2023-07-31 14:34:37,645:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:34:38,402:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:34:38,404:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:34:38,424:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:34:38,427:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:34:38,455:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:34:38,470:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:34:38,470:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:34:38,520:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:34:40,691:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:34:42,346:INFO:Calculating mean and std
2023-07-31 14:34:42,350:INFO:Creating metrics dataframe
2023-07-31 14:34:42,796:INFO:Uploading results into container
2023-07-31 14:34:42,798:INFO:Uploading model into container now
2023-07-31 14:34:42,798:INFO:_master_model_container: 8
2023-07-31 14:34:42,798:INFO:_display_container: 2
2023-07-31 14:34:42,799:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 14:34:42,799:INFO:create_model() successfully completed......................................
2023-07-31 14:34:42,981:INFO:SubProcess create_model() end ==================================
2023-07-31 14:34:42,981:INFO:Creating metrics dataframe
2023-07-31 14:34:42,996:INFO:Initializing Ada Boost Classifier
2023-07-31 14:34:42,996:INFO:Total runtime is 0.7912296772003173 minutes
2023-07-31 14:34:43,001:INFO:SubProcess create_model() called ==================================
2023-07-31 14:34:43,001:INFO:Initializing create_model()
2023-07-31 14:34:43,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:34:43,001:INFO:Checking exceptions
2023-07-31 14:34:43,001:INFO:Importing libraries
2023-07-31 14:34:43,001:INFO:Copying training dataset
2023-07-31 14:34:43,077:INFO:Defining folds
2023-07-31 14:34:43,077:INFO:Declaring metric variables
2023-07-31 14:34:43,082:INFO:Importing untrained model
2023-07-31 14:34:43,087:INFO:Ada Boost Classifier Imported successfully
2023-07-31 14:34:43,095:INFO:Starting cross validation
2023-07-31 14:34:43,139:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:35:04,173:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:35:04,219:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:35:04,692:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:35:05,574:INFO:Calculating mean and std
2023-07-31 14:35:05,578:INFO:Creating metrics dataframe
2023-07-31 14:35:05,756:INFO:Uploading results into container
2023-07-31 14:35:05,759:INFO:Uploading model into container now
2023-07-31 14:35:05,760:INFO:_master_model_container: 9
2023-07-31 14:35:05,760:INFO:_display_container: 2
2023-07-31 14:35:05,760:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 14:35:05,760:INFO:create_model() successfully completed......................................
2023-07-31 14:35:05,936:INFO:SubProcess create_model() end ==================================
2023-07-31 14:35:05,936:INFO:Creating metrics dataframe
2023-07-31 14:35:05,950:INFO:Initializing Gradient Boosting Classifier
2023-07-31 14:35:05,950:INFO:Total runtime is 1.1737926363945008 minutes
2023-07-31 14:35:05,954:INFO:SubProcess create_model() called ==================================
2023-07-31 14:35:05,954:INFO:Initializing create_model()
2023-07-31 14:35:05,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:35:05,954:INFO:Checking exceptions
2023-07-31 14:35:05,954:INFO:Importing libraries
2023-07-31 14:35:05,954:INFO:Copying training dataset
2023-07-31 14:35:06,022:INFO:Defining folds
2023-07-31 14:35:06,022:INFO:Declaring metric variables
2023-07-31 14:35:06,026:INFO:Importing untrained model
2023-07-31 14:35:06,030:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 14:35:06,037:INFO:Starting cross validation
2023-07-31 14:35:06,079:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:35:45,140:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:35:48,705:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:11,596:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:12,072:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:12,144:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:12,394:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:13,184:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:14,560:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:15,049:INFO:Calculating mean and std
2023-07-31 14:36:15,054:INFO:Creating metrics dataframe
2023-07-31 14:36:15,510:INFO:Uploading results into container
2023-07-31 14:36:15,511:INFO:Uploading model into container now
2023-07-31 14:36:15,511:INFO:_master_model_container: 10
2023-07-31 14:36:15,512:INFO:_display_container: 2
2023-07-31 14:36:15,512:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 14:36:15,512:INFO:create_model() successfully completed......................................
2023-07-31 14:36:15,680:INFO:SubProcess create_model() end ==================================
2023-07-31 14:36:15,680:INFO:Creating metrics dataframe
2023-07-31 14:36:15,694:INFO:Initializing Linear Discriminant Analysis
2023-07-31 14:36:15,694:INFO:Total runtime is 2.3361899614334107 minutes
2023-07-31 14:36:15,697:INFO:SubProcess create_model() called ==================================
2023-07-31 14:36:15,698:INFO:Initializing create_model()
2023-07-31 14:36:15,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:36:15,698:INFO:Checking exceptions
2023-07-31 14:36:15,698:INFO:Importing libraries
2023-07-31 14:36:15,698:INFO:Copying training dataset
2023-07-31 14:36:15,764:INFO:Defining folds
2023-07-31 14:36:15,765:INFO:Declaring metric variables
2023-07-31 14:36:15,769:INFO:Importing untrained model
2023-07-31 14:36:15,772:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 14:36:15,779:INFO:Starting cross validation
2023-07-31 14:36:15,821:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:36:21,569:INFO:Calculating mean and std
2023-07-31 14:36:21,571:INFO:Creating metrics dataframe
2023-07-31 14:36:21,760:INFO:Uploading results into container
2023-07-31 14:36:21,761:INFO:Uploading model into container now
2023-07-31 14:36:21,761:INFO:_master_model_container: 11
2023-07-31 14:36:21,761:INFO:_display_container: 2
2023-07-31 14:36:21,762:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 14:36:21,762:INFO:create_model() successfully completed......................................
2023-07-31 14:36:21,880:INFO:SubProcess create_model() end ==================================
2023-07-31 14:36:21,880:INFO:Creating metrics dataframe
2023-07-31 14:36:21,894:INFO:Initializing Extra Trees Classifier
2023-07-31 14:36:21,894:INFO:Total runtime is 2.439520827929179 minutes
2023-07-31 14:36:21,897:INFO:SubProcess create_model() called ==================================
2023-07-31 14:36:21,898:INFO:Initializing create_model()
2023-07-31 14:36:21,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:36:21,898:INFO:Checking exceptions
2023-07-31 14:36:21,898:INFO:Importing libraries
2023-07-31 14:36:21,898:INFO:Copying training dataset
2023-07-31 14:36:21,965:INFO:Defining folds
2023-07-31 14:36:21,965:INFO:Declaring metric variables
2023-07-31 14:36:21,969:INFO:Importing untrained model
2023-07-31 14:36:21,973:INFO:Extra Trees Classifier Imported successfully
2023-07-31 14:36:21,979:INFO:Starting cross validation
2023-07-31 14:36:22,021:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:36:24,379:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:24,519:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:24,551:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:24,558:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:24,570:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:24,634:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:24,670:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:25,470:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:36:26,135:INFO:Calculating mean and std
2023-07-31 14:36:26,137:INFO:Creating metrics dataframe
2023-07-31 14:36:26,580:INFO:Uploading results into container
2023-07-31 14:36:26,581:INFO:Uploading model into container now
2023-07-31 14:36:26,582:INFO:_master_model_container: 12
2023-07-31 14:36:26,582:INFO:_display_container: 2
2023-07-31 14:36:26,582:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 14:36:26,582:INFO:create_model() successfully completed......................................
2023-07-31 14:36:26,699:INFO:SubProcess create_model() end ==================================
2023-07-31 14:36:26,699:INFO:Creating metrics dataframe
2023-07-31 14:36:26,714:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 14:36:26,715:INFO:Total runtime is 2.5198708971341452 minutes
2023-07-31 14:36:26,719:INFO:SubProcess create_model() called ==================================
2023-07-31 14:36:26,719:INFO:Initializing create_model()
2023-07-31 14:36:26,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:36:26,719:INFO:Checking exceptions
2023-07-31 14:36:26,719:INFO:Importing libraries
2023-07-31 14:36:26,719:INFO:Copying training dataset
2023-07-31 14:36:26,785:INFO:Defining folds
2023-07-31 14:36:26,786:INFO:Declaring metric variables
2023-07-31 14:36:26,790:INFO:Importing untrained model
2023-07-31 14:36:26,794:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 14:36:26,802:INFO:Starting cross validation
2023-07-31 14:36:26,845:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:37:19,149:INFO:Calculating mean and std
2023-07-31 14:37:19,153:INFO:Creating metrics dataframe
2023-07-31 14:37:19,635:INFO:Uploading results into container
2023-07-31 14:37:19,637:INFO:Uploading model into container now
2023-07-31 14:37:19,638:INFO:_master_model_container: 13
2023-07-31 14:37:19,638:INFO:_display_container: 2
2023-07-31 14:37:19,639:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 14:37:19,639:INFO:create_model() successfully completed......................................
2023-07-31 14:37:19,938:INFO:SubProcess create_model() end ==================================
2023-07-31 14:37:19,939:INFO:Creating metrics dataframe
2023-07-31 14:37:19,957:INFO:Initializing Dummy Classifier
2023-07-31 14:37:19,957:INFO:Total runtime is 3.407249673207601 minutes
2023-07-31 14:37:19,963:INFO:SubProcess create_model() called ==================================
2023-07-31 14:37:19,963:INFO:Initializing create_model()
2023-07-31 14:37:19,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0fac73d30>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:37:19,963:INFO:Checking exceptions
2023-07-31 14:37:19,963:INFO:Importing libraries
2023-07-31 14:37:19,964:INFO:Copying training dataset
2023-07-31 14:37:20,083:INFO:Defining folds
2023-07-31 14:37:20,084:INFO:Declaring metric variables
2023-07-31 14:37:20,089:INFO:Importing untrained model
2023-07-31 14:37:20,093:INFO:Dummy Classifier Imported successfully
2023-07-31 14:37:20,102:INFO:Starting cross validation
2023-07-31 14:37:20,153:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:37:22,613:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:37:23,778:INFO:Calculating mean and std
2023-07-31 14:37:23,781:INFO:Creating metrics dataframe
2023-07-31 14:37:23,998:INFO:Uploading results into container
2023-07-31 14:37:23,999:INFO:Uploading model into container now
2023-07-31 14:37:23,999:INFO:_master_model_container: 14
2023-07-31 14:37:24,000:INFO:_display_container: 2
2023-07-31 14:37:24,000:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 14:37:24,000:INFO:create_model() successfully completed......................................
2023-07-31 14:37:24,162:INFO:SubProcess create_model() end ==================================
2023-07-31 14:37:24,162:INFO:Creating metrics dataframe
2023-07-31 14:37:24,190:INFO:Initializing create_model()
2023-07-31 14:37:24,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9fd1f3e310>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:37:24,190:INFO:Checking exceptions
2023-07-31 14:37:24,192:INFO:Importing libraries
2023-07-31 14:37:24,192:INFO:Copying training dataset
2023-07-31 14:37:24,284:INFO:Defining folds
2023-07-31 14:37:24,285:INFO:Declaring metric variables
2023-07-31 14:37:24,285:INFO:Importing untrained model
2023-07-31 14:37:24,285:INFO:Declaring custom model
2023-07-31 14:37:24,286:INFO:Logistic Regression Imported successfully
2023-07-31 14:37:24,330:INFO:Cross validation set to False
2023-07-31 14:37:24,330:INFO:Fitting Model
2023-07-31 14:37:33,181:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:37:33,181:INFO:create_model() successfully completed......................................
2023-07-31 14:37:33,407:INFO:_master_model_container: 14
2023-07-31 14:37:33,407:INFO:_display_container: 2
2023-07-31 14:37:33,408:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:37:33,408:INFO:compare_models() successfully completed......................................
2023-07-31 14:37:36,622:INFO:Initializing set_config()
2023-07-31 14:37:36,622:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, variable=seed, value=42, kwargs={})
2023-07-31 14:37:36,622:INFO:Global variable: seed updated to 42
2023-07-31 14:37:36,623:INFO:set_config() successfully completed......................................
2023-07-31 14:37:36,764:INFO:PyCaret ClassificationExperiment
2023-07-31 14:37:36,764:INFO:Logging name: clf-default-name
2023-07-31 14:37:36,764:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 14:37:36,764:INFO:version 3.0.2
2023-07-31 14:37:36,764:INFO:Initializing setup()
2023-07-31 14:37:36,764:INFO:self.USI: ee46
2023-07-31 14:37:36,764:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 14:37:36,764:INFO:Checking environment
2023-07-31 14:37:36,764:INFO:python_version: 3.9.16
2023-07-31 14:37:36,764:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 14:37:36,764:INFO:machine: x86_64
2023-07-31 14:37:36,764:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:37:36,765:INFO:Memory: svmem(total=67419119616, available=8647024640, percent=87.2, used=57856917504, free=1912279040, active=58138603520, inactive=4879974400, buffers=114040832, cached=7535882240, shared=223551488, slab=1471959040)
2023-07-31 14:37:36,767:INFO:Physical Core: 28
2023-07-31 14:37:36,767:INFO:Logical Core: 56
2023-07-31 14:37:36,767:INFO:Checking libraries
2023-07-31 14:37:36,767:INFO:System:
2023-07-31 14:37:36,767:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 14:37:36,767:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 14:37:36,767:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:37:36,767:INFO:PyCaret required dependencies:
2023-07-31 14:37:36,767:INFO:                 pip: 23.0.1
2023-07-31 14:37:36,767:INFO:          setuptools: 66.0.0
2023-07-31 14:37:36,767:INFO:             pycaret: 3.0.2
2023-07-31 14:37:36,767:INFO:             IPython: 8.13.2
2023-07-31 14:37:36,767:INFO:          ipywidgets: 8.0.6
2023-07-31 14:37:36,767:INFO:                tqdm: 4.65.0
2023-07-31 14:37:36,767:INFO:               numpy: 1.23.5
2023-07-31 14:37:36,767:INFO:              pandas: 1.5.3
2023-07-31 14:37:36,767:INFO:              jinja2: 3.1.2
2023-07-31 14:37:36,767:INFO:               scipy: 1.10.1
2023-07-31 14:37:36,768:INFO:              joblib: 1.2.0
2023-07-31 14:37:36,768:INFO:             sklearn: 1.2.2
2023-07-31 14:37:36,768:INFO:                pyod: 1.0.9
2023-07-31 14:37:36,768:INFO:            imblearn: 0.10.1
2023-07-31 14:37:36,768:INFO:   category_encoders: 2.6.1
2023-07-31 14:37:36,768:INFO:            lightgbm: 3.3.5
2023-07-31 14:37:36,768:INFO:               numba: 0.57.0
2023-07-31 14:37:36,768:INFO:            requests: 2.28.1
2023-07-31 14:37:36,768:INFO:          matplotlib: 3.7.1
2023-07-31 14:37:36,768:INFO:          scikitplot: 0.3.7
2023-07-31 14:37:36,768:INFO:         yellowbrick: 1.5
2023-07-31 14:37:36,768:INFO:              plotly: 5.14.1
2023-07-31 14:37:36,768:INFO:             kaleido: 0.2.1
2023-07-31 14:37:36,768:INFO:         statsmodels: 0.14.0
2023-07-31 14:37:36,768:INFO:              sktime: 0.17.0
2023-07-31 14:37:36,768:INFO:               tbats: 1.1.3
2023-07-31 14:37:36,768:INFO:            pmdarima: 2.0.3
2023-07-31 14:37:36,768:INFO:              psutil: 5.9.5
2023-07-31 14:37:36,768:INFO:PyCaret optional dependencies:
2023-07-31 14:37:36,768:INFO:                shap: Not installed
2023-07-31 14:37:36,768:INFO:           interpret: Not installed
2023-07-31 14:37:36,768:INFO:                umap: Not installed
2023-07-31 14:37:36,768:INFO:    pandas_profiling: Not installed
2023-07-31 14:37:36,768:INFO:  explainerdashboard: Not installed
2023-07-31 14:37:36,768:INFO:             autoviz: Not installed
2023-07-31 14:37:36,768:INFO:           fairlearn: Not installed
2023-07-31 14:37:36,768:INFO:             xgboost: Not installed
2023-07-31 14:37:36,768:INFO:            catboost: Not installed
2023-07-31 14:37:36,768:INFO:              kmodes: Not installed
2023-07-31 14:37:36,768:INFO:             mlxtend: Not installed
2023-07-31 14:37:36,768:INFO:       statsforecast: Not installed
2023-07-31 14:37:36,768:INFO:        tune_sklearn: Not installed
2023-07-31 14:37:36,768:INFO:                 ray: Not installed
2023-07-31 14:37:36,769:INFO:            hyperopt: Not installed
2023-07-31 14:37:36,769:INFO:              optuna: Not installed
2023-07-31 14:37:36,769:INFO:               skopt: Not installed
2023-07-31 14:37:36,769:INFO:              mlflow: Not installed
2023-07-31 14:37:36,769:INFO:              gradio: Not installed
2023-07-31 14:37:36,769:INFO:             fastapi: Not installed
2023-07-31 14:37:36,769:INFO:             uvicorn: Not installed
2023-07-31 14:37:36,769:INFO:              m2cgen: Not installed
2023-07-31 14:37:36,769:INFO:           evidently: Not installed
2023-07-31 14:37:36,769:INFO:               fugue: Not installed
2023-07-31 14:37:36,769:INFO:           streamlit: Not installed
2023-07-31 14:37:36,769:INFO:             prophet: Not installed
2023-07-31 14:37:36,769:INFO:None
2023-07-31 14:37:36,769:INFO:Set up data.
2023-07-31 14:37:41,131:INFO:Set up train/test split.
2023-07-31 14:37:41,383:INFO:Set up index.
2023-07-31 14:37:41,383:INFO:Set up folding strategy.
2023-07-31 14:37:41,383:INFO:Assigning column types.
2023-07-31 14:37:41,538:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 14:37:41,583:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:37:41,584:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:37:41,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,656:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:37:41,657:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:37:41,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,694:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 14:37:41,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:37:41,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,815:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:37:41,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,845:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 14:37:41,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:41,993:INFO:Preparing preprocessing pipeline...
2023-07-31 14:37:42,021:INFO:Set up simple imputation.
2023-07-31 14:37:42,046:INFO:Set up column name cleaning.
2023-07-31 14:37:43,340:INFO:Finished creating preprocessing pipeline.
2023-07-31 14:37:43,419:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 14:37:43,419:INFO:Creating final display dataframe.
2023-07-31 14:37:47,133:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (742, 11886)
4        Transformed data shape      (742, 11886)
5   Transformed train set shape      (630, 11886)
6    Transformed test set shape      (112, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              ee46
2023-07-31 14:37:47,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:47,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:47,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:47,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:37:47,309:INFO:setup() successfully completed in 10.69s...............
2023-07-31 14:37:47,318:INFO:Initializing compare_models()
2023-07-31 14:37:47,319:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 14:37:47,319:INFO:Checking exceptions
2023-07-31 14:37:47,695:INFO:Preparing display monitor
2023-07-31 14:37:47,727:INFO:Initializing Logistic Regression
2023-07-31 14:37:47,728:INFO:Total runtime is 4.132588704427083e-06 minutes
2023-07-31 14:37:47,734:INFO:SubProcess create_model() called ==================================
2023-07-31 14:37:47,734:INFO:Initializing create_model()
2023-07-31 14:37:47,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:37:47,735:INFO:Checking exceptions
2023-07-31 14:37:47,735:INFO:Importing libraries
2023-07-31 14:37:47,735:INFO:Copying training dataset
2023-07-31 14:37:48,116:INFO:Defining folds
2023-07-31 14:37:48,116:INFO:Declaring metric variables
2023-07-31 14:37:48,121:INFO:Importing untrained model
2023-07-31 14:37:48,127:INFO:Logistic Regression Imported successfully
2023-07-31 14:37:48,136:INFO:Starting cross validation
2023-07-31 14:37:48,186:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:38:03,241:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:04,807:INFO:Calculating mean and std
2023-07-31 14:38:04,810:INFO:Creating metrics dataframe
2023-07-31 14:38:05,077:INFO:Uploading results into container
2023-07-31 14:38:05,078:INFO:Uploading model into container now
2023-07-31 14:38:05,079:INFO:_master_model_container: 1
2023-07-31 14:38:05,079:INFO:_display_container: 2
2023-07-31 14:38:05,080:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:38:05,080:INFO:create_model() successfully completed......................................
2023-07-31 14:38:05,419:INFO:SubProcess create_model() end ==================================
2023-07-31 14:38:05,420:INFO:Creating metrics dataframe
2023-07-31 14:38:05,433:INFO:Initializing K Neighbors Classifier
2023-07-31 14:38:05,433:INFO:Total runtime is 0.29509704907735185 minutes
2023-07-31 14:38:05,438:INFO:SubProcess create_model() called ==================================
2023-07-31 14:38:05,439:INFO:Initializing create_model()
2023-07-31 14:38:05,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:38:05,439:INFO:Checking exceptions
2023-07-31 14:38:05,439:INFO:Importing libraries
2023-07-31 14:38:05,439:INFO:Copying training dataset
2023-07-31 14:38:05,625:INFO:Defining folds
2023-07-31 14:38:05,625:INFO:Declaring metric variables
2023-07-31 14:38:05,630:INFO:Importing untrained model
2023-07-31 14:38:05,635:INFO:K Neighbors Classifier Imported successfully
2023-07-31 14:38:05,644:INFO:Starting cross validation
2023-07-31 14:38:05,695:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:38:08,422:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:09,900:INFO:Calculating mean and std
2023-07-31 14:38:09,904:INFO:Creating metrics dataframe
2023-07-31 14:38:10,131:INFO:Uploading results into container
2023-07-31 14:38:10,133:INFO:Uploading model into container now
2023-07-31 14:38:10,134:INFO:_master_model_container: 2
2023-07-31 14:38:10,134:INFO:_display_container: 2
2023-07-31 14:38:10,134:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 14:38:10,134:INFO:create_model() successfully completed......................................
2023-07-31 14:38:10,413:INFO:SubProcess create_model() end ==================================
2023-07-31 14:38:10,414:INFO:Creating metrics dataframe
2023-07-31 14:38:10,429:INFO:Initializing Naive Bayes
2023-07-31 14:38:10,429:INFO:Total runtime is 0.37835592826207476 minutes
2023-07-31 14:38:10,434:INFO:SubProcess create_model() called ==================================
2023-07-31 14:38:10,435:INFO:Initializing create_model()
2023-07-31 14:38:10,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:38:10,435:INFO:Checking exceptions
2023-07-31 14:38:10,435:INFO:Importing libraries
2023-07-31 14:38:10,435:INFO:Copying training dataset
2023-07-31 14:38:10,620:INFO:Defining folds
2023-07-31 14:38:10,620:INFO:Declaring metric variables
2023-07-31 14:38:10,625:INFO:Importing untrained model
2023-07-31 14:38:10,630:INFO:Naive Bayes Imported successfully
2023-07-31 14:38:10,639:INFO:Starting cross validation
2023-07-31 14:38:10,691:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:38:14,615:INFO:Calculating mean and std
2023-07-31 14:38:14,618:INFO:Creating metrics dataframe
2023-07-31 14:38:14,827:INFO:Uploading results into container
2023-07-31 14:38:14,828:INFO:Uploading model into container now
2023-07-31 14:38:14,829:INFO:_master_model_container: 3
2023-07-31 14:38:14,829:INFO:_display_container: 2
2023-07-31 14:38:14,829:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 14:38:14,829:INFO:create_model() successfully completed......................................
2023-07-31 14:38:15,065:INFO:SubProcess create_model() end ==================================
2023-07-31 14:38:15,065:INFO:Creating metrics dataframe
2023-07-31 14:38:15,079:INFO:Initializing Decision Tree Classifier
2023-07-31 14:38:15,079:INFO:Total runtime is 0.4558639287948608 minutes
2023-07-31 14:38:15,084:INFO:SubProcess create_model() called ==================================
2023-07-31 14:38:15,084:INFO:Initializing create_model()
2023-07-31 14:38:15,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:38:15,084:INFO:Checking exceptions
2023-07-31 14:38:15,085:INFO:Importing libraries
2023-07-31 14:38:15,085:INFO:Copying training dataset
2023-07-31 14:38:15,244:INFO:Defining folds
2023-07-31 14:38:15,244:INFO:Declaring metric variables
2023-07-31 14:38:15,249:INFO:Importing untrained model
2023-07-31 14:38:15,254:INFO:Decision Tree Classifier Imported successfully
2023-07-31 14:38:15,263:INFO:Starting cross validation
2023-07-31 14:38:15,310:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:38:20,188:INFO:Calculating mean and std
2023-07-31 14:38:20,190:INFO:Creating metrics dataframe
2023-07-31 14:38:20,408:INFO:Uploading results into container
2023-07-31 14:38:20,410:INFO:Uploading model into container now
2023-07-31 14:38:20,410:INFO:_master_model_container: 4
2023-07-31 14:38:20,410:INFO:_display_container: 2
2023-07-31 14:38:20,411:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 14:38:20,411:INFO:create_model() successfully completed......................................
2023-07-31 14:38:20,641:INFO:SubProcess create_model() end ==================================
2023-07-31 14:38:20,641:INFO:Creating metrics dataframe
2023-07-31 14:38:20,655:INFO:Initializing SVM - Linear Kernel
2023-07-31 14:38:20,655:INFO:Total runtime is 0.5487885951995849 minutes
2023-07-31 14:38:20,659:INFO:SubProcess create_model() called ==================================
2023-07-31 14:38:20,660:INFO:Initializing create_model()
2023-07-31 14:38:20,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:38:20,660:INFO:Checking exceptions
2023-07-31 14:38:20,660:INFO:Importing libraries
2023-07-31 14:38:20,660:INFO:Copying training dataset
2023-07-31 14:38:20,807:INFO:Defining folds
2023-07-31 14:38:20,807:INFO:Declaring metric variables
2023-07-31 14:38:20,811:INFO:Importing untrained model
2023-07-31 14:38:20,816:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 14:38:20,824:INFO:Starting cross validation
2023-07-31 14:38:20,870:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:38:23,377:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:38:23,390:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:38:23,394:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:38:23,402:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:38:23,419:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:38:23,425:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:38:23,436:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:38:23,543:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:38:24,407:INFO:Calculating mean and std
2023-07-31 14:38:24,410:INFO:Creating metrics dataframe
2023-07-31 14:38:24,612:INFO:Uploading results into container
2023-07-31 14:38:24,613:INFO:Uploading model into container now
2023-07-31 14:38:24,614:INFO:_master_model_container: 5
2023-07-31 14:38:24,614:INFO:_display_container: 2
2023-07-31 14:38:24,615:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 14:38:24,615:INFO:create_model() successfully completed......................................
2023-07-31 14:38:24,786:INFO:SubProcess create_model() end ==================================
2023-07-31 14:38:24,786:INFO:Creating metrics dataframe
2023-07-31 14:38:24,799:INFO:Initializing Ridge Classifier
2023-07-31 14:38:24,799:INFO:Total runtime is 0.6178619305292765 minutes
2023-07-31 14:38:24,803:INFO:SubProcess create_model() called ==================================
2023-07-31 14:38:24,803:INFO:Initializing create_model()
2023-07-31 14:38:24,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:38:24,803:INFO:Checking exceptions
2023-07-31 14:38:24,803:INFO:Importing libraries
2023-07-31 14:38:24,803:INFO:Copying training dataset
2023-07-31 14:38:24,925:INFO:Defining folds
2023-07-31 14:38:24,925:INFO:Declaring metric variables
2023-07-31 14:38:24,929:INFO:Importing untrained model
2023-07-31 14:38:24,933:INFO:Ridge Classifier Imported successfully
2023-07-31 14:38:24,940:INFO:Starting cross validation
2023-07-31 14:38:24,983:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:38:27,086:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:38:27,088:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:38:27,094:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:38:27,160:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:38:27,163:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:38:27,169:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:38:27,210:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:38:27,282:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:38:28,108:INFO:Calculating mean and std
2023-07-31 14:38:28,110:INFO:Creating metrics dataframe
2023-07-31 14:38:28,300:INFO:Uploading results into container
2023-07-31 14:38:28,301:INFO:Uploading model into container now
2023-07-31 14:38:28,301:INFO:_master_model_container: 6
2023-07-31 14:38:28,301:INFO:_display_container: 2
2023-07-31 14:38:28,302:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 14:38:28,302:INFO:create_model() successfully completed......................................
2023-07-31 14:38:28,447:INFO:SubProcess create_model() end ==================================
2023-07-31 14:38:28,447:INFO:Creating metrics dataframe
2023-07-31 14:38:28,460:INFO:Initializing Random Forest Classifier
2023-07-31 14:38:28,460:INFO:Total runtime is 0.6788807551066081 minutes
2023-07-31 14:38:28,464:INFO:SubProcess create_model() called ==================================
2023-07-31 14:38:28,464:INFO:Initializing create_model()
2023-07-31 14:38:28,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:38:28,464:INFO:Checking exceptions
2023-07-31 14:38:28,464:INFO:Importing libraries
2023-07-31 14:38:28,464:INFO:Copying training dataset
2023-07-31 14:38:28,603:INFO:Defining folds
2023-07-31 14:38:28,603:INFO:Declaring metric variables
2023-07-31 14:38:28,608:INFO:Importing untrained model
2023-07-31 14:38:28,613:INFO:Random Forest Classifier Imported successfully
2023-07-31 14:38:28,621:INFO:Starting cross validation
2023-07-31 14:38:28,668:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:38:31,225:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:31,283:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:31,305:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:31,317:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:31,363:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:31,462:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:31,485:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:38:33,543:INFO:Calculating mean and std
2023-07-31 14:38:33,546:INFO:Creating metrics dataframe
2023-07-31 14:38:34,055:INFO:Uploading results into container
2023-07-31 14:38:34,057:INFO:Uploading model into container now
2023-07-31 14:38:34,059:INFO:_master_model_container: 7
2023-07-31 14:38:34,059:INFO:_display_container: 2
2023-07-31 14:38:34,060:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 14:38:34,060:INFO:create_model() successfully completed......................................
2023-07-31 14:38:34,431:INFO:SubProcess create_model() end ==================================
2023-07-31 14:38:34,432:INFO:Creating metrics dataframe
2023-07-31 14:38:34,445:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 14:38:34,446:INFO:Total runtime is 0.7786358078320821 minutes
2023-07-31 14:38:34,449:INFO:SubProcess create_model() called ==================================
2023-07-31 14:38:34,449:INFO:Initializing create_model()
2023-07-31 14:38:34,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:38:34,449:INFO:Checking exceptions
2023-07-31 14:38:34,449:INFO:Importing libraries
2023-07-31 14:38:34,450:INFO:Copying training dataset
2023-07-31 14:38:34,564:INFO:Defining folds
2023-07-31 14:38:34,565:INFO:Declaring metric variables
2023-07-31 14:38:34,569:INFO:Importing untrained model
2023-07-31 14:38:34,572:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 14:38:34,579:INFO:Starting cross validation
2023-07-31 14:38:34,617:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:38:36,259:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:38:36,344:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:38:36,408:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:38:36,412:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:38:36,451:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:38:36,459:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:38:36,491:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:38:36,525:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:38:40,098:INFO:Calculating mean and std
2023-07-31 14:38:40,100:INFO:Creating metrics dataframe
2023-07-31 14:38:40,260:INFO:Uploading results into container
2023-07-31 14:38:40,261:INFO:Uploading model into container now
2023-07-31 14:38:40,261:INFO:_master_model_container: 8
2023-07-31 14:38:40,261:INFO:_display_container: 2
2023-07-31 14:38:40,261:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 14:38:40,261:INFO:create_model() successfully completed......................................
2023-07-31 14:38:40,392:INFO:SubProcess create_model() end ==================================
2023-07-31 14:38:40,393:INFO:Creating metrics dataframe
2023-07-31 14:38:40,405:INFO:Initializing Ada Boost Classifier
2023-07-31 14:38:40,405:INFO:Total runtime is 0.8779636065165202 minutes
2023-07-31 14:38:40,409:INFO:SubProcess create_model() called ==================================
2023-07-31 14:38:40,409:INFO:Initializing create_model()
2023-07-31 14:38:40,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:38:40,409:INFO:Checking exceptions
2023-07-31 14:38:40,409:INFO:Importing libraries
2023-07-31 14:38:40,409:INFO:Copying training dataset
2023-07-31 14:38:40,521:INFO:Defining folds
2023-07-31 14:38:40,521:INFO:Declaring metric variables
2023-07-31 14:38:40,525:INFO:Importing untrained model
2023-07-31 14:38:40,529:INFO:Ada Boost Classifier Imported successfully
2023-07-31 14:38:40,536:INFO:Starting cross validation
2023-07-31 14:38:40,602:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:39:17,790:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:39:18,008:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:39:18,833:INFO:Calculating mean and std
2023-07-31 14:39:18,835:INFO:Creating metrics dataframe
2023-07-31 14:39:19,024:INFO:Uploading results into container
2023-07-31 14:39:19,025:INFO:Uploading model into container now
2023-07-31 14:39:19,025:INFO:_master_model_container: 9
2023-07-31 14:39:19,025:INFO:_display_container: 2
2023-07-31 14:39:19,026:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 14:39:19,026:INFO:create_model() successfully completed......................................
2023-07-31 14:39:19,206:INFO:SubProcess create_model() end ==================================
2023-07-31 14:39:19,206:INFO:Creating metrics dataframe
2023-07-31 14:39:19,219:INFO:Initializing Gradient Boosting Classifier
2023-07-31 14:39:19,220:INFO:Total runtime is 1.5248709758122763 minutes
2023-07-31 14:39:19,223:INFO:SubProcess create_model() called ==================================
2023-07-31 14:39:19,224:INFO:Initializing create_model()
2023-07-31 14:39:19,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:39:19,224:INFO:Checking exceptions
2023-07-31 14:39:19,224:INFO:Importing libraries
2023-07-31 14:39:19,224:INFO:Copying training dataset
2023-07-31 14:39:19,345:INFO:Defining folds
2023-07-31 14:39:19,345:INFO:Declaring metric variables
2023-07-31 14:39:19,349:INFO:Importing untrained model
2023-07-31 14:39:19,353:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 14:39:19,359:INFO:Starting cross validation
2023-07-31 14:39:19,405:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:41:49,287:INFO:Calculating mean and std
2023-07-31 14:41:49,290:INFO:Creating metrics dataframe
2023-07-31 14:41:49,479:INFO:Uploading results into container
2023-07-31 14:41:49,480:INFO:Uploading model into container now
2023-07-31 14:41:49,481:INFO:_master_model_container: 10
2023-07-31 14:41:49,481:INFO:_display_container: 2
2023-07-31 14:41:49,481:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 14:41:49,482:INFO:create_model() successfully completed......................................
2023-07-31 14:41:49,652:INFO:SubProcess create_model() end ==================================
2023-07-31 14:41:49,652:INFO:Creating metrics dataframe
2023-07-31 14:41:49,665:INFO:Initializing Linear Discriminant Analysis
2023-07-31 14:41:49,665:INFO:Total runtime is 4.032290244102478 minutes
2023-07-31 14:41:49,668:INFO:SubProcess create_model() called ==================================
2023-07-31 14:41:49,669:INFO:Initializing create_model()
2023-07-31 14:41:49,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:41:49,669:INFO:Checking exceptions
2023-07-31 14:41:49,669:INFO:Importing libraries
2023-07-31 14:41:49,669:INFO:Copying training dataset
2023-07-31 14:41:49,785:INFO:Defining folds
2023-07-31 14:41:49,785:INFO:Declaring metric variables
2023-07-31 14:41:49,789:INFO:Importing untrained model
2023-07-31 14:41:49,793:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 14:41:49,799:INFO:Starting cross validation
2023-07-31 14:41:49,840:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:41:56,218:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:41:56,297:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:41:56,872:INFO:Calculating mean and std
2023-07-31 14:41:56,875:INFO:Creating metrics dataframe
2023-07-31 14:41:57,002:INFO:Uploading results into container
2023-07-31 14:41:57,003:INFO:Uploading model into container now
2023-07-31 14:41:57,003:INFO:_master_model_container: 11
2023-07-31 14:41:57,003:INFO:_display_container: 2
2023-07-31 14:41:57,004:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 14:41:57,004:INFO:create_model() successfully completed......................................
2023-07-31 14:41:57,127:INFO:SubProcess create_model() end ==================================
2023-07-31 14:41:57,127:INFO:Creating metrics dataframe
2023-07-31 14:41:57,140:INFO:Initializing Extra Trees Classifier
2023-07-31 14:41:57,141:INFO:Total runtime is 4.156887237230937 minutes
2023-07-31 14:41:57,144:INFO:SubProcess create_model() called ==================================
2023-07-31 14:41:57,144:INFO:Initializing create_model()
2023-07-31 14:41:57,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:41:57,145:INFO:Checking exceptions
2023-07-31 14:41:57,145:INFO:Importing libraries
2023-07-31 14:41:57,145:INFO:Copying training dataset
2023-07-31 14:41:57,261:INFO:Defining folds
2023-07-31 14:41:57,261:INFO:Declaring metric variables
2023-07-31 14:41:57,265:INFO:Importing untrained model
2023-07-31 14:41:57,268:INFO:Extra Trees Classifier Imported successfully
2023-07-31 14:41:57,275:INFO:Starting cross validation
2023-07-31 14:41:57,316:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:41:59,738:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:41:59,824:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:41:59,824:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:41:59,853:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:41:59,860:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:41:59,880:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:41:59,989:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:42:00,150:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:42:01,174:INFO:Calculating mean and std
2023-07-31 14:42:01,178:INFO:Creating metrics dataframe
2023-07-31 14:42:01,583:INFO:Uploading results into container
2023-07-31 14:42:01,584:INFO:Uploading model into container now
2023-07-31 14:42:01,585:INFO:_master_model_container: 12
2023-07-31 14:42:01,585:INFO:_display_container: 2
2023-07-31 14:42:01,585:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 14:42:01,585:INFO:create_model() successfully completed......................................
2023-07-31 14:42:01,713:INFO:SubProcess create_model() end ==================================
2023-07-31 14:42:01,713:INFO:Creating metrics dataframe
2023-07-31 14:42:01,727:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 14:42:01,727:INFO:Total runtime is 4.233333377043407 minutes
2023-07-31 14:42:01,731:INFO:SubProcess create_model() called ==================================
2023-07-31 14:42:01,731:INFO:Initializing create_model()
2023-07-31 14:42:01,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:42:01,731:INFO:Checking exceptions
2023-07-31 14:42:01,732:INFO:Importing libraries
2023-07-31 14:42:01,732:INFO:Copying training dataset
2023-07-31 14:42:01,847:INFO:Defining folds
2023-07-31 14:42:01,848:INFO:Declaring metric variables
2023-07-31 14:42:01,852:INFO:Importing untrained model
2023-07-31 14:42:01,855:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 14:42:01,862:INFO:Starting cross validation
2023-07-31 14:42:01,904:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:43:54,423:INFO:Calculating mean and std
2023-07-31 14:43:54,452:INFO:Creating metrics dataframe
2023-07-31 14:43:54,885:INFO:Uploading results into container
2023-07-31 14:43:54,886:INFO:Uploading model into container now
2023-07-31 14:43:54,887:INFO:_master_model_container: 13
2023-07-31 14:43:54,887:INFO:_display_container: 2
2023-07-31 14:43:54,888:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 14:43:54,888:INFO:create_model() successfully completed......................................
2023-07-31 14:43:55,095:INFO:SubProcess create_model() end ==================================
2023-07-31 14:43:55,096:INFO:Creating metrics dataframe
2023-07-31 14:43:55,111:INFO:Initializing Dummy Classifier
2023-07-31 14:43:55,111:INFO:Total runtime is 6.123063858350119 minutes
2023-07-31 14:43:55,115:INFO:SubProcess create_model() called ==================================
2023-07-31 14:43:55,115:INFO:Initializing create_model()
2023-07-31 14:43:55,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9fd1f11220>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:43:55,115:INFO:Checking exceptions
2023-07-31 14:43:55,115:INFO:Importing libraries
2023-07-31 14:43:55,116:INFO:Copying training dataset
2023-07-31 14:43:55,235:INFO:Defining folds
2023-07-31 14:43:55,236:INFO:Declaring metric variables
2023-07-31 14:43:55,240:INFO:Importing untrained model
2023-07-31 14:43:55,243:INFO:Dummy Classifier Imported successfully
2023-07-31 14:43:55,250:INFO:Starting cross validation
2023-07-31 14:43:55,292:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:43:57,879:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 14:43:57,928:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 14:43:57,930:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 14:43:58,039:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 14:43:58,628:INFO:Calculating mean and std
2023-07-31 14:43:58,634:INFO:Creating metrics dataframe
2023-07-31 14:43:59,044:INFO:Uploading results into container
2023-07-31 14:43:59,045:INFO:Uploading model into container now
2023-07-31 14:43:59,046:INFO:_master_model_container: 14
2023-07-31 14:43:59,046:INFO:_display_container: 2
2023-07-31 14:43:59,046:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 14:43:59,047:INFO:create_model() successfully completed......................................
2023-07-31 14:43:59,225:INFO:SubProcess create_model() end ==================================
2023-07-31 14:43:59,225:INFO:Creating metrics dataframe
2023-07-31 14:43:59,251:INFO:Initializing create_model()
2023-07-31 14:43:59,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9f52190>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:43:59,252:INFO:Checking exceptions
2023-07-31 14:43:59,253:INFO:Importing libraries
2023-07-31 14:43:59,253:INFO:Copying training dataset
2023-07-31 14:43:59,376:INFO:Defining folds
2023-07-31 14:43:59,376:INFO:Declaring metric variables
2023-07-31 14:43:59,376:INFO:Importing untrained model
2023-07-31 14:43:59,376:INFO:Declaring custom model
2023-07-31 14:43:59,377:INFO:Ridge Classifier Imported successfully
2023-07-31 14:43:59,418:INFO:Cross validation set to False
2023-07-31 14:43:59,418:INFO:Fitting Model
2023-07-31 14:44:00,189:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=4.83152e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-07-31 14:44:00,614:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 14:44:00,614:INFO:create_model() successfully completed......................................
2023-07-31 14:44:00,825:INFO:_master_model_container: 14
2023-07-31 14:44:00,825:INFO:_display_container: 2
2023-07-31 14:44:00,826:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 14:44:00,826:INFO:compare_models() successfully completed......................................
2023-07-31 14:44:00,913:INFO:Initializing set_config()
2023-07-31 14:44:00,913:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, variable=seed, value=42, kwargs={})
2023-07-31 14:44:00,914:INFO:Global variable: seed updated to 42
2023-07-31 14:44:00,914:INFO:set_config() successfully completed......................................
2023-07-31 14:44:01,019:INFO:PyCaret ClassificationExperiment
2023-07-31 14:44:01,019:INFO:Logging name: clf-default-name
2023-07-31 14:44:01,019:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 14:44:01,019:INFO:version 3.0.2
2023-07-31 14:44:01,019:INFO:Initializing setup()
2023-07-31 14:44:01,019:INFO:self.USI: 3c81
2023-07-31 14:44:01,019:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 14:44:01,019:INFO:Checking environment
2023-07-31 14:44:01,019:INFO:python_version: 3.9.16
2023-07-31 14:44:01,019:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 14:44:01,019:INFO:machine: x86_64
2023-07-31 14:44:01,020:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:44:01,020:INFO:Memory: svmem(total=67419119616, available=11055775744, percent=83.6, used=55420252160, free=10365222912, active=49155756032, inactive=5629411328, buffers=43913216, cached=1589731328, shared=248897536, slab=1308676096)
2023-07-31 14:44:01,022:INFO:Physical Core: 28
2023-07-31 14:44:01,022:INFO:Logical Core: 56
2023-07-31 14:44:01,022:INFO:Checking libraries
2023-07-31 14:44:01,022:INFO:System:
2023-07-31 14:44:01,022:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 14:44:01,022:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 14:44:01,022:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:44:01,022:INFO:PyCaret required dependencies:
2023-07-31 14:44:01,022:INFO:                 pip: 23.0.1
2023-07-31 14:44:01,022:INFO:          setuptools: 66.0.0
2023-07-31 14:44:01,022:INFO:             pycaret: 3.0.2
2023-07-31 14:44:01,022:INFO:             IPython: 8.13.2
2023-07-31 14:44:01,022:INFO:          ipywidgets: 8.0.6
2023-07-31 14:44:01,022:INFO:                tqdm: 4.65.0
2023-07-31 14:44:01,022:INFO:               numpy: 1.23.5
2023-07-31 14:44:01,022:INFO:              pandas: 1.5.3
2023-07-31 14:44:01,022:INFO:              jinja2: 3.1.2
2023-07-31 14:44:01,022:INFO:               scipy: 1.10.1
2023-07-31 14:44:01,022:INFO:              joblib: 1.2.0
2023-07-31 14:44:01,022:INFO:             sklearn: 1.2.2
2023-07-31 14:44:01,022:INFO:                pyod: 1.0.9
2023-07-31 14:44:01,022:INFO:            imblearn: 0.10.1
2023-07-31 14:44:01,022:INFO:   category_encoders: 2.6.1
2023-07-31 14:44:01,022:INFO:            lightgbm: 3.3.5
2023-07-31 14:44:01,022:INFO:               numba: 0.57.0
2023-07-31 14:44:01,022:INFO:            requests: 2.28.1
2023-07-31 14:44:01,022:INFO:          matplotlib: 3.7.1
2023-07-31 14:44:01,022:INFO:          scikitplot: 0.3.7
2023-07-31 14:44:01,022:INFO:         yellowbrick: 1.5
2023-07-31 14:44:01,022:INFO:              plotly: 5.14.1
2023-07-31 14:44:01,023:INFO:             kaleido: 0.2.1
2023-07-31 14:44:01,023:INFO:         statsmodels: 0.14.0
2023-07-31 14:44:01,023:INFO:              sktime: 0.17.0
2023-07-31 14:44:01,023:INFO:               tbats: 1.1.3
2023-07-31 14:44:01,023:INFO:            pmdarima: 2.0.3
2023-07-31 14:44:01,023:INFO:              psutil: 5.9.5
2023-07-31 14:44:01,023:INFO:PyCaret optional dependencies:
2023-07-31 14:44:01,023:INFO:                shap: Not installed
2023-07-31 14:44:01,023:INFO:           interpret: Not installed
2023-07-31 14:44:01,023:INFO:                umap: Not installed
2023-07-31 14:44:01,023:INFO:    pandas_profiling: Not installed
2023-07-31 14:44:01,023:INFO:  explainerdashboard: Not installed
2023-07-31 14:44:01,023:INFO:             autoviz: Not installed
2023-07-31 14:44:01,023:INFO:           fairlearn: Not installed
2023-07-31 14:44:01,023:INFO:             xgboost: Not installed
2023-07-31 14:44:01,023:INFO:            catboost: Not installed
2023-07-31 14:44:01,023:INFO:              kmodes: Not installed
2023-07-31 14:44:01,023:INFO:             mlxtend: Not installed
2023-07-31 14:44:01,023:INFO:       statsforecast: Not installed
2023-07-31 14:44:01,023:INFO:        tune_sklearn: Not installed
2023-07-31 14:44:01,023:INFO:                 ray: Not installed
2023-07-31 14:44:01,023:INFO:            hyperopt: Not installed
2023-07-31 14:44:01,023:INFO:              optuna: Not installed
2023-07-31 14:44:01,023:INFO:               skopt: Not installed
2023-07-31 14:44:01,023:INFO:              mlflow: Not installed
2023-07-31 14:44:01,023:INFO:              gradio: Not installed
2023-07-31 14:44:01,023:INFO:             fastapi: Not installed
2023-07-31 14:44:01,023:INFO:             uvicorn: Not installed
2023-07-31 14:44:01,023:INFO:              m2cgen: Not installed
2023-07-31 14:44:01,023:INFO:           evidently: Not installed
2023-07-31 14:44:01,023:INFO:               fugue: Not installed
2023-07-31 14:44:01,023:INFO:           streamlit: Not installed
2023-07-31 14:44:01,023:INFO:             prophet: Not installed
2023-07-31 14:44:01,023:INFO:None
2023-07-31 14:44:01,024:INFO:Set up data.
2023-07-31 14:44:01,106:INFO:Set up train/test split.
2023-07-31 14:44:01,120:INFO:Set up index.
2023-07-31 14:44:01,120:INFO:Set up folding strategy.
2023-07-31 14:44:01,121:INFO:Assigning column types.
2023-07-31 14:44:01,125:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 14:44:01,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:44:01,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:44:01,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,238:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:44:01,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:44:01,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,266:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 14:44:01,309:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:44:01,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,378:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:44:01,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,404:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 14:44:01,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,537:INFO:Preparing preprocessing pipeline...
2023-07-31 14:44:01,540:INFO:Set up simple imputation.
2023-07-31 14:44:01,569:INFO:Finished creating preprocessing pipeline.
2023-07-31 14:44:01,574:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-07-31 14:44:01,574:INFO:Creating final display dataframe.
2023-07-31 14:44:01,688:INFO:Setup _display_container:                     Description             Value
0                    Session id                44
1                        Target             group
2                   Target type            Binary
3           Original data shape        (742, 294)
4        Transformed data shape        (742, 294)
5   Transformed train set shape        (630, 294)
6    Transformed test set shape        (112, 294)
7              Numeric features               293
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3c81
2023-07-31 14:44:01,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:44:01,833:INFO:setup() successfully completed in 0.92s...............
2023-07-31 14:44:01,839:INFO:Initializing compare_models()
2023-07-31 14:44:01,839:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, include=None, fold=None, round=4, cross_validation=False, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': False, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 14:44:01,840:INFO:Checking exceptions
2023-07-31 14:44:01,845:INFO:Preparing display monitor
2023-07-31 14:44:01,873:INFO:Initializing Logistic Regression
2023-07-31 14:44:01,874:INFO:Total runtime is 3.4133593241373697e-06 minutes
2023-07-31 14:44:01,877:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:01,878:INFO:Initializing create_model()
2023-07-31 14:44:01,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:01,878:INFO:Checking exceptions
2023-07-31 14:44:01,878:INFO:Importing libraries
2023-07-31 14:44:01,878:INFO:Copying training dataset
2023-07-31 14:44:01,883:INFO:Defining folds
2023-07-31 14:44:01,883:INFO:Declaring metric variables
2023-07-31 14:44:01,887:INFO:Importing untrained model
2023-07-31 14:44:01,890:INFO:Logistic Regression Imported successfully
2023-07-31 14:44:01,895:INFO:Cross validation set to False
2023-07-31 14:44:01,895:INFO:Fitting Model
2023-07-31 14:44:02,408:INFO:Initializing predict_model()
2023-07-31 14:44:02,408:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=44,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0afa08b80>)
2023-07-31 14:44:02,409:INFO:Checking exceptions
2023-07-31 14:44:02,409:INFO:Preloading libraries
2023-07-31 14:44:02,718:INFO:_display_container: 2
2023-07-31 14:44:02,830:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:44:02,830:INFO:create_model() successfully completed......................................
2023-07-31 14:44:03,006:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:03,007:INFO:Creating metrics dataframe
2023-07-31 14:44:03,017:INFO:Initializing K Neighbors Classifier
2023-07-31 14:44:03,017:INFO:Total runtime is 0.019066365559895833 minutes
2023-07-31 14:44:03,021:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:03,021:INFO:Initializing create_model()
2023-07-31 14:44:03,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:03,021:INFO:Checking exceptions
2023-07-31 14:44:03,022:INFO:Importing libraries
2023-07-31 14:44:03,022:INFO:Copying training dataset
2023-07-31 14:44:03,028:INFO:Defining folds
2023-07-31 14:44:03,028:INFO:Declaring metric variables
2023-07-31 14:44:03,032:INFO:Importing untrained model
2023-07-31 14:44:03,035:INFO:K Neighbors Classifier Imported successfully
2023-07-31 14:44:03,041:INFO:Cross validation set to False
2023-07-31 14:44:03,041:INFO:Fitting Model
2023-07-31 14:44:03,085:INFO:Initializing predict_model()
2023-07-31 14:44:03,085:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b1b55700>)
2023-07-31 14:44:03,085:INFO:Checking exceptions
2023-07-31 14:44:03,085:INFO:Preloading libraries
2023-07-31 14:44:03,525:INFO:_display_container: 2
2023-07-31 14:44:03,635:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 14:44:03,635:INFO:create_model() successfully completed......................................
2023-07-31 14:44:03,807:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:03,808:INFO:Creating metrics dataframe
2023-07-31 14:44:03,820:INFO:Initializing Naive Bayes
2023-07-31 14:44:03,820:INFO:Total runtime is 0.03244460423787435 minutes
2023-07-31 14:44:03,824:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:03,824:INFO:Initializing create_model()
2023-07-31 14:44:03,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:03,824:INFO:Checking exceptions
2023-07-31 14:44:03,824:INFO:Importing libraries
2023-07-31 14:44:03,825:INFO:Copying training dataset
2023-07-31 14:44:03,831:INFO:Defining folds
2023-07-31 14:44:03,831:INFO:Declaring metric variables
2023-07-31 14:44:03,835:INFO:Importing untrained model
2023-07-31 14:44:03,839:INFO:Naive Bayes Imported successfully
2023-07-31 14:44:03,847:INFO:Cross validation set to False
2023-07-31 14:44:03,847:INFO:Fitting Model
2023-07-31 14:44:03,900:INFO:Initializing predict_model()
2023-07-31 14:44:03,900:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f904d0d0>)
2023-07-31 14:44:03,900:INFO:Checking exceptions
2023-07-31 14:44:03,900:INFO:Preloading libraries
2023-07-31 14:44:04,158:INFO:_display_container: 2
2023-07-31 14:44:04,267:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 14:44:04,267:INFO:create_model() successfully completed......................................
2023-07-31 14:44:04,458:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:04,458:INFO:Creating metrics dataframe
2023-07-31 14:44:04,471:INFO:Initializing Decision Tree Classifier
2023-07-31 14:44:04,472:INFO:Total runtime is 0.043306211630503334 minutes
2023-07-31 14:44:04,476:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:04,477:INFO:Initializing create_model()
2023-07-31 14:44:04,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:04,477:INFO:Checking exceptions
2023-07-31 14:44:04,477:INFO:Importing libraries
2023-07-31 14:44:04,477:INFO:Copying training dataset
2023-07-31 14:44:04,484:INFO:Defining folds
2023-07-31 14:44:04,485:INFO:Declaring metric variables
2023-07-31 14:44:04,490:INFO:Importing untrained model
2023-07-31 14:44:04,495:INFO:Decision Tree Classifier Imported successfully
2023-07-31 14:44:04,501:INFO:Cross validation set to False
2023-07-31 14:44:04,501:INFO:Fitting Model
2023-07-31 14:44:04,596:INFO:Initializing predict_model()
2023-07-31 14:44:04,596:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=44, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f904d3a0>)
2023-07-31 14:44:04,596:INFO:Checking exceptions
2023-07-31 14:44:04,596:INFO:Preloading libraries
2023-07-31 14:44:04,870:INFO:_display_container: 2
2023-07-31 14:44:04,984:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=44, splitter='best')
2023-07-31 14:44:04,984:INFO:create_model() successfully completed......................................
2023-07-31 14:44:05,158:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:05,158:INFO:Creating metrics dataframe
2023-07-31 14:44:05,172:INFO:Initializing SVM - Linear Kernel
2023-07-31 14:44:05,172:INFO:Total runtime is 0.054974182446797686 minutes
2023-07-31 14:44:05,177:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:05,177:INFO:Initializing create_model()
2023-07-31 14:44:05,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:05,177:INFO:Checking exceptions
2023-07-31 14:44:05,177:INFO:Importing libraries
2023-07-31 14:44:05,178:INFO:Copying training dataset
2023-07-31 14:44:05,185:INFO:Defining folds
2023-07-31 14:44:05,186:INFO:Declaring metric variables
2023-07-31 14:44:05,190:INFO:Importing untrained model
2023-07-31 14:44:05,196:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 14:44:05,201:INFO:Cross validation set to False
2023-07-31 14:44:05,202:INFO:Fitting Model
2023-07-31 14:44:05,260:INFO:Initializing predict_model()
2023-07-31 14:44:05,260:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('actual_estimator',
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=44,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fa846f70>)
2023-07-31 14:44:05,260:INFO:Checking exceptions
2023-07-31 14:44:05,260:INFO:Preloading libraries
2023-07-31 14:44:05,533:INFO:_display_container: 2
2023-07-31 14:44:05,651:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=44, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 14:44:05,652:INFO:create_model() successfully completed......................................
2023-07-31 14:44:05,835:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:05,835:INFO:Creating metrics dataframe
2023-07-31 14:44:05,851:INFO:Initializing Ridge Classifier
2023-07-31 14:44:05,851:INFO:Total runtime is 0.06629695494969685 minutes
2023-07-31 14:44:05,856:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:05,857:INFO:Initializing create_model()
2023-07-31 14:44:05,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:05,857:INFO:Checking exceptions
2023-07-31 14:44:05,857:INFO:Importing libraries
2023-07-31 14:44:05,857:INFO:Copying training dataset
2023-07-31 14:44:05,867:INFO:Defining folds
2023-07-31 14:44:05,867:INFO:Declaring metric variables
2023-07-31 14:44:05,873:INFO:Importing untrained model
2023-07-31 14:44:05,879:INFO:Ridge Classifier Imported successfully
2023-07-31 14:44:05,886:INFO:Cross validation set to False
2023-07-31 14:44:05,886:INFO:Fitting Model
2023-07-31 14:44:06,055:INFO:Initializing predict_model()
2023-07-31 14:44:06,055:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=44, solver='auto',
                                 tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f8f08310>)
2023-07-31 14:44:06,055:INFO:Checking exceptions
2023-07-31 14:44:06,055:INFO:Preloading libraries
2023-07-31 14:44:06,351:INFO:_display_container: 2
2023-07-31 14:44:06,468:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=44, solver='auto',
                tol=0.0001)
2023-07-31 14:44:06,468:INFO:create_model() successfully completed......................................
2023-07-31 14:44:06,630:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:06,631:INFO:Creating metrics dataframe
2023-07-31 14:44:06,645:INFO:Initializing Random Forest Classifier
2023-07-31 14:44:06,646:INFO:Total runtime is 0.07953539689381917 minutes
2023-07-31 14:44:06,651:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:06,652:INFO:Initializing create_model()
2023-07-31 14:44:06,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:06,652:INFO:Checking exceptions
2023-07-31 14:44:06,652:INFO:Importing libraries
2023-07-31 14:44:06,652:INFO:Copying training dataset
2023-07-31 14:44:06,661:INFO:Defining folds
2023-07-31 14:44:06,661:INFO:Declaring metric variables
2023-07-31 14:44:06,665:INFO:Importing untrained model
2023-07-31 14:44:06,670:INFO:Random Forest Classifier Imported successfully
2023-07-31 14:44:06,675:INFO:Cross validation set to False
2023-07-31 14:44:06,675:INFO:Fitting Model
2023-07-31 14:44:07,381:INFO:Initializing predict_model()
2023-07-31 14:44:07,381:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=44,
                                        verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b1b55280>)
2023-07-31 14:44:07,381:INFO:Checking exceptions
2023-07-31 14:44:07,381:INFO:Preloading libraries
2023-07-31 14:44:07,752:INFO:_display_container: 2
2023-07-31 14:44:07,883:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=44, verbose=0, warm_start=False)
2023-07-31 14:44:07,883:INFO:create_model() successfully completed......................................
2023-07-31 14:44:08,068:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:08,068:INFO:Creating metrics dataframe
2023-07-31 14:44:08,082:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 14:44:08,082:INFO:Total runtime is 0.10347416003545125 minutes
2023-07-31 14:44:08,086:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:08,087:INFO:Initializing create_model()
2023-07-31 14:44:08,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:08,087:INFO:Checking exceptions
2023-07-31 14:44:08,087:INFO:Importing libraries
2023-07-31 14:44:08,088:INFO:Copying training dataset
2023-07-31 14:44:08,100:INFO:Defining folds
2023-07-31 14:44:08,100:INFO:Declaring metric variables
2023-07-31 14:44:08,104:INFO:Importing untrained model
2023-07-31 14:44:08,107:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 14:44:08,112:INFO:Cross validation set to False
2023-07-31 14:44:08,112:INFO:Fitting Model
2023-07-31 14:44:08,297:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:44:08,570:INFO:Initializing predict_model()
2023-07-31 14:44:08,570:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f904d3a0>)
2023-07-31 14:44:08,570:INFO:Checking exceptions
2023-07-31 14:44:08,570:INFO:Preloading libraries
2023-07-31 14:44:08,857:INFO:_display_container: 2
2023-07-31 14:44:08,965:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 14:44:08,965:INFO:create_model() successfully completed......................................
2023-07-31 14:44:09,141:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:09,141:INFO:Creating metrics dataframe
2023-07-31 14:44:09,155:INFO:Initializing Ada Boost Classifier
2023-07-31 14:44:09,155:INFO:Total runtime is 0.12136094967524211 minutes
2023-07-31 14:44:09,159:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:09,159:INFO:Initializing create_model()
2023-07-31 14:44:09,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:09,159:INFO:Checking exceptions
2023-07-31 14:44:09,159:INFO:Importing libraries
2023-07-31 14:44:09,159:INFO:Copying training dataset
2023-07-31 14:44:09,165:INFO:Defining folds
2023-07-31 14:44:09,165:INFO:Declaring metric variables
2023-07-31 14:44:09,169:INFO:Importing untrained model
2023-07-31 14:44:09,173:INFO:Ada Boost Classifier Imported successfully
2023-07-31 14:44:09,178:INFO:Cross validation set to False
2023-07-31 14:44:09,178:INFO:Fitting Model
2023-07-31 14:44:10,370:INFO:Initializing predict_model()
2023-07-31 14:44:10,370:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=44))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f904df70>)
2023-07-31 14:44:10,370:INFO:Checking exceptions
2023-07-31 14:44:10,371:INFO:Preloading libraries
2023-07-31 14:44:10,596:INFO:_display_container: 2
2023-07-31 14:44:10,701:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=44)
2023-07-31 14:44:10,701:INFO:create_model() successfully completed......................................
2023-07-31 14:44:10,866:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:10,866:INFO:Creating metrics dataframe
2023-07-31 14:44:10,889:INFO:Initializing Gradient Boosting Classifier
2023-07-31 14:44:10,890:INFO:Total runtime is 0.15027180115381877 minutes
2023-07-31 14:44:10,894:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:10,894:INFO:Initializing create_model()
2023-07-31 14:44:10,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:10,894:INFO:Checking exceptions
2023-07-31 14:44:10,894:INFO:Importing libraries
2023-07-31 14:44:10,894:INFO:Copying training dataset
2023-07-31 14:44:10,901:INFO:Defining folds
2023-07-31 14:44:10,901:INFO:Declaring metric variables
2023-07-31 14:44:10,905:INFO:Importing untrained model
2023-07-31 14:44:10,909:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 14:44:10,914:INFO:Cross validation set to False
2023-07-31 14:44:10,914:INFO:Fitting Model
2023-07-31 14:44:14,426:INFO:Initializing predict_model()
2023-07-31 14:44:14,426:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=44, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f8b06820>)
2023-07-31 14:44:14,426:INFO:Checking exceptions
2023-07-31 14:44:14,426:INFO:Preloading libraries
2023-07-31 14:44:14,628:INFO:_display_container: 2
2023-07-31 14:44:14,729:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=44, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 14:44:14,729:INFO:create_model() successfully completed......................................
2023-07-31 14:44:14,846:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:14,846:INFO:Creating metrics dataframe
2023-07-31 14:44:14,860:INFO:Initializing Linear Discriminant Analysis
2023-07-31 14:44:14,861:INFO:Total runtime is 0.21645290454228722 minutes
2023-07-31 14:44:14,864:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:14,864:INFO:Initializing create_model()
2023-07-31 14:44:14,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:14,865:INFO:Checking exceptions
2023-07-31 14:44:14,865:INFO:Importing libraries
2023-07-31 14:44:14,865:INFO:Copying training dataset
2023-07-31 14:44:14,871:INFO:Defining folds
2023-07-31 14:44:14,871:INFO:Declaring metric variables
2023-07-31 14:44:14,875:INFO:Importing untrained model
2023-07-31 14:44:14,878:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 14:44:14,883:INFO:Cross validation set to False
2023-07-31 14:44:14,883:INFO:Fitting Model
2023-07-31 14:44:15,239:INFO:Initializing predict_model()
2023-07-31 14:44:15,240:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b1b5b790>)
2023-07-31 14:44:15,240:INFO:Checking exceptions
2023-07-31 14:44:15,240:INFO:Preloading libraries
2023-07-31 14:44:15,448:INFO:_display_container: 2
2023-07-31 14:44:15,561:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 14:44:15,561:INFO:create_model() successfully completed......................................
2023-07-31 14:44:15,727:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:15,727:INFO:Creating metrics dataframe
2023-07-31 14:44:15,741:INFO:Initializing Extra Trees Classifier
2023-07-31 14:44:15,741:INFO:Total runtime is 0.23113201459248864 minutes
2023-07-31 14:44:15,745:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:15,745:INFO:Initializing create_model()
2023-07-31 14:44:15,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:15,745:INFO:Checking exceptions
2023-07-31 14:44:15,746:INFO:Importing libraries
2023-07-31 14:44:15,746:INFO:Copying training dataset
2023-07-31 14:44:15,751:INFO:Defining folds
2023-07-31 14:44:15,751:INFO:Declaring metric variables
2023-07-31 14:44:15,755:INFO:Importing untrained model
2023-07-31 14:44:15,759:INFO:Extra Trees Classifier Imported successfully
2023-07-31 14:44:15,764:INFO:Cross validation set to False
2023-07-31 14:44:15,764:INFO:Fitting Model
2023-07-31 14:44:16,312:INFO:Initializing predict_model()
2023-07-31 14:44:16,312:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=44,
                                      verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f8b069d0>)
2023-07-31 14:44:16,312:INFO:Checking exceptions
2023-07-31 14:44:16,312:INFO:Preloading libraries
2023-07-31 14:44:16,665:INFO:_display_container: 2
2023-07-31 14:44:16,786:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=44, verbose=0, warm_start=False)
2023-07-31 14:44:16,786:INFO:create_model() successfully completed......................................
2023-07-31 14:44:16,946:INFO:SubProcess create_model() end ==================================
2023-07-31 14:44:16,947:INFO:Creating metrics dataframe
2023-07-31 14:44:16,962:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 14:44:16,962:INFO:Total runtime is 0.25147266785303757 minutes
2023-07-31 14:44:16,966:INFO:SubProcess create_model() called ==================================
2023-07-31 14:44:16,966:INFO:Initializing create_model()
2023-07-31 14:44:16,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:44:16,967:INFO:Checking exceptions
2023-07-31 14:44:16,967:INFO:Importing libraries
2023-07-31 14:44:16,967:INFO:Copying training dataset
2023-07-31 14:44:16,974:INFO:Defining folds
2023-07-31 14:44:16,974:INFO:Declaring metric variables
2023-07-31 14:44:16,979:INFO:Importing untrained model
2023-07-31 14:44:16,982:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 14:44:16,987:INFO:Cross validation set to False
2023-07-31 14:44:16,988:INFO:Fitting Model
2023-07-31 14:45:42,375:INFO:Initializing predict_model()
2023-07-31 14:45:42,377:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=44,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b1b5bdc0>)
2023-07-31 14:45:42,377:INFO:Checking exceptions
2023-07-31 14:45:42,377:INFO:Preloading libraries
2023-07-31 14:45:42,918:INFO:_display_container: 2
2023-07-31 14:45:43,353:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=44, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 14:45:43,353:INFO:create_model() successfully completed......................................
2023-07-31 14:45:43,516:INFO:SubProcess create_model() end ==================================
2023-07-31 14:45:43,516:INFO:Creating metrics dataframe
2023-07-31 14:45:43,533:INFO:Initializing Dummy Classifier
2023-07-31 14:45:43,533:INFO:Total runtime is 1.6943342288335166 minutes
2023-07-31 14:45:43,538:INFO:SubProcess create_model() called ==================================
2023-07-31 14:45:43,538:INFO:Initializing create_model()
2023-07-31 14:45:43,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9706b80>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:45:43,538:INFO:Checking exceptions
2023-07-31 14:45:43,539:INFO:Importing libraries
2023-07-31 14:45:43,539:INFO:Copying training dataset
2023-07-31 14:45:43,547:INFO:Defining folds
2023-07-31 14:45:43,548:INFO:Declaring metric variables
2023-07-31 14:45:43,552:INFO:Importing untrained model
2023-07-31 14:45:43,556:INFO:Dummy Classifier Imported successfully
2023-07-31 14:45:43,562:INFO:Cross validation set to False
2023-07-31 14:45:43,562:INFO:Fitting Model
2023-07-31 14:45:43,611:INFO:Initializing predict_model()
2023-07-31 14:45:43,611:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DummyClassifier(constant=None, random_state=44,
                                 strategy='prior'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f8b06790>)
2023-07-31 14:45:43,611:INFO:Checking exceptions
2023-07-31 14:45:43,611:INFO:Preloading libraries
2023-07-31 14:45:43,690:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 14:45:43,891:INFO:_display_container: 2
2023-07-31 14:45:44,002:INFO:DummyClassifier(constant=None, random_state=44, strategy='prior')
2023-07-31 14:45:44,002:INFO:create_model() successfully completed......................................
2023-07-31 14:45:44,188:INFO:SubProcess create_model() end ==================================
2023-07-31 14:45:44,189:INFO:Creating metrics dataframe
2023-07-31 14:45:44,218:INFO:Initializing create_model()
2023-07-31 14:45:44,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9059820>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:45:44,218:INFO:Checking exceptions
2023-07-31 14:45:44,220:INFO:Importing libraries
2023-07-31 14:45:44,221:INFO:Copying training dataset
2023-07-31 14:45:44,227:INFO:Defining folds
2023-07-31 14:45:44,227:INFO:Declaring metric variables
2023-07-31 14:45:44,227:INFO:Importing untrained model
2023-07-31 14:45:44,227:INFO:Declaring custom model
2023-07-31 14:45:44,228:INFO:Logistic Regression Imported successfully
2023-07-31 14:45:44,229:INFO:Cross validation set to False
2023-07-31 14:45:44,229:INFO:Fitting Model
2023-07-31 14:45:44,381:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:45:44,381:INFO:create_model() successfully completed......................................
2023-07-31 14:45:44,604:INFO:_master_model_container: 0
2023-07-31 14:45:44,604:INFO:_display_container: 2
2023-07-31 14:45:44,605:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:45:44,605:INFO:compare_models() successfully completed......................................
2023-07-31 14:51:54,013:INFO:Initializing set_config()
2023-07-31 14:51:54,013:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, variable=seed, value=42, kwargs={})
2023-07-31 14:51:54,013:INFO:Global variable: seed updated to 42
2023-07-31 14:51:54,013:INFO:set_config() successfully completed......................................
2023-07-31 14:51:54,123:INFO:PyCaret ClassificationExperiment
2023-07-31 14:51:54,123:INFO:Logging name: clf-default-name
2023-07-31 14:51:54,123:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 14:51:54,123:INFO:version 3.0.2
2023-07-31 14:51:54,123:INFO:Initializing setup()
2023-07-31 14:51:54,123:INFO:self.USI: c897
2023-07-31 14:51:54,123:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 14:51:54,123:INFO:Checking environment
2023-07-31 14:51:54,123:INFO:python_version: 3.9.16
2023-07-31 14:51:54,123:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 14:51:54,124:INFO:machine: x86_64
2023-07-31 14:51:54,124:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:51:54,124:INFO:Memory: svmem(total=67419119616, available=33639755776, percent=50.1, used=32863936512, free=29990158336, active=30071156736, inactive=5097041920, buffers=68177920, cached=4496846848, shared=220987392, slab=1288122368)
2023-07-31 14:51:54,125:INFO:Physical Core: 28
2023-07-31 14:51:54,125:INFO:Logical Core: 56
2023-07-31 14:51:54,125:INFO:Checking libraries
2023-07-31 14:51:54,126:INFO:System:
2023-07-31 14:51:54,126:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 14:51:54,126:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 14:51:54,126:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:51:54,126:INFO:PyCaret required dependencies:
2023-07-31 14:51:54,126:INFO:                 pip: 23.0.1
2023-07-31 14:51:54,126:INFO:          setuptools: 66.0.0
2023-07-31 14:51:54,126:INFO:             pycaret: 3.0.2
2023-07-31 14:51:54,126:INFO:             IPython: 8.13.2
2023-07-31 14:51:54,126:INFO:          ipywidgets: 8.0.6
2023-07-31 14:51:54,126:INFO:                tqdm: 4.65.0
2023-07-31 14:51:54,126:INFO:               numpy: 1.23.5
2023-07-31 14:51:54,126:INFO:              pandas: 1.5.3
2023-07-31 14:51:54,126:INFO:              jinja2: 3.1.2
2023-07-31 14:51:54,126:INFO:               scipy: 1.10.1
2023-07-31 14:51:54,126:INFO:              joblib: 1.2.0
2023-07-31 14:51:54,126:INFO:             sklearn: 1.2.2
2023-07-31 14:51:54,126:INFO:                pyod: 1.0.9
2023-07-31 14:51:54,126:INFO:            imblearn: 0.10.1
2023-07-31 14:51:54,126:INFO:   category_encoders: 2.6.1
2023-07-31 14:51:54,126:INFO:            lightgbm: 3.3.5
2023-07-31 14:51:54,126:INFO:               numba: 0.57.0
2023-07-31 14:51:54,126:INFO:            requests: 2.28.1
2023-07-31 14:51:54,126:INFO:          matplotlib: 3.7.1
2023-07-31 14:51:54,126:INFO:          scikitplot: 0.3.7
2023-07-31 14:51:54,126:INFO:         yellowbrick: 1.5
2023-07-31 14:51:54,126:INFO:              plotly: 5.14.1
2023-07-31 14:51:54,126:INFO:             kaleido: 0.2.1
2023-07-31 14:51:54,126:INFO:         statsmodels: 0.14.0
2023-07-31 14:51:54,126:INFO:              sktime: 0.17.0
2023-07-31 14:51:54,126:INFO:               tbats: 1.1.3
2023-07-31 14:51:54,127:INFO:            pmdarima: 2.0.3
2023-07-31 14:51:54,127:INFO:              psutil: 5.9.5
2023-07-31 14:51:54,127:INFO:PyCaret optional dependencies:
2023-07-31 14:51:54,127:INFO:                shap: Not installed
2023-07-31 14:51:54,127:INFO:           interpret: Not installed
2023-07-31 14:51:54,127:INFO:                umap: Not installed
2023-07-31 14:51:54,127:INFO:    pandas_profiling: Not installed
2023-07-31 14:51:54,127:INFO:  explainerdashboard: Not installed
2023-07-31 14:51:54,127:INFO:             autoviz: Not installed
2023-07-31 14:51:54,127:INFO:           fairlearn: Not installed
2023-07-31 14:51:54,127:INFO:             xgboost: Not installed
2023-07-31 14:51:54,127:INFO:            catboost: Not installed
2023-07-31 14:51:54,127:INFO:              kmodes: Not installed
2023-07-31 14:51:54,127:INFO:             mlxtend: Not installed
2023-07-31 14:51:54,127:INFO:       statsforecast: Not installed
2023-07-31 14:51:54,127:INFO:        tune_sklearn: Not installed
2023-07-31 14:51:54,127:INFO:                 ray: Not installed
2023-07-31 14:51:54,127:INFO:            hyperopt: Not installed
2023-07-31 14:51:54,127:INFO:              optuna: Not installed
2023-07-31 14:51:54,127:INFO:               skopt: Not installed
2023-07-31 14:51:54,127:INFO:              mlflow: Not installed
2023-07-31 14:51:54,127:INFO:              gradio: Not installed
2023-07-31 14:51:54,127:INFO:             fastapi: Not installed
2023-07-31 14:51:54,127:INFO:             uvicorn: Not installed
2023-07-31 14:51:54,127:INFO:              m2cgen: Not installed
2023-07-31 14:51:54,127:INFO:           evidently: Not installed
2023-07-31 14:51:54,127:INFO:               fugue: Not installed
2023-07-31 14:51:54,127:INFO:           streamlit: Not installed
2023-07-31 14:51:54,127:INFO:             prophet: Not installed
2023-07-31 14:51:54,127:INFO:None
2023-07-31 14:51:54,127:INFO:Set up data.
2023-07-31 14:51:57,972:INFO:Set up train/test split.
2023-07-31 14:51:58,145:INFO:Set up index.
2023-07-31 14:51:58,145:INFO:Set up folding strategy.
2023-07-31 14:51:58,145:INFO:Assigning column types.
2023-07-31 14:51:58,212:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 14:51:58,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:51:58,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:51:58,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:51:58,326:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:51:58,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,353:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 14:51:58,396:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:51:58,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,466:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:51:58,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,494:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,494:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 14:51:58,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:51:58,744:INFO:Preparing preprocessing pipeline...
2023-07-31 14:51:58,761:INFO:Set up simple imputation.
2023-07-31 14:51:58,774:INFO:Set up column name cleaning.
2023-07-31 14:51:59,823:INFO:Finished creating preprocessing pipeline.
2023-07-31 14:51:59,891:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 14:51:59,892:INFO:Creating final display dataframe.
2023-07-31 14:52:02,697:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (421, 11886)
4        Transformed data shape      (421, 11886)
5   Transformed train set shape      (378, 11886)
6    Transformed test set shape       (43, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c897
2023-07-31 14:52:02,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:52:02,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:52:02,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:52:02,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:52:02,851:INFO:setup() successfully completed in 8.84s...............
2023-07-31 14:52:02,859:INFO:Initializing compare_models()
2023-07-31 14:52:02,859:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 14:52:02,859:INFO:Checking exceptions
2023-07-31 14:52:02,909:INFO:Preparing display monitor
2023-07-31 14:52:02,935:INFO:Initializing Logistic Regression
2023-07-31 14:52:02,936:INFO:Total runtime is 3.596146901448568e-06 minutes
2023-07-31 14:52:02,939:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:02,939:INFO:Initializing create_model()
2023-07-31 14:52:02,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:02,940:INFO:Checking exceptions
2023-07-31 14:52:02,940:INFO:Importing libraries
2023-07-31 14:52:02,940:INFO:Copying training dataset
2023-07-31 14:52:03,008:INFO:Defining folds
2023-07-31 14:52:03,008:INFO:Declaring metric variables
2023-07-31 14:52:03,012:INFO:Importing untrained model
2023-07-31 14:52:03,016:INFO:Logistic Regression Imported successfully
2023-07-31 14:52:03,023:INFO:Starting cross validation
2023-07-31 14:52:03,066:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:52:12,440:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:13,176:INFO:Calculating mean and std
2023-07-31 14:52:13,180:INFO:Creating metrics dataframe
2023-07-31 14:52:13,336:INFO:Uploading results into container
2023-07-31 14:52:13,338:INFO:Uploading model into container now
2023-07-31 14:52:13,338:INFO:_master_model_container: 1
2023-07-31 14:52:13,338:INFO:_display_container: 2
2023-07-31 14:52:13,339:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:52:13,339:INFO:create_model() successfully completed......................................
2023-07-31 14:52:13,617:INFO:SubProcess create_model() end ==================================
2023-07-31 14:52:13,617:INFO:Creating metrics dataframe
2023-07-31 14:52:13,632:INFO:Initializing K Neighbors Classifier
2023-07-31 14:52:13,632:INFO:Total runtime is 0.1782848596572876 minutes
2023-07-31 14:52:13,637:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:13,637:INFO:Initializing create_model()
2023-07-31 14:52:13,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:13,638:INFO:Checking exceptions
2023-07-31 14:52:13,638:INFO:Importing libraries
2023-07-31 14:52:13,638:INFO:Copying training dataset
2023-07-31 14:52:13,718:INFO:Defining folds
2023-07-31 14:52:13,718:INFO:Declaring metric variables
2023-07-31 14:52:13,724:INFO:Importing untrained model
2023-07-31 14:52:13,728:INFO:K Neighbors Classifier Imported successfully
2023-07-31 14:52:13,736:INFO:Starting cross validation
2023-07-31 14:52:13,779:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:52:17,031:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:17,056:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:17,066:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:18,483:INFO:Calculating mean and std
2023-07-31 14:52:18,486:INFO:Creating metrics dataframe
2023-07-31 14:52:18,689:INFO:Uploading results into container
2023-07-31 14:52:18,690:INFO:Uploading model into container now
2023-07-31 14:52:18,691:INFO:_master_model_container: 2
2023-07-31 14:52:18,691:INFO:_display_container: 2
2023-07-31 14:52:18,692:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 14:52:18,692:INFO:create_model() successfully completed......................................
2023-07-31 14:52:18,989:INFO:SubProcess create_model() end ==================================
2023-07-31 14:52:18,990:INFO:Creating metrics dataframe
2023-07-31 14:52:19,003:INFO:Initializing Naive Bayes
2023-07-31 14:52:19,003:INFO:Total runtime is 0.2677969535191854 minutes
2023-07-31 14:52:19,008:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:19,008:INFO:Initializing create_model()
2023-07-31 14:52:19,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:19,008:INFO:Checking exceptions
2023-07-31 14:52:19,008:INFO:Importing libraries
2023-07-31 14:52:19,008:INFO:Copying training dataset
2023-07-31 14:52:19,082:INFO:Defining folds
2023-07-31 14:52:19,083:INFO:Declaring metric variables
2023-07-31 14:52:19,088:INFO:Importing untrained model
2023-07-31 14:52:19,092:INFO:Naive Bayes Imported successfully
2023-07-31 14:52:19,100:INFO:Starting cross validation
2023-07-31 14:52:19,143:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:52:22,536:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:22,540:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:22,637:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:23,830:INFO:Calculating mean and std
2023-07-31 14:52:23,834:INFO:Creating metrics dataframe
2023-07-31 14:52:24,031:INFO:Uploading results into container
2023-07-31 14:52:24,032:INFO:Uploading model into container now
2023-07-31 14:52:24,033:INFO:_master_model_container: 3
2023-07-31 14:52:24,033:INFO:_display_container: 2
2023-07-31 14:52:24,033:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 14:52:24,033:INFO:create_model() successfully completed......................................
2023-07-31 14:52:24,319:INFO:SubProcess create_model() end ==================================
2023-07-31 14:52:24,320:INFO:Creating metrics dataframe
2023-07-31 14:52:24,333:INFO:Initializing Decision Tree Classifier
2023-07-31 14:52:24,333:INFO:Total runtime is 0.356628155708313 minutes
2023-07-31 14:52:24,337:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:24,338:INFO:Initializing create_model()
2023-07-31 14:52:24,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:24,338:INFO:Checking exceptions
2023-07-31 14:52:24,338:INFO:Importing libraries
2023-07-31 14:52:24,338:INFO:Copying training dataset
2023-07-31 14:52:24,409:INFO:Defining folds
2023-07-31 14:52:24,410:INFO:Declaring metric variables
2023-07-31 14:52:24,414:INFO:Importing untrained model
2023-07-31 14:52:24,419:INFO:Decision Tree Classifier Imported successfully
2023-07-31 14:52:24,426:INFO:Starting cross validation
2023-07-31 14:52:24,469:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:52:28,454:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:29,852:INFO:Calculating mean and std
2023-07-31 14:52:29,854:INFO:Creating metrics dataframe
2023-07-31 14:52:30,062:INFO:Uploading results into container
2023-07-31 14:52:30,064:INFO:Uploading model into container now
2023-07-31 14:52:30,064:INFO:_master_model_container: 4
2023-07-31 14:52:30,065:INFO:_display_container: 2
2023-07-31 14:52:30,065:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 14:52:30,065:INFO:create_model() successfully completed......................................
2023-07-31 14:52:30,333:INFO:SubProcess create_model() end ==================================
2023-07-31 14:52:30,333:INFO:Creating metrics dataframe
2023-07-31 14:52:30,346:INFO:Initializing SVM - Linear Kernel
2023-07-31 14:52:30,347:INFO:Total runtime is 0.45685461759567264 minutes
2023-07-31 14:52:30,351:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:30,352:INFO:Initializing create_model()
2023-07-31 14:52:30,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:30,352:INFO:Checking exceptions
2023-07-31 14:52:30,352:INFO:Importing libraries
2023-07-31 14:52:30,352:INFO:Copying training dataset
2023-07-31 14:52:30,427:INFO:Defining folds
2023-07-31 14:52:30,427:INFO:Declaring metric variables
2023-07-31 14:52:30,432:INFO:Importing untrained model
2023-07-31 14:52:30,437:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 14:52:30,444:INFO:Starting cross validation
2023-07-31 14:52:30,488:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:52:34,199:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:52:34,264:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:34,338:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:52:34,407:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:34,431:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:52:34,473:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:52:34,479:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:52:34,481:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:52:34,502:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:34,560:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:52:34,574:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:52:35,105:INFO:Calculating mean and std
2023-07-31 14:52:35,109:INFO:Creating metrics dataframe
2023-07-31 14:52:35,536:INFO:Uploading results into container
2023-07-31 14:52:35,537:INFO:Uploading model into container now
2023-07-31 14:52:35,538:INFO:_master_model_container: 5
2023-07-31 14:52:35,538:INFO:_display_container: 2
2023-07-31 14:52:35,539:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 14:52:35,539:INFO:create_model() successfully completed......................................
2023-07-31 14:52:35,773:INFO:SubProcess create_model() end ==================================
2023-07-31 14:52:35,773:INFO:Creating metrics dataframe
2023-07-31 14:52:35,789:INFO:Initializing Ridge Classifier
2023-07-31 14:52:35,789:INFO:Total runtime is 0.5475571552912395 minutes
2023-07-31 14:52:35,793:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:35,794:INFO:Initializing create_model()
2023-07-31 14:52:35,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:35,794:INFO:Checking exceptions
2023-07-31 14:52:35,794:INFO:Importing libraries
2023-07-31 14:52:35,794:INFO:Copying training dataset
2023-07-31 14:52:35,895:INFO:Defining folds
2023-07-31 14:52:35,898:INFO:Declaring metric variables
2023-07-31 14:52:35,904:INFO:Importing untrained model
2023-07-31 14:52:35,909:INFO:Ridge Classifier Imported successfully
2023-07-31 14:52:35,917:INFO:Starting cross validation
2023-07-31 14:52:35,965:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:52:39,236:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:52:39,352:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:52:39,392:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:39,446:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:52:39,451:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:39,465:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:52:39,525:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:52:39,527:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:52:39,645:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:39,719:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:52:39,865:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:52:40,786:INFO:Calculating mean and std
2023-07-31 14:52:40,791:INFO:Creating metrics dataframe
2023-07-31 14:52:41,428:INFO:Uploading results into container
2023-07-31 14:52:41,430:INFO:Uploading model into container now
2023-07-31 14:52:41,432:INFO:_master_model_container: 6
2023-07-31 14:52:41,432:INFO:_display_container: 2
2023-07-31 14:52:41,433:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 14:52:41,433:INFO:create_model() successfully completed......................................
2023-07-31 14:52:41,767:INFO:SubProcess create_model() end ==================================
2023-07-31 14:52:41,767:INFO:Creating metrics dataframe
2023-07-31 14:52:41,783:INFO:Initializing Random Forest Classifier
2023-07-31 14:52:41,783:INFO:Total runtime is 0.6474622567494711 minutes
2023-07-31 14:52:41,788:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:41,788:INFO:Initializing create_model()
2023-07-31 14:52:41,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:41,789:INFO:Checking exceptions
2023-07-31 14:52:41,789:INFO:Importing libraries
2023-07-31 14:52:41,789:INFO:Copying training dataset
2023-07-31 14:52:41,900:INFO:Defining folds
2023-07-31 14:52:41,900:INFO:Declaring metric variables
2023-07-31 14:52:41,905:INFO:Importing untrained model
2023-07-31 14:52:41,912:INFO:Random Forest Classifier Imported successfully
2023-07-31 14:52:41,922:INFO:Starting cross validation
2023-07-31 14:52:41,970:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:52:45,808:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:45,818:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:46,009:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:46,068:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:46,088:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:46,112:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:46,124:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:46,179:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:47,377:INFO:Calculating mean and std
2023-07-31 14:52:47,380:INFO:Creating metrics dataframe
2023-07-31 14:52:47,561:INFO:Uploading results into container
2023-07-31 14:52:47,563:INFO:Uploading model into container now
2023-07-31 14:52:47,564:INFO:_master_model_container: 7
2023-07-31 14:52:47,564:INFO:_display_container: 2
2023-07-31 14:52:47,565:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 14:52:47,565:INFO:create_model() successfully completed......................................
2023-07-31 14:52:47,834:INFO:SubProcess create_model() end ==================================
2023-07-31 14:52:47,834:INFO:Creating metrics dataframe
2023-07-31 14:52:47,849:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 14:52:47,849:INFO:Total runtime is 0.7485660473505656 minutes
2023-07-31 14:52:47,854:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:47,855:INFO:Initializing create_model()
2023-07-31 14:52:47,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:47,855:INFO:Checking exceptions
2023-07-31 14:52:47,855:INFO:Importing libraries
2023-07-31 14:52:47,855:INFO:Copying training dataset
2023-07-31 14:52:47,946:INFO:Defining folds
2023-07-31 14:52:47,946:INFO:Declaring metric variables
2023-07-31 14:52:47,951:INFO:Importing untrained model
2023-07-31 14:52:47,955:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 14:52:47,962:INFO:Starting cross validation
2023-07-31 14:52:48,005:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:52:48,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:52:48,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:52:48,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:52:48,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:52:48,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:52:48,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:52:48,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:52:48,850:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:52:51,644:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:51,709:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:52:53,191:INFO:Calculating mean and std
2023-07-31 14:52:53,194:INFO:Creating metrics dataframe
2023-07-31 14:52:53,370:INFO:Uploading results into container
2023-07-31 14:52:53,371:INFO:Uploading model into container now
2023-07-31 14:52:53,371:INFO:_master_model_container: 8
2023-07-31 14:52:53,372:INFO:_display_container: 2
2023-07-31 14:52:53,372:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 14:52:53,372:INFO:create_model() successfully completed......................................
2023-07-31 14:52:53,623:INFO:SubProcess create_model() end ==================================
2023-07-31 14:52:53,623:INFO:Creating metrics dataframe
2023-07-31 14:52:53,644:INFO:Initializing Ada Boost Classifier
2023-07-31 14:52:53,645:INFO:Total runtime is 0.8451524774233501 minutes
2023-07-31 14:52:53,649:INFO:SubProcess create_model() called ==================================
2023-07-31 14:52:53,650:INFO:Initializing create_model()
2023-07-31 14:52:53,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:52:53,650:INFO:Checking exceptions
2023-07-31 14:52:53,650:INFO:Importing libraries
2023-07-31 14:52:53,650:INFO:Copying training dataset
2023-07-31 14:52:53,738:INFO:Defining folds
2023-07-31 14:52:53,738:INFO:Declaring metric variables
2023-07-31 14:52:53,743:INFO:Importing untrained model
2023-07-31 14:52:53,748:INFO:Ada Boost Classifier Imported successfully
2023-07-31 14:52:53,756:INFO:Starting cross validation
2023-07-31 14:52:53,803:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:53:16,302:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:53:16,305:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:53:16,387:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:53:16,468:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:53:16,879:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:53:17,065:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:53:17,134:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:53:17,427:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:53:17,964:INFO:Calculating mean and std
2023-07-31 14:53:17,967:INFO:Creating metrics dataframe
2023-07-31 14:53:18,419:INFO:Uploading results into container
2023-07-31 14:53:18,421:INFO:Uploading model into container now
2023-07-31 14:53:18,421:INFO:_master_model_container: 9
2023-07-31 14:53:18,421:INFO:_display_container: 2
2023-07-31 14:53:18,422:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 14:53:18,422:INFO:create_model() successfully completed......................................
2023-07-31 14:53:18,671:INFO:SubProcess create_model() end ==================================
2023-07-31 14:53:18,671:INFO:Creating metrics dataframe
2023-07-31 14:53:18,686:INFO:Initializing Gradient Boosting Classifier
2023-07-31 14:53:18,687:INFO:Total runtime is 1.2625206589698792 minutes
2023-07-31 14:53:18,691:INFO:SubProcess create_model() called ==================================
2023-07-31 14:53:18,691:INFO:Initializing create_model()
2023-07-31 14:53:18,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:53:18,691:INFO:Checking exceptions
2023-07-31 14:53:18,692:INFO:Importing libraries
2023-07-31 14:53:18,692:INFO:Copying training dataset
2023-07-31 14:53:18,775:INFO:Defining folds
2023-07-31 14:53:18,775:INFO:Declaring metric variables
2023-07-31 14:53:18,779:INFO:Importing untrained model
2023-07-31 14:53:18,784:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 14:53:18,791:INFO:Starting cross validation
2023-07-31 14:53:18,837:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:54:04,363:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:36,554:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:36,763:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:36,980:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:36,990:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:36,997:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:37,181:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:38,209:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:38,692:INFO:Calculating mean and std
2023-07-31 14:54:38,697:INFO:Creating metrics dataframe
2023-07-31 14:54:39,111:INFO:Uploading results into container
2023-07-31 14:54:39,112:INFO:Uploading model into container now
2023-07-31 14:54:39,113:INFO:_master_model_container: 10
2023-07-31 14:54:39,113:INFO:_display_container: 2
2023-07-31 14:54:39,114:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 14:54:39,114:INFO:create_model() successfully completed......................................
2023-07-31 14:54:39,317:INFO:SubProcess create_model() end ==================================
2023-07-31 14:54:39,317:INFO:Creating metrics dataframe
2023-07-31 14:54:39,330:INFO:Initializing Linear Discriminant Analysis
2023-07-31 14:54:39,330:INFO:Total runtime is 2.606579101085663 minutes
2023-07-31 14:54:39,334:INFO:SubProcess create_model() called ==================================
2023-07-31 14:54:39,334:INFO:Initializing create_model()
2023-07-31 14:54:39,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:54:39,334:INFO:Checking exceptions
2023-07-31 14:54:39,334:INFO:Importing libraries
2023-07-31 14:54:39,334:INFO:Copying training dataset
2023-07-31 14:54:39,398:INFO:Defining folds
2023-07-31 14:54:39,398:INFO:Declaring metric variables
2023-07-31 14:54:39,402:INFO:Importing untrained model
2023-07-31 14:54:39,405:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 14:54:39,411:INFO:Starting cross validation
2023-07-31 14:54:39,449:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:54:44,841:INFO:Calculating mean and std
2023-07-31 14:54:44,845:INFO:Creating metrics dataframe
2023-07-31 14:54:44,979:INFO:Uploading results into container
2023-07-31 14:54:44,980:INFO:Uploading model into container now
2023-07-31 14:54:44,981:INFO:_master_model_container: 11
2023-07-31 14:54:44,981:INFO:_display_container: 2
2023-07-31 14:54:44,982:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 14:54:44,982:INFO:create_model() successfully completed......................................
2023-07-31 14:54:45,145:INFO:SubProcess create_model() end ==================================
2023-07-31 14:54:45,145:INFO:Creating metrics dataframe
2023-07-31 14:54:45,158:INFO:Initializing Extra Trees Classifier
2023-07-31 14:54:45,159:INFO:Total runtime is 2.703721058368683 minutes
2023-07-31 14:54:45,162:INFO:SubProcess create_model() called ==================================
2023-07-31 14:54:45,162:INFO:Initializing create_model()
2023-07-31 14:54:45,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:54:45,163:INFO:Checking exceptions
2023-07-31 14:54:45,163:INFO:Importing libraries
2023-07-31 14:54:45,163:INFO:Copying training dataset
2023-07-31 14:54:45,222:INFO:Defining folds
2023-07-31 14:54:45,223:INFO:Declaring metric variables
2023-07-31 14:54:45,226:INFO:Importing untrained model
2023-07-31 14:54:45,230:INFO:Extra Trees Classifier Imported successfully
2023-07-31 14:54:45,237:INFO:Starting cross validation
2023-07-31 14:54:45,279:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:54:47,780:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:47,787:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:47,842:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:47,872:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:47,952:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:47,980:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:47,991:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:48,038:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:54:49,234:INFO:Calculating mean and std
2023-07-31 14:54:49,236:INFO:Creating metrics dataframe
2023-07-31 14:54:49,668:INFO:Uploading results into container
2023-07-31 14:54:49,669:INFO:Uploading model into container now
2023-07-31 14:54:49,670:INFO:_master_model_container: 12
2023-07-31 14:54:49,670:INFO:_display_container: 2
2023-07-31 14:54:49,670:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 14:54:49,671:INFO:create_model() successfully completed......................................
2023-07-31 14:54:49,812:INFO:SubProcess create_model() end ==================================
2023-07-31 14:54:49,812:INFO:Creating metrics dataframe
2023-07-31 14:54:49,825:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 14:54:49,825:INFO:Total runtime is 2.7815022945404055 minutes
2023-07-31 14:54:49,829:INFO:SubProcess create_model() called ==================================
2023-07-31 14:54:49,829:INFO:Initializing create_model()
2023-07-31 14:54:49,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:54:49,830:INFO:Checking exceptions
2023-07-31 14:54:49,830:INFO:Importing libraries
2023-07-31 14:54:49,830:INFO:Copying training dataset
2023-07-31 14:54:49,892:INFO:Defining folds
2023-07-31 14:54:49,893:INFO:Declaring metric variables
2023-07-31 14:54:49,897:INFO:Importing untrained model
2023-07-31 14:54:49,900:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 14:54:49,907:INFO:Starting cross validation
2023-07-31 14:54:49,944:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:55:37,510:INFO:Calculating mean and std
2023-07-31 14:55:37,514:INFO:Creating metrics dataframe
2023-07-31 14:55:37,681:INFO:Uploading results into container
2023-07-31 14:55:37,683:INFO:Uploading model into container now
2023-07-31 14:55:37,683:INFO:_master_model_container: 13
2023-07-31 14:55:37,683:INFO:_display_container: 2
2023-07-31 14:55:37,684:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 14:55:37,684:INFO:create_model() successfully completed......................................
2023-07-31 14:55:37,854:INFO:SubProcess create_model() end ==================================
2023-07-31 14:55:37,854:INFO:Creating metrics dataframe
2023-07-31 14:55:37,869:INFO:Initializing Dummy Classifier
2023-07-31 14:55:37,869:INFO:Total runtime is 3.58222873210907 minutes
2023-07-31 14:55:37,873:INFO:SubProcess create_model() called ==================================
2023-07-31 14:55:37,873:INFO:Initializing create_model()
2023-07-31 14:55:37,873:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f91408e0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:55:37,873:INFO:Checking exceptions
2023-07-31 14:55:37,873:INFO:Importing libraries
2023-07-31 14:55:37,873:INFO:Copying training dataset
2023-07-31 14:55:37,936:INFO:Defining folds
2023-07-31 14:55:37,937:INFO:Declaring metric variables
2023-07-31 14:55:37,941:INFO:Importing untrained model
2023-07-31 14:55:37,944:INFO:Dummy Classifier Imported successfully
2023-07-31 14:55:37,951:INFO:Starting cross validation
2023-07-31 14:55:37,993:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:55:41,023:INFO:Calculating mean and std
2023-07-31 14:55:41,025:INFO:Creating metrics dataframe
2023-07-31 14:55:41,187:INFO:Uploading results into container
2023-07-31 14:55:41,188:INFO:Uploading model into container now
2023-07-31 14:55:41,188:INFO:_master_model_container: 14
2023-07-31 14:55:41,189:INFO:_display_container: 2
2023-07-31 14:55:41,189:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 14:55:41,189:INFO:create_model() successfully completed......................................
2023-07-31 14:55:41,328:INFO:SubProcess create_model() end ==================================
2023-07-31 14:55:41,328:INFO:Creating metrics dataframe
2023-07-31 14:55:41,356:INFO:Initializing create_model()
2023-07-31 14:55:41,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f9b840d0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:55:41,357:INFO:Checking exceptions
2023-07-31 14:55:41,359:INFO:Importing libraries
2023-07-31 14:55:41,360:INFO:Copying training dataset
2023-07-31 14:55:41,433:INFO:Defining folds
2023-07-31 14:55:41,433:INFO:Declaring metric variables
2023-07-31 14:55:41,433:INFO:Importing untrained model
2023-07-31 14:55:41,434:INFO:Declaring custom model
2023-07-31 14:55:41,434:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 14:55:41,495:INFO:Cross validation set to False
2023-07-31 14:55:41,495:INFO:Fitting Model
2023-07-31 14:55:44,785:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 14:55:44,785:INFO:create_model() successfully completed......................................
2023-07-31 14:55:44,945:INFO:_master_model_container: 14
2023-07-31 14:55:44,946:INFO:_display_container: 2
2023-07-31 14:55:44,946:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 14:55:44,946:INFO:compare_models() successfully completed......................................
2023-07-31 14:55:47,990:INFO:Initializing set_config()
2023-07-31 14:55:47,991:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, variable=seed, value=42, kwargs={})
2023-07-31 14:55:47,991:INFO:Global variable: seed updated to 42
2023-07-31 14:55:47,991:INFO:set_config() successfully completed......................................
2023-07-31 14:55:48,123:INFO:PyCaret ClassificationExperiment
2023-07-31 14:55:48,123:INFO:Logging name: clf-default-name
2023-07-31 14:55:48,123:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 14:55:48,123:INFO:version 3.0.2
2023-07-31 14:55:48,123:INFO:Initializing setup()
2023-07-31 14:55:48,123:INFO:self.USI: 9ea4
2023-07-31 14:55:48,123:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 14:55:48,123:INFO:Checking environment
2023-07-31 14:55:48,123:INFO:python_version: 3.9.16
2023-07-31 14:55:48,123:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 14:55:48,123:INFO:machine: x86_64
2023-07-31 14:55:48,123:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:55:48,124:INFO:Memory: svmem(total=67419119616, available=15197421568, percent=77.5, used=51319001088, free=7678414848, active=49901240320, inactive=7431127040, buffers=72544256, cached=8349159424, shared=210001920, slab=1410584576)
2023-07-31 14:55:48,125:INFO:Physical Core: 28
2023-07-31 14:55:48,125:INFO:Logical Core: 56
2023-07-31 14:55:48,125:INFO:Checking libraries
2023-07-31 14:55:48,126:INFO:System:
2023-07-31 14:55:48,126:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 14:55:48,126:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 14:55:48,126:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 14:55:48,126:INFO:PyCaret required dependencies:
2023-07-31 14:55:48,126:INFO:                 pip: 23.0.1
2023-07-31 14:55:48,126:INFO:          setuptools: 66.0.0
2023-07-31 14:55:48,126:INFO:             pycaret: 3.0.2
2023-07-31 14:55:48,126:INFO:             IPython: 8.13.2
2023-07-31 14:55:48,126:INFO:          ipywidgets: 8.0.6
2023-07-31 14:55:48,126:INFO:                tqdm: 4.65.0
2023-07-31 14:55:48,126:INFO:               numpy: 1.23.5
2023-07-31 14:55:48,126:INFO:              pandas: 1.5.3
2023-07-31 14:55:48,126:INFO:              jinja2: 3.1.2
2023-07-31 14:55:48,126:INFO:               scipy: 1.10.1
2023-07-31 14:55:48,126:INFO:              joblib: 1.2.0
2023-07-31 14:55:48,126:INFO:             sklearn: 1.2.2
2023-07-31 14:55:48,126:INFO:                pyod: 1.0.9
2023-07-31 14:55:48,126:INFO:            imblearn: 0.10.1
2023-07-31 14:55:48,126:INFO:   category_encoders: 2.6.1
2023-07-31 14:55:48,126:INFO:            lightgbm: 3.3.5
2023-07-31 14:55:48,126:INFO:               numba: 0.57.0
2023-07-31 14:55:48,126:INFO:            requests: 2.28.1
2023-07-31 14:55:48,126:INFO:          matplotlib: 3.7.1
2023-07-31 14:55:48,126:INFO:          scikitplot: 0.3.7
2023-07-31 14:55:48,126:INFO:         yellowbrick: 1.5
2023-07-31 14:55:48,126:INFO:              plotly: 5.14.1
2023-07-31 14:55:48,126:INFO:             kaleido: 0.2.1
2023-07-31 14:55:48,126:INFO:         statsmodels: 0.14.0
2023-07-31 14:55:48,126:INFO:              sktime: 0.17.0
2023-07-31 14:55:48,126:INFO:               tbats: 1.1.3
2023-07-31 14:55:48,127:INFO:            pmdarima: 2.0.3
2023-07-31 14:55:48,127:INFO:              psutil: 5.9.5
2023-07-31 14:55:48,127:INFO:PyCaret optional dependencies:
2023-07-31 14:55:48,127:INFO:                shap: Not installed
2023-07-31 14:55:48,127:INFO:           interpret: Not installed
2023-07-31 14:55:48,127:INFO:                umap: Not installed
2023-07-31 14:55:48,127:INFO:    pandas_profiling: Not installed
2023-07-31 14:55:48,127:INFO:  explainerdashboard: Not installed
2023-07-31 14:55:48,127:INFO:             autoviz: Not installed
2023-07-31 14:55:48,127:INFO:           fairlearn: Not installed
2023-07-31 14:55:48,127:INFO:             xgboost: Not installed
2023-07-31 14:55:48,127:INFO:            catboost: Not installed
2023-07-31 14:55:48,127:INFO:              kmodes: Not installed
2023-07-31 14:55:48,127:INFO:             mlxtend: Not installed
2023-07-31 14:55:48,127:INFO:       statsforecast: Not installed
2023-07-31 14:55:48,127:INFO:        tune_sklearn: Not installed
2023-07-31 14:55:48,127:INFO:                 ray: Not installed
2023-07-31 14:55:48,127:INFO:            hyperopt: Not installed
2023-07-31 14:55:48,127:INFO:              optuna: Not installed
2023-07-31 14:55:48,127:INFO:               skopt: Not installed
2023-07-31 14:55:48,127:INFO:              mlflow: Not installed
2023-07-31 14:55:48,127:INFO:              gradio: Not installed
2023-07-31 14:55:48,127:INFO:             fastapi: Not installed
2023-07-31 14:55:48,127:INFO:             uvicorn: Not installed
2023-07-31 14:55:48,127:INFO:              m2cgen: Not installed
2023-07-31 14:55:48,127:INFO:           evidently: Not installed
2023-07-31 14:55:48,127:INFO:               fugue: Not installed
2023-07-31 14:55:48,128:INFO:           streamlit: Not installed
2023-07-31 14:55:48,128:INFO:             prophet: Not installed
2023-07-31 14:55:48,128:INFO:None
2023-07-31 14:55:48,128:INFO:Set up data.
2023-07-31 14:55:52,358:INFO:Set up train/test split.
2023-07-31 14:55:52,552:INFO:Set up index.
2023-07-31 14:55:52,552:INFO:Set up folding strategy.
2023-07-31 14:55:52,552:INFO:Assigning column types.
2023-07-31 14:55:52,687:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 14:55:52,730:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:55:52,731:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:55:52,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:52,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:52,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:55:52,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:55:52,829:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:52,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:52,830:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 14:55:52,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:55:52,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:52,900:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:52,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:55:52,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:52,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:52,973:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 14:55:53,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:53,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:53,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:53,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:53,114:INFO:Preparing preprocessing pipeline...
2023-07-31 14:55:53,139:INFO:Set up simple imputation.
2023-07-31 14:55:53,161:INFO:Set up column name cleaning.
2023-07-31 14:55:54,247:INFO:Finished creating preprocessing pipeline.
2023-07-31 14:55:54,310:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['A1BG', 'A2LD1', 'A2M', 'A4GALT',
                                             'AAAS', 'AACS', 'AAGAB', 'AAK1',
                                             'AAMP', 'AARS2', 'AARSD1', 'AARS',
                                             'AASDHPPT', 'AASDH', 'AATF',
                                             'AATK', 'ABAT', 'ABCA10',
                                             'ABCA11P', 'ABCA1', 'ABCA2',
                                             'ABCA3', 'ABCA5', 'ABCA6', 'ABCA7',
                                             'ABCB10', 'ABCB1', 'ABCB4',
                                             'ABCB6', 'A...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-07-31 14:55:54,310:INFO:Creating final display dataframe.
2023-07-31 14:55:57,341:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target             group
2                   Target type            Binary
3           Original data shape      (742, 11886)
4        Transformed data shape      (742, 11886)
5   Transformed train set shape      (667, 11886)
6    Transformed test set shape       (75, 11886)
7              Numeric features             11885
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9ea4
2023-07-31 14:55:57,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:57,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:57,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:57,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:55:57,491:INFO:setup() successfully completed in 9.5s...............
2023-07-31 14:55:57,497:INFO:Initializing compare_models()
2023-07-31 14:55:57,498:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 14:55:57,498:INFO:Checking exceptions
2023-07-31 14:55:57,587:INFO:Preparing display monitor
2023-07-31 14:55:57,609:INFO:Initializing Logistic Regression
2023-07-31 14:55:57,609:INFO:Total runtime is 3.0120213826497395e-06 minutes
2023-07-31 14:55:57,613:INFO:SubProcess create_model() called ==================================
2023-07-31 14:55:57,613:INFO:Initializing create_model()
2023-07-31 14:55:57,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:55:57,613:INFO:Checking exceptions
2023-07-31 14:55:57,613:INFO:Importing libraries
2023-07-31 14:55:57,614:INFO:Copying training dataset
2023-07-31 14:55:57,729:INFO:Defining folds
2023-07-31 14:55:57,729:INFO:Declaring metric variables
2023-07-31 14:55:57,733:INFO:Importing untrained model
2023-07-31 14:55:57,737:INFO:Logistic Regression Imported successfully
2023-07-31 14:55:57,743:INFO:Starting cross validation
2023-07-31 14:55:57,785:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:56:09,788:INFO:Calculating mean and std
2023-07-31 14:56:09,791:INFO:Creating metrics dataframe
2023-07-31 14:56:09,942:INFO:Uploading results into container
2023-07-31 14:56:09,943:INFO:Uploading model into container now
2023-07-31 14:56:09,943:INFO:_master_model_container: 1
2023-07-31 14:56:09,944:INFO:_display_container: 2
2023-07-31 14:56:09,944:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 14:56:09,944:INFO:create_model() successfully completed......................................
2023-07-31 14:56:10,104:INFO:SubProcess create_model() end ==================================
2023-07-31 14:56:10,104:INFO:Creating metrics dataframe
2023-07-31 14:56:10,115:INFO:Initializing K Neighbors Classifier
2023-07-31 14:56:10,115:INFO:Total runtime is 0.20842416683832804 minutes
2023-07-31 14:56:10,118:INFO:SubProcess create_model() called ==================================
2023-07-31 14:56:10,119:INFO:Initializing create_model()
2023-07-31 14:56:10,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:56:10,119:INFO:Checking exceptions
2023-07-31 14:56:10,119:INFO:Importing libraries
2023-07-31 14:56:10,119:INFO:Copying training dataset
2023-07-31 14:56:10,243:INFO:Defining folds
2023-07-31 14:56:10,243:INFO:Declaring metric variables
2023-07-31 14:56:10,248:INFO:Importing untrained model
2023-07-31 14:56:10,252:INFO:K Neighbors Classifier Imported successfully
2023-07-31 14:56:10,258:INFO:Starting cross validation
2023-07-31 14:56:10,301:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:56:13,603:INFO:Calculating mean and std
2023-07-31 14:56:13,607:INFO:Creating metrics dataframe
2023-07-31 14:56:14,012:INFO:Uploading results into container
2023-07-31 14:56:14,014:INFO:Uploading model into container now
2023-07-31 14:56:14,014:INFO:_master_model_container: 2
2023-07-31 14:56:14,014:INFO:_display_container: 2
2023-07-31 14:56:14,015:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 14:56:14,015:INFO:create_model() successfully completed......................................
2023-07-31 14:56:14,174:INFO:SubProcess create_model() end ==================================
2023-07-31 14:56:14,174:INFO:Creating metrics dataframe
2023-07-31 14:56:14,185:INFO:Initializing Naive Bayes
2023-07-31 14:56:14,185:INFO:Total runtime is 0.27626886367797854 minutes
2023-07-31 14:56:14,189:INFO:SubProcess create_model() called ==================================
2023-07-31 14:56:14,189:INFO:Initializing create_model()
2023-07-31 14:56:14,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:56:14,189:INFO:Checking exceptions
2023-07-31 14:56:14,189:INFO:Importing libraries
2023-07-31 14:56:14,190:INFO:Copying training dataset
2023-07-31 14:56:14,301:INFO:Defining folds
2023-07-31 14:56:14,301:INFO:Declaring metric variables
2023-07-31 14:56:14,305:INFO:Importing untrained model
2023-07-31 14:56:14,308:INFO:Naive Bayes Imported successfully
2023-07-31 14:56:14,315:INFO:Starting cross validation
2023-07-31 14:56:14,357:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:56:16,592:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:17,705:INFO:Calculating mean and std
2023-07-31 14:56:17,707:INFO:Creating metrics dataframe
2023-07-31 14:56:17,845:INFO:Uploading results into container
2023-07-31 14:56:17,846:INFO:Uploading model into container now
2023-07-31 14:56:17,847:INFO:_master_model_container: 3
2023-07-31 14:56:17,847:INFO:_display_container: 2
2023-07-31 14:56:17,847:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 14:56:17,847:INFO:create_model() successfully completed......................................
2023-07-31 14:56:17,984:INFO:SubProcess create_model() end ==================================
2023-07-31 14:56:17,985:INFO:Creating metrics dataframe
2023-07-31 14:56:17,996:INFO:Initializing Decision Tree Classifier
2023-07-31 14:56:17,996:INFO:Total runtime is 0.33978586594263716 minutes
2023-07-31 14:56:18,000:INFO:SubProcess create_model() called ==================================
2023-07-31 14:56:18,000:INFO:Initializing create_model()
2023-07-31 14:56:18,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:56:18,000:INFO:Checking exceptions
2023-07-31 14:56:18,000:INFO:Importing libraries
2023-07-31 14:56:18,000:INFO:Copying training dataset
2023-07-31 14:56:18,116:INFO:Defining folds
2023-07-31 14:56:18,117:INFO:Declaring metric variables
2023-07-31 14:56:18,121:INFO:Importing untrained model
2023-07-31 14:56:18,125:INFO:Decision Tree Classifier Imported successfully
2023-07-31 14:56:18,131:INFO:Starting cross validation
2023-07-31 14:56:18,173:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:56:22,908:INFO:Calculating mean and std
2023-07-31 14:56:22,911:INFO:Creating metrics dataframe
2023-07-31 14:56:23,327:INFO:Uploading results into container
2023-07-31 14:56:23,328:INFO:Uploading model into container now
2023-07-31 14:56:23,329:INFO:_master_model_container: 4
2023-07-31 14:56:23,329:INFO:_display_container: 2
2023-07-31 14:56:23,329:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2023-07-31 14:56:23,329:INFO:create_model() successfully completed......................................
2023-07-31 14:56:23,458:INFO:SubProcess create_model() end ==================================
2023-07-31 14:56:23,458:INFO:Creating metrics dataframe
2023-07-31 14:56:23,471:INFO:Initializing SVM - Linear Kernel
2023-07-31 14:56:23,471:INFO:Total runtime is 0.43103135426839195 minutes
2023-07-31 14:56:23,475:INFO:SubProcess create_model() called ==================================
2023-07-31 14:56:23,475:INFO:Initializing create_model()
2023-07-31 14:56:23,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:56:23,476:INFO:Checking exceptions
2023-07-31 14:56:23,476:INFO:Importing libraries
2023-07-31 14:56:23,476:INFO:Copying training dataset
2023-07-31 14:56:23,589:INFO:Defining folds
2023-07-31 14:56:23,589:INFO:Declaring metric variables
2023-07-31 14:56:23,594:INFO:Importing untrained model
2023-07-31 14:56:23,598:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 14:56:23,605:INFO:Starting cross validation
2023-07-31 14:56:23,648:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:56:26,243:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:56:26,276:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:56:26,297:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:56:26,303:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:56:26,319:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:56:26,336:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:56:26,477:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:56:26,480:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 14:56:27,073:INFO:Calculating mean and std
2023-07-31 14:56:27,076:INFO:Creating metrics dataframe
2023-07-31 14:56:27,487:INFO:Uploading results into container
2023-07-31 14:56:27,488:INFO:Uploading model into container now
2023-07-31 14:56:27,489:INFO:_master_model_container: 5
2023-07-31 14:56:27,489:INFO:_display_container: 2
2023-07-31 14:56:27,489:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 14:56:27,489:INFO:create_model() successfully completed......................................
2023-07-31 14:56:27,610:INFO:SubProcess create_model() end ==================================
2023-07-31 14:56:27,610:INFO:Creating metrics dataframe
2023-07-31 14:56:27,622:INFO:Initializing Ridge Classifier
2023-07-31 14:56:27,622:INFO:Total runtime is 0.5002129356066386 minutes
2023-07-31 14:56:27,626:INFO:SubProcess create_model() called ==================================
2023-07-31 14:56:27,626:INFO:Initializing create_model()
2023-07-31 14:56:27,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:56:27,626:INFO:Checking exceptions
2023-07-31 14:56:27,626:INFO:Importing libraries
2023-07-31 14:56:27,626:INFO:Copying training dataset
2023-07-31 14:56:27,737:INFO:Defining folds
2023-07-31 14:56:27,737:INFO:Declaring metric variables
2023-07-31 14:56:27,741:INFO:Importing untrained model
2023-07-31 14:56:27,744:INFO:Ridge Classifier Imported successfully
2023-07-31 14:56:27,751:INFO:Starting cross validation
2023-07-31 14:56:27,793:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:56:28,689:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.82598e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-07-31 14:56:28,691:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.77794e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-07-31 14:56:28,798:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=5.85249e-08): result may not be accurate.
  dual_coef = linalg.solve(K, y, assume_a="pos", overwrite_a=False)

2023-07-31 14:56:29,924:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:56:29,978:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:56:29,990:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:56:30,009:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:56:30,042:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:56:30,044:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:56:30,072:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:56:30,138:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 14:56:30,759:INFO:Calculating mean and std
2023-07-31 14:56:30,764:INFO:Creating metrics dataframe
2023-07-31 14:56:31,182:INFO:Uploading results into container
2023-07-31 14:56:31,183:INFO:Uploading model into container now
2023-07-31 14:56:31,184:INFO:_master_model_container: 6
2023-07-31 14:56:31,184:INFO:_display_container: 2
2023-07-31 14:56:31,184:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2023-07-31 14:56:31,185:INFO:create_model() successfully completed......................................
2023-07-31 14:56:31,363:INFO:SubProcess create_model() end ==================================
2023-07-31 14:56:31,363:INFO:Creating metrics dataframe
2023-07-31 14:56:31,376:INFO:Initializing Random Forest Classifier
2023-07-31 14:56:31,376:INFO:Total runtime is 0.5627812306086223 minutes
2023-07-31 14:56:31,380:INFO:SubProcess create_model() called ==================================
2023-07-31 14:56:31,380:INFO:Initializing create_model()
2023-07-31 14:56:31,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:56:31,380:INFO:Checking exceptions
2023-07-31 14:56:31,380:INFO:Importing libraries
2023-07-31 14:56:31,380:INFO:Copying training dataset
2023-07-31 14:56:31,497:INFO:Defining folds
2023-07-31 14:56:31,498:INFO:Declaring metric variables
2023-07-31 14:56:31,502:INFO:Importing untrained model
2023-07-31 14:56:31,505:INFO:Random Forest Classifier Imported successfully
2023-07-31 14:56:31,512:INFO:Starting cross validation
2023-07-31 14:56:31,554:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:56:34,325:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:34,357:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:34,428:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:34,445:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:34,484:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:34,488:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:34,519:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:34,530:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 14:56:35,841:INFO:Calculating mean and std
2023-07-31 14:56:35,843:INFO:Creating metrics dataframe
2023-07-31 14:56:36,000:INFO:Uploading results into container
2023-07-31 14:56:36,001:INFO:Uploading model into container now
2023-07-31 14:56:36,002:INFO:_master_model_container: 7
2023-07-31 14:56:36,002:INFO:_display_container: 2
2023-07-31 14:56:36,002:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2023-07-31 14:56:36,002:INFO:create_model() successfully completed......................................
2023-07-31 14:56:36,123:INFO:SubProcess create_model() end ==================================
2023-07-31 14:56:36,123:INFO:Creating metrics dataframe
2023-07-31 14:56:36,136:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 14:56:36,136:INFO:Total runtime is 0.6421137611071269 minutes
2023-07-31 14:56:36,139:INFO:SubProcess create_model() called ==================================
2023-07-31 14:56:36,140:INFO:Initializing create_model()
2023-07-31 14:56:36,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:56:36,140:INFO:Checking exceptions
2023-07-31 14:56:36,140:INFO:Importing libraries
2023-07-31 14:56:36,140:INFO:Copying training dataset
2023-07-31 14:56:36,251:INFO:Defining folds
2023-07-31 14:56:36,251:INFO:Declaring metric variables
2023-07-31 14:56:36,255:INFO:Importing untrained model
2023-07-31 14:56:36,259:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 14:56:36,265:INFO:Starting cross validation
2023-07-31 14:56:36,307:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:56:38,100:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:56:38,160:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:56:38,177:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:56:38,185:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:56:38,254:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:56:38,293:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:56:38,451:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:56:38,457:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 14:56:41,742:INFO:Calculating mean and std
2023-07-31 14:56:41,745:INFO:Creating metrics dataframe
2023-07-31 14:56:41,887:INFO:Uploading results into container
2023-07-31 14:56:41,888:INFO:Uploading model into container now
2023-07-31 14:56:41,889:INFO:_master_model_container: 8
2023-07-31 14:56:41,889:INFO:_display_container: 2
2023-07-31 14:56:41,889:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 14:56:41,889:INFO:create_model() successfully completed......................................
2023-07-31 14:56:42,011:INFO:SubProcess create_model() end ==================================
2023-07-31 14:56:42,012:INFO:Creating metrics dataframe
2023-07-31 14:56:42,025:INFO:Initializing Ada Boost Classifier
2023-07-31 14:56:42,025:INFO:Total runtime is 0.7402587731679281 minutes
2023-07-31 14:56:42,028:INFO:SubProcess create_model() called ==================================
2023-07-31 14:56:42,029:INFO:Initializing create_model()
2023-07-31 14:56:42,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:56:42,029:INFO:Checking exceptions
2023-07-31 14:56:42,029:INFO:Importing libraries
2023-07-31 14:56:42,029:INFO:Copying training dataset
2023-07-31 14:56:42,141:INFO:Defining folds
2023-07-31 14:56:42,141:INFO:Declaring metric variables
2023-07-31 14:56:42,145:INFO:Importing untrained model
2023-07-31 14:56:42,149:INFO:Ada Boost Classifier Imported successfully
2023-07-31 14:56:42,156:INFO:Starting cross validation
2023-07-31 14:56:42,197:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:57:23,255:INFO:Calculating mean and std
2023-07-31 14:57:23,259:INFO:Creating metrics dataframe
2023-07-31 14:57:23,696:INFO:Uploading results into container
2023-07-31 14:57:23,697:INFO:Uploading model into container now
2023-07-31 14:57:23,698:INFO:_master_model_container: 9
2023-07-31 14:57:23,698:INFO:_display_container: 2
2023-07-31 14:57:23,699:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=42)
2023-07-31 14:57:23,699:INFO:create_model() successfully completed......................................
2023-07-31 14:57:23,875:INFO:SubProcess create_model() end ==================================
2023-07-31 14:57:23,875:INFO:Creating metrics dataframe
2023-07-31 14:57:23,890:INFO:Initializing Gradient Boosting Classifier
2023-07-31 14:57:23,891:INFO:Total runtime is 1.4380204757054647 minutes
2023-07-31 14:57:23,894:INFO:SubProcess create_model() called ==================================
2023-07-31 14:57:23,895:INFO:Initializing create_model()
2023-07-31 14:57:23,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 14:57:23,895:INFO:Checking exceptions
2023-07-31 14:57:23,895:INFO:Importing libraries
2023-07-31 14:57:23,895:INFO:Copying training dataset
2023-07-31 14:57:24,020:INFO:Defining folds
2023-07-31 14:57:24,020:INFO:Declaring metric variables
2023-07-31 14:57:24,025:INFO:Importing untrained model
2023-07-31 14:57:24,029:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 14:57:24,036:INFO:Starting cross validation
2023-07-31 14:57:24,078:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 14:59:36,989:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-07-31 14:59:39,057:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:09,465:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:16,148:INFO:Calculating mean and std
2023-07-31 15:00:16,152:INFO:Creating metrics dataframe
2023-07-31 15:00:16,621:INFO:Uploading results into container
2023-07-31 15:00:16,623:INFO:Uploading model into container now
2023-07-31 15:00:16,624:INFO:_master_model_container: 10
2023-07-31 15:00:16,624:INFO:_display_container: 2
2023-07-31 15:00:16,625:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 15:00:16,625:INFO:create_model() successfully completed......................................
2023-07-31 15:00:16,954:INFO:SubProcess create_model() end ==================================
2023-07-31 15:00:16,955:INFO:Creating metrics dataframe
2023-07-31 15:00:16,974:INFO:Initializing Linear Discriminant Analysis
2023-07-31 15:00:16,975:INFO:Total runtime is 4.32275706132253 minutes
2023-07-31 15:00:16,981:INFO:SubProcess create_model() called ==================================
2023-07-31 15:00:16,982:INFO:Initializing create_model()
2023-07-31 15:00:16,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:00:16,982:INFO:Checking exceptions
2023-07-31 15:00:16,982:INFO:Importing libraries
2023-07-31 15:00:16,982:INFO:Copying training dataset
2023-07-31 15:00:17,181:INFO:Defining folds
2023-07-31 15:00:17,181:INFO:Declaring metric variables
2023-07-31 15:00:17,188:INFO:Importing untrained model
2023-07-31 15:00:17,194:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 15:00:17,205:INFO:Starting cross validation
2023-07-31 15:00:17,258:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:00:26,406:INFO:Calculating mean and std
2023-07-31 15:00:26,408:INFO:Creating metrics dataframe
2023-07-31 15:00:26,806:INFO:Uploading results into container
2023-07-31 15:00:26,807:INFO:Uploading model into container now
2023-07-31 15:00:26,808:INFO:_master_model_container: 11
2023-07-31 15:00:26,808:INFO:_display_container: 2
2023-07-31 15:00:26,808:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 15:00:26,808:INFO:create_model() successfully completed......................................
2023-07-31 15:00:26,931:INFO:SubProcess create_model() end ==================================
2023-07-31 15:00:26,931:INFO:Creating metrics dataframe
2023-07-31 15:00:26,944:INFO:Initializing Extra Trees Classifier
2023-07-31 15:00:26,944:INFO:Total runtime is 4.4889162977536525 minutes
2023-07-31 15:00:26,948:INFO:SubProcess create_model() called ==================================
2023-07-31 15:00:26,948:INFO:Initializing create_model()
2023-07-31 15:00:26,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:00:26,948:INFO:Checking exceptions
2023-07-31 15:00:26,948:INFO:Importing libraries
2023-07-31 15:00:26,948:INFO:Copying training dataset
2023-07-31 15:00:27,059:INFO:Defining folds
2023-07-31 15:00:27,059:INFO:Declaring metric variables
2023-07-31 15:00:27,063:INFO:Importing untrained model
2023-07-31 15:00:27,067:INFO:Extra Trees Classifier Imported successfully
2023-07-31 15:00:27,074:INFO:Starting cross validation
2023-07-31 15:00:27,114:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:00:29,553:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:29,588:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:29,623:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:29,627:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:29,628:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:29,634:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:29,653:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:29,669:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-31 15:00:31,029:INFO:Calculating mean and std
2023-07-31 15:00:31,031:INFO:Creating metrics dataframe
2023-07-31 15:00:31,140:INFO:Uploading results into container
2023-07-31 15:00:31,141:INFO:Uploading model into container now
2023-07-31 15:00:31,142:INFO:_master_model_container: 12
2023-07-31 15:00:31,142:INFO:_display_container: 2
2023-07-31 15:00:31,142:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2023-07-31 15:00:31,142:INFO:create_model() successfully completed......................................
2023-07-31 15:00:31,273:INFO:SubProcess create_model() end ==================================
2023-07-31 15:00:31,273:INFO:Creating metrics dataframe
2023-07-31 15:00:31,287:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 15:00:31,288:INFO:Total runtime is 4.5613053480784105 minutes
2023-07-31 15:00:31,291:INFO:SubProcess create_model() called ==================================
2023-07-31 15:00:31,291:INFO:Initializing create_model()
2023-07-31 15:00:31,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:00:31,292:INFO:Checking exceptions
2023-07-31 15:00:31,292:INFO:Importing libraries
2023-07-31 15:00:31,292:INFO:Copying training dataset
2023-07-31 15:00:31,403:INFO:Defining folds
2023-07-31 15:00:31,404:INFO:Declaring metric variables
2023-07-31 15:00:31,408:INFO:Importing untrained model
2023-07-31 15:00:31,411:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 15:00:31,418:INFO:Starting cross validation
2023-07-31 15:00:31,459:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:26,193:INFO:Calculating mean and std
2023-07-31 15:02:26,197:INFO:Creating metrics dataframe
2023-07-31 15:02:26,583:INFO:Uploading results into container
2023-07-31 15:02:26,584:INFO:Uploading model into container now
2023-07-31 15:02:26,585:INFO:_master_model_container: 13
2023-07-31 15:02:26,585:INFO:_display_container: 2
2023-07-31 15:02:26,585:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 15:02:26,585:INFO:create_model() successfully completed......................................
2023-07-31 15:02:26,745:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:26,745:INFO:Creating metrics dataframe
2023-07-31 15:02:26,759:INFO:Initializing Dummy Classifier
2023-07-31 15:02:26,759:INFO:Total runtime is 6.485833267370861 minutes
2023-07-31 15:02:26,763:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:26,763:INFO:Initializing create_model()
2023-07-31 15:02:26,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f968bd00>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:26,763:INFO:Checking exceptions
2023-07-31 15:02:26,763:INFO:Importing libraries
2023-07-31 15:02:26,763:INFO:Copying training dataset
2023-07-31 15:02:26,876:INFO:Defining folds
2023-07-31 15:02:26,876:INFO:Declaring metric variables
2023-07-31 15:02:26,880:INFO:Importing untrained model
2023-07-31 15:02:26,883:INFO:Dummy Classifier Imported successfully
2023-07-31 15:02:26,890:INFO:Starting cross validation
2023-07-31 15:02:26,931:INFO:Cross validating with KFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:29,141:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:29,728:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:29,861:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:29,909:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:30,433:INFO:Calculating mean and std
2023-07-31 15:02:30,438:INFO:Creating metrics dataframe
2023-07-31 15:02:30,542:INFO:Uploading results into container
2023-07-31 15:02:30,543:INFO:Uploading model into container now
2023-07-31 15:02:30,544:INFO:_master_model_container: 14
2023-07-31 15:02:30,544:INFO:_display_container: 2
2023-07-31 15:02:30,544:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2023-07-31 15:02:30,545:INFO:create_model() successfully completed......................................
2023-07-31 15:02:30,721:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:30,721:INFO:Creating metrics dataframe
2023-07-31 15:02:30,746:INFO:Initializing create_model()
2023-07-31 15:02:30,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f968baf0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:30,747:INFO:Checking exceptions
2023-07-31 15:02:30,748:INFO:Importing libraries
2023-07-31 15:02:30,748:INFO:Copying training dataset
2023-07-31 15:02:30,871:INFO:Defining folds
2023-07-31 15:02:30,871:INFO:Declaring metric variables
2023-07-31 15:02:30,871:INFO:Importing untrained model
2023-07-31 15:02:30,871:INFO:Declaring custom model
2023-07-31 15:02:30,872:INFO:Logistic Regression Imported successfully
2023-07-31 15:02:30,913:INFO:Cross validation set to False
2023-07-31 15:02:30,913:INFO:Fitting Model
2023-07-31 15:02:37,197:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 15:02:37,197:INFO:create_model() successfully completed......................................
2023-07-31 15:02:37,380:INFO:_master_model_container: 14
2023-07-31 15:02:37,380:INFO:_display_container: 2
2023-07-31 15:02:37,381:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 15:02:37,381:INFO:compare_models() successfully completed......................................
2023-07-31 15:02:37,471:INFO:Initializing set_config()
2023-07-31 15:02:37,472:INFO:set_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, variable=seed, value=42, kwargs={})
2023-07-31 15:02:37,472:INFO:Global variable: seed updated to 42
2023-07-31 15:02:37,472:INFO:set_config() successfully completed......................................
2023-07-31 15:02:37,571:INFO:PyCaret ClassificationExperiment
2023-07-31 15:02:37,571:INFO:Logging name: clf-default-name
2023-07-31 15:02:37,571:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 15:02:37,572:INFO:version 3.0.2
2023-07-31 15:02:37,572:INFO:Initializing setup()
2023-07-31 15:02:37,572:INFO:self.USI: 74ce
2023-07-31 15:02:37,572:INFO:self._variable_keys: {'n_jobs_param', 'html_param', 'pipeline', 'fold_groups_param', 'y_train', 'y', 'exp_id', '_available_plots', '_ml_usecase', 'exp_name_log', 'X', 'fix_imbalance', 'USI', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'X_test', 'memory', 'X_train', 'target_param', 'is_multiclass', 'gpu_param', 'logging_param', 'idx', 'log_plots_param', 'data'}
2023-07-31 15:02:37,572:INFO:Checking environment
2023-07-31 15:02:37,572:INFO:python_version: 3.9.16
2023-07-31 15:02:37,572:INFO:python_build: ('main', 'Mar  8 2023 14:00:05')
2023-07-31 15:02:37,572:INFO:machine: x86_64
2023-07-31 15:02:37,572:INFO:platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 15:02:37,572:INFO:Memory: svmem(total=67419119616, available=23249268736, percent=65.5, used=43253620736, free=15584223232, active=41675624448, inactive=7739666432, buffers=76406784, cached=8504868864, shared=223059968, slab=1439567872)
2023-07-31 15:02:37,574:INFO:Physical Core: 28
2023-07-31 15:02:37,574:INFO:Logical Core: 56
2023-07-31 15:02:37,574:INFO:Checking libraries
2023-07-31 15:02:37,574:INFO:System:
2023-07-31 15:02:37,574:INFO:    python: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
2023-07-31 15:02:37,574:INFO:executable: /home/wyl/miniconda3/envs/dl/bin/python
2023-07-31 15:02:37,574:INFO:   machine: Linux-5.4.0-153-generic-x86_64-with-glibc2.31
2023-07-31 15:02:37,574:INFO:PyCaret required dependencies:
2023-07-31 15:02:37,574:INFO:                 pip: 23.0.1
2023-07-31 15:02:37,574:INFO:          setuptools: 66.0.0
2023-07-31 15:02:37,574:INFO:             pycaret: 3.0.2
2023-07-31 15:02:37,574:INFO:             IPython: 8.13.2
2023-07-31 15:02:37,574:INFO:          ipywidgets: 8.0.6
2023-07-31 15:02:37,574:INFO:                tqdm: 4.65.0
2023-07-31 15:02:37,574:INFO:               numpy: 1.23.5
2023-07-31 15:02:37,574:INFO:              pandas: 1.5.3
2023-07-31 15:02:37,574:INFO:              jinja2: 3.1.2
2023-07-31 15:02:37,574:INFO:               scipy: 1.10.1
2023-07-31 15:02:37,574:INFO:              joblib: 1.2.0
2023-07-31 15:02:37,574:INFO:             sklearn: 1.2.2
2023-07-31 15:02:37,574:INFO:                pyod: 1.0.9
2023-07-31 15:02:37,574:INFO:            imblearn: 0.10.1
2023-07-31 15:02:37,574:INFO:   category_encoders: 2.6.1
2023-07-31 15:02:37,574:INFO:            lightgbm: 3.3.5
2023-07-31 15:02:37,574:INFO:               numba: 0.57.0
2023-07-31 15:02:37,574:INFO:            requests: 2.28.1
2023-07-31 15:02:37,574:INFO:          matplotlib: 3.7.1
2023-07-31 15:02:37,575:INFO:          scikitplot: 0.3.7
2023-07-31 15:02:37,575:INFO:         yellowbrick: 1.5
2023-07-31 15:02:37,575:INFO:              plotly: 5.14.1
2023-07-31 15:02:37,575:INFO:             kaleido: 0.2.1
2023-07-31 15:02:37,575:INFO:         statsmodels: 0.14.0
2023-07-31 15:02:37,575:INFO:              sktime: 0.17.0
2023-07-31 15:02:37,575:INFO:               tbats: 1.1.3
2023-07-31 15:02:37,575:INFO:            pmdarima: 2.0.3
2023-07-31 15:02:37,575:INFO:              psutil: 5.9.5
2023-07-31 15:02:37,575:INFO:PyCaret optional dependencies:
2023-07-31 15:02:37,575:INFO:                shap: Not installed
2023-07-31 15:02:37,575:INFO:           interpret: Not installed
2023-07-31 15:02:37,575:INFO:                umap: Not installed
2023-07-31 15:02:37,575:INFO:    pandas_profiling: Not installed
2023-07-31 15:02:37,575:INFO:  explainerdashboard: Not installed
2023-07-31 15:02:37,575:INFO:             autoviz: Not installed
2023-07-31 15:02:37,575:INFO:           fairlearn: Not installed
2023-07-31 15:02:37,575:INFO:             xgboost: Not installed
2023-07-31 15:02:37,575:INFO:            catboost: Not installed
2023-07-31 15:02:37,575:INFO:              kmodes: Not installed
2023-07-31 15:02:37,575:INFO:             mlxtend: Not installed
2023-07-31 15:02:37,575:INFO:       statsforecast: Not installed
2023-07-31 15:02:37,575:INFO:        tune_sklearn: Not installed
2023-07-31 15:02:37,575:INFO:                 ray: Not installed
2023-07-31 15:02:37,575:INFO:            hyperopt: Not installed
2023-07-31 15:02:37,575:INFO:              optuna: Not installed
2023-07-31 15:02:37,575:INFO:               skopt: Not installed
2023-07-31 15:02:37,575:INFO:              mlflow: Not installed
2023-07-31 15:02:37,575:INFO:              gradio: Not installed
2023-07-31 15:02:37,575:INFO:             fastapi: Not installed
2023-07-31 15:02:37,575:INFO:             uvicorn: Not installed
2023-07-31 15:02:37,575:INFO:              m2cgen: Not installed
2023-07-31 15:02:37,575:INFO:           evidently: Not installed
2023-07-31 15:02:37,576:INFO:               fugue: Not installed
2023-07-31 15:02:37,576:INFO:           streamlit: Not installed
2023-07-31 15:02:37,576:INFO:             prophet: Not installed
2023-07-31 15:02:37,576:INFO:None
2023-07-31 15:02:37,576:INFO:Set up data.
2023-07-31 15:02:37,659:INFO:Set up train/test split.
2023-07-31 15:02:37,667:INFO:Set up index.
2023-07-31 15:02:37,667:INFO:Set up folding strategy.
2023-07-31 15:02:37,667:INFO:Assigning column types.
2023-07-31 15:02:37,671:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 15:02:37,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 15:02:37,714:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 15:02:37,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:37,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:37,782:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 15:02:37,783:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 15:02:37,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:37,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:37,810:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 15:02:37,852:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 15:02:37,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:37,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:37,922:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 15:02:37,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:37,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:37,948:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 15:02:38,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:38,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:38,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:38,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:38,088:INFO:Preparing preprocessing pipeline...
2023-07-31 15:02:38,089:INFO:Set up simple imputation.
2023-07-31 15:02:38,119:INFO:Finished creating preprocessing pipeline.
2023-07-31 15:02:38,125:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-07-31 15:02:38,125:INFO:Creating final display dataframe.
2023-07-31 15:02:38,245:INFO:Setup _display_container:                     Description             Value
0                    Session id                44
1                        Target             group
2                   Target type            Binary
3           Original data shape        (742, 294)
4        Transformed data shape        (742, 294)
5   Transformed train set shape        (667, 294)
6    Transformed test set shape         (75, 294)
7              Numeric features               293
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                 8
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              74ce
2023-07-31 15:02:38,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:38,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:38,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:38,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:02:38,392:INFO:setup() successfully completed in 0.92s...............
2023-07-31 15:02:38,398:INFO:Initializing compare_models()
2023-07-31 15:02:38,398:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, include=None, fold=None, round=4, cross_validation=False, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': False, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 15:02:38,399:INFO:Checking exceptions
2023-07-31 15:02:38,403:INFO:Preparing display monitor
2023-07-31 15:02:38,428:INFO:Initializing Logistic Regression
2023-07-31 15:02:38,428:INFO:Total runtime is 2.9802322387695312e-06 minutes
2023-07-31 15:02:38,431:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:38,432:INFO:Initializing create_model()
2023-07-31 15:02:38,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:38,432:INFO:Checking exceptions
2023-07-31 15:02:38,432:INFO:Importing libraries
2023-07-31 15:02:38,432:INFO:Copying training dataset
2023-07-31 15:02:38,438:INFO:Defining folds
2023-07-31 15:02:38,438:INFO:Declaring metric variables
2023-07-31 15:02:38,441:INFO:Importing untrained model
2023-07-31 15:02:38,445:INFO:Logistic Regression Imported successfully
2023-07-31 15:02:38,450:INFO:Cross validation set to False
2023-07-31 15:02:38,450:INFO:Fitting Model
2023-07-31 15:02:38,594:INFO:Initializing predict_model()
2023-07-31 15:02:38,594:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=44,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fa7938b0>)
2023-07-31 15:02:38,594:INFO:Checking exceptions
2023-07-31 15:02:38,594:INFO:Preloading libraries
2023-07-31 15:02:38,864:INFO:_display_container: 2
2023-07-31 15:02:38,961:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 15:02:38,961:INFO:create_model() successfully completed......................................
2023-07-31 15:02:39,087:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:39,087:INFO:Creating metrics dataframe
2023-07-31 15:02:39,097:INFO:Initializing K Neighbors Classifier
2023-07-31 15:02:39,097:INFO:Total runtime is 0.011152148246765137 minutes
2023-07-31 15:02:39,100:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:39,101:INFO:Initializing create_model()
2023-07-31 15:02:39,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:39,101:INFO:Checking exceptions
2023-07-31 15:02:39,101:INFO:Importing libraries
2023-07-31 15:02:39,101:INFO:Copying training dataset
2023-07-31 15:02:39,106:INFO:Defining folds
2023-07-31 15:02:39,106:INFO:Declaring metric variables
2023-07-31 15:02:39,109:INFO:Importing untrained model
2023-07-31 15:02:39,112:INFO:K Neighbors Classifier Imported successfully
2023-07-31 15:02:39,117:INFO:Cross validation set to False
2023-07-31 15:02:39,117:INFO:Fitting Model
2023-07-31 15:02:39,158:INFO:Initializing predict_model()
2023-07-31 15:02:39,158:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b157a430>)
2023-07-31 15:02:39,158:INFO:Checking exceptions
2023-07-31 15:02:39,158:INFO:Preloading libraries
2023-07-31 15:02:39,533:INFO:_display_container: 2
2023-07-31 15:02:39,634:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 15:02:39,634:INFO:create_model() successfully completed......................................
2023-07-31 15:02:39,759:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:39,759:INFO:Creating metrics dataframe
2023-07-31 15:02:39,771:INFO:Initializing Naive Bayes
2023-07-31 15:02:39,771:INFO:Total runtime is 0.022388219833374023 minutes
2023-07-31 15:02:39,774:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:39,775:INFO:Initializing create_model()
2023-07-31 15:02:39,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:39,775:INFO:Checking exceptions
2023-07-31 15:02:39,775:INFO:Importing libraries
2023-07-31 15:02:39,775:INFO:Copying training dataset
2023-07-31 15:02:39,782:INFO:Defining folds
2023-07-31 15:02:39,782:INFO:Declaring metric variables
2023-07-31 15:02:39,786:INFO:Importing untrained model
2023-07-31 15:02:39,789:INFO:Naive Bayes Imported successfully
2023-07-31 15:02:39,794:INFO:Cross validation set to False
2023-07-31 15:02:39,794:INFO:Fitting Model
2023-07-31 15:02:39,838:INFO:Initializing predict_model()
2023-07-31 15:02:39,838:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b17560d0>)
2023-07-31 15:02:39,838:INFO:Checking exceptions
2023-07-31 15:02:39,838:INFO:Preloading libraries
2023-07-31 15:02:40,061:INFO:_display_container: 2
2023-07-31 15:02:40,163:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 15:02:40,163:INFO:create_model() successfully completed......................................
2023-07-31 15:02:40,291:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:40,291:INFO:Creating metrics dataframe
2023-07-31 15:02:40,303:INFO:Initializing Decision Tree Classifier
2023-07-31 15:02:40,303:INFO:Total runtime is 0.031249419848124186 minutes
2023-07-31 15:02:40,306:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:40,306:INFO:Initializing create_model()
2023-07-31 15:02:40,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:40,307:INFO:Checking exceptions
2023-07-31 15:02:40,307:INFO:Importing libraries
2023-07-31 15:02:40,307:INFO:Copying training dataset
2023-07-31 15:02:40,313:INFO:Defining folds
2023-07-31 15:02:40,313:INFO:Declaring metric variables
2023-07-31 15:02:40,317:INFO:Importing untrained model
2023-07-31 15:02:40,320:INFO:Decision Tree Classifier Imported successfully
2023-07-31 15:02:40,325:INFO:Cross validation set to False
2023-07-31 15:02:40,325:INFO:Fitting Model
2023-07-31 15:02:40,404:INFO:Initializing predict_model()
2023-07-31 15:02:40,405:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=44, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f90b80d0>)
2023-07-31 15:02:40,405:INFO:Checking exceptions
2023-07-31 15:02:40,405:INFO:Preloading libraries
2023-07-31 15:02:40,622:INFO:_display_container: 2
2023-07-31 15:02:40,723:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=44, splitter='best')
2023-07-31 15:02:40,723:INFO:create_model() successfully completed......................................
2023-07-31 15:02:40,847:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:40,847:INFO:Creating metrics dataframe
2023-07-31 15:02:40,859:INFO:Initializing SVM - Linear Kernel
2023-07-31 15:02:40,859:INFO:Total runtime is 0.0405232032140096 minutes
2023-07-31 15:02:40,863:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:40,863:INFO:Initializing create_model()
2023-07-31 15:02:40,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:40,863:INFO:Checking exceptions
2023-07-31 15:02:40,863:INFO:Importing libraries
2023-07-31 15:02:40,863:INFO:Copying training dataset
2023-07-31 15:02:40,870:INFO:Defining folds
2023-07-31 15:02:40,870:INFO:Declaring metric variables
2023-07-31 15:02:40,874:INFO:Importing untrained model
2023-07-31 15:02:40,877:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 15:02:40,882:INFO:Cross validation set to False
2023-07-31 15:02:40,882:INFO:Fitting Model
2023-07-31 15:02:40,942:INFO:Initializing predict_model()
2023-07-31 15:02:40,942:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('actual_estimator',
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=44,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f90b80d0>)
2023-07-31 15:02:40,942:INFO:Checking exceptions
2023-07-31 15:02:40,942:INFO:Preloading libraries
2023-07-31 15:02:41,199:INFO:_display_container: 2
2023-07-31 15:02:41,297:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=44, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 15:02:41,297:INFO:create_model() successfully completed......................................
2023-07-31 15:02:41,418:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:41,419:INFO:Creating metrics dataframe
2023-07-31 15:02:41,431:INFO:Initializing Ridge Classifier
2023-07-31 15:02:41,431:INFO:Total runtime is 0.0500577171643575 minutes
2023-07-31 15:02:41,434:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:41,435:INFO:Initializing create_model()
2023-07-31 15:02:41,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:41,435:INFO:Checking exceptions
2023-07-31 15:02:41,435:INFO:Importing libraries
2023-07-31 15:02:41,435:INFO:Copying training dataset
2023-07-31 15:02:41,441:INFO:Defining folds
2023-07-31 15:02:41,441:INFO:Declaring metric variables
2023-07-31 15:02:41,445:INFO:Importing untrained model
2023-07-31 15:02:41,448:INFO:Ridge Classifier Imported successfully
2023-07-31 15:02:41,453:INFO:Cross validation set to False
2023-07-31 15:02:41,453:INFO:Fitting Model
2023-07-31 15:02:41,577:INFO:Initializing predict_model()
2023-07-31 15:02:41,577:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=44, solver='auto',
                                 tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0af87a700>)
2023-07-31 15:02:41,577:INFO:Checking exceptions
2023-07-31 15:02:41,577:INFO:Preloading libraries
2023-07-31 15:02:41,890:INFO:_display_container: 2
2023-07-31 15:02:41,994:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=44, solver='auto',
                tol=0.0001)
2023-07-31 15:02:41,994:INFO:create_model() successfully completed......................................
2023-07-31 15:02:42,127:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:42,127:INFO:Creating metrics dataframe
2023-07-31 15:02:42,139:INFO:Initializing Random Forest Classifier
2023-07-31 15:02:42,139:INFO:Total runtime is 0.061858824888865155 minutes
2023-07-31 15:02:42,143:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:42,143:INFO:Initializing create_model()
2023-07-31 15:02:42,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:42,143:INFO:Checking exceptions
2023-07-31 15:02:42,143:INFO:Importing libraries
2023-07-31 15:02:42,143:INFO:Copying training dataset
2023-07-31 15:02:42,149:INFO:Defining folds
2023-07-31 15:02:42,149:INFO:Declaring metric variables
2023-07-31 15:02:42,153:INFO:Importing untrained model
2023-07-31 15:02:42,156:INFO:Random Forest Classifier Imported successfully
2023-07-31 15:02:42,161:INFO:Cross validation set to False
2023-07-31 15:02:42,161:INFO:Fitting Model
2023-07-31 15:02:42,843:INFO:Initializing predict_model()
2023-07-31 15:02:42,843:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=44,
                                        verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b18bbaf0>)
2023-07-31 15:02:42,843:INFO:Checking exceptions
2023-07-31 15:02:42,843:INFO:Preloading libraries
2023-07-31 15:02:43,164:INFO:_display_container: 2
2023-07-31 15:02:43,263:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=44, verbose=0, warm_start=False)
2023-07-31 15:02:43,263:INFO:create_model() successfully completed......................................
2023-07-31 15:02:43,386:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:43,386:INFO:Creating metrics dataframe
2023-07-31 15:02:43,399:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 15:02:43,399:INFO:Total runtime is 0.08285358746846518 minutes
2023-07-31 15:02:43,402:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:43,403:INFO:Initializing create_model()
2023-07-31 15:02:43,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:43,403:INFO:Checking exceptions
2023-07-31 15:02:43,403:INFO:Importing libraries
2023-07-31 15:02:43,403:INFO:Copying training dataset
2023-07-31 15:02:43,409:INFO:Defining folds
2023-07-31 15:02:43,409:INFO:Declaring metric variables
2023-07-31 15:02:43,413:INFO:Importing untrained model
2023-07-31 15:02:43,416:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 15:02:43,421:INFO:Cross validation set to False
2023-07-31 15:02:43,421:INFO:Fitting Model
2023-07-31 15:02:43,533:WARNING:/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:43,777:INFO:Initializing predict_model()
2023-07-31 15:02:43,777:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0bc15ad30>)
2023-07-31 15:02:43,778:INFO:Checking exceptions
2023-07-31 15:02:43,778:INFO:Preloading libraries
2023-07-31 15:02:44,047:INFO:_display_container: 2
2023-07-31 15:02:44,144:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 15:02:44,144:INFO:create_model() successfully completed......................................
2023-07-31 15:02:44,267:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:44,267:INFO:Creating metrics dataframe
2023-07-31 15:02:44,281:INFO:Initializing Ada Boost Classifier
2023-07-31 15:02:44,281:INFO:Total runtime is 0.09755013386408488 minutes
2023-07-31 15:02:44,284:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:44,285:INFO:Initializing create_model()
2023-07-31 15:02:44,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:44,285:INFO:Checking exceptions
2023-07-31 15:02:44,285:INFO:Importing libraries
2023-07-31 15:02:44,285:INFO:Copying training dataset
2023-07-31 15:02:44,291:INFO:Defining folds
2023-07-31 15:02:44,291:INFO:Declaring metric variables
2023-07-31 15:02:44,295:INFO:Importing untrained model
2023-07-31 15:02:44,299:INFO:Ada Boost Classifier Imported successfully
2023-07-31 15:02:44,304:INFO:Cross validation set to False
2023-07-31 15:02:44,304:INFO:Fitting Model
2023-07-31 15:02:45,547:INFO:Initializing predict_model()
2023-07-31 15:02:45,547:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=44))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f90b8160>)
2023-07-31 15:02:45,547:INFO:Checking exceptions
2023-07-31 15:02:45,547:INFO:Preloading libraries
2023-07-31 15:02:45,771:INFO:_display_container: 2
2023-07-31 15:02:45,871:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=44)
2023-07-31 15:02:45,871:INFO:create_model() successfully completed......................................
2023-07-31 15:02:45,993:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:45,994:INFO:Creating metrics dataframe
2023-07-31 15:02:46,007:INFO:Initializing Gradient Boosting Classifier
2023-07-31 15:02:46,007:INFO:Total runtime is 0.12632491985956829 minutes
2023-07-31 15:02:46,011:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:46,011:INFO:Initializing create_model()
2023-07-31 15:02:46,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:46,011:INFO:Checking exceptions
2023-07-31 15:02:46,012:INFO:Importing libraries
2023-07-31 15:02:46,012:INFO:Copying training dataset
2023-07-31 15:02:46,017:INFO:Defining folds
2023-07-31 15:02:46,018:INFO:Declaring metric variables
2023-07-31 15:02:46,022:INFO:Importing untrained model
2023-07-31 15:02:46,026:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 15:02:46,031:INFO:Cross validation set to False
2023-07-31 15:02:46,031:INFO:Fitting Model
2023-07-31 15:02:49,698:INFO:Initializing predict_model()
2023-07-31 15:02:49,698:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=44, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b19b61f0>)
2023-07-31 15:02:49,698:INFO:Checking exceptions
2023-07-31 15:02:49,698:INFO:Preloading libraries
2023-07-31 15:02:49,904:INFO:_display_container: 2
2023-07-31 15:02:50,004:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=44, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 15:02:50,004:INFO:create_model() successfully completed......................................
2023-07-31 15:02:50,125:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:50,125:INFO:Creating metrics dataframe
2023-07-31 15:02:50,139:INFO:Initializing Linear Discriminant Analysis
2023-07-31 15:02:50,139:INFO:Total runtime is 0.1951925794283549 minutes
2023-07-31 15:02:50,143:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:50,143:INFO:Initializing create_model()
2023-07-31 15:02:50,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:50,143:INFO:Checking exceptions
2023-07-31 15:02:50,143:INFO:Importing libraries
2023-07-31 15:02:50,143:INFO:Copying training dataset
2023-07-31 15:02:50,149:INFO:Defining folds
2023-07-31 15:02:50,149:INFO:Declaring metric variables
2023-07-31 15:02:50,153:INFO:Importing untrained model
2023-07-31 15:02:50,157:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 15:02:50,162:INFO:Cross validation set to False
2023-07-31 15:02:50,162:INFO:Fitting Model
2023-07-31 15:02:50,486:INFO:Initializing predict_model()
2023-07-31 15:02:50,486:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b18bb3a0>)
2023-07-31 15:02:50,486:INFO:Checking exceptions
2023-07-31 15:02:50,486:INFO:Preloading libraries
2023-07-31 15:02:50,691:INFO:_display_container: 2
2023-07-31 15:02:50,789:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 15:02:50,789:INFO:create_model() successfully completed......................................
2023-07-31 15:02:50,913:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:50,913:INFO:Creating metrics dataframe
2023-07-31 15:02:50,927:INFO:Initializing Extra Trees Classifier
2023-07-31 15:02:50,927:INFO:Total runtime is 0.20832653840382895 minutes
2023-07-31 15:02:50,931:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:50,931:INFO:Initializing create_model()
2023-07-31 15:02:50,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:50,932:INFO:Checking exceptions
2023-07-31 15:02:50,932:INFO:Importing libraries
2023-07-31 15:02:50,932:INFO:Copying training dataset
2023-07-31 15:02:50,938:INFO:Defining folds
2023-07-31 15:02:50,938:INFO:Declaring metric variables
2023-07-31 15:02:50,942:INFO:Importing untrained model
2023-07-31 15:02:50,946:INFO:Extra Trees Classifier Imported successfully
2023-07-31 15:02:50,951:INFO:Cross validation set to False
2023-07-31 15:02:50,951:INFO:Fitting Model
2023-07-31 15:02:51,485:INFO:Initializing predict_model()
2023-07-31 15:02:51,485:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=44,
                                      verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0bc15a820>)
2023-07-31 15:02:51,485:INFO:Checking exceptions
2023-07-31 15:02:51,485:INFO:Preloading libraries
2023-07-31 15:02:51,814:INFO:_display_container: 2
2023-07-31 15:02:51,922:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=44, verbose=0, warm_start=False)
2023-07-31 15:02:51,923:INFO:create_model() successfully completed......................................
2023-07-31 15:02:52,044:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:52,044:INFO:Creating metrics dataframe
2023-07-31 15:02:52,059:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 15:02:52,059:INFO:Total runtime is 0.22719124158223472 minutes
2023-07-31 15:02:52,063:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:52,063:INFO:Initializing create_model()
2023-07-31 15:02:52,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:52,063:INFO:Checking exceptions
2023-07-31 15:02:52,063:INFO:Importing libraries
2023-07-31 15:02:52,064:INFO:Copying training dataset
2023-07-31 15:02:52,070:INFO:Defining folds
2023-07-31 15:02:52,070:INFO:Declaring metric variables
2023-07-31 15:02:52,074:INFO:Importing untrained model
2023-07-31 15:02:52,078:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 15:02:52,083:INFO:Cross validation set to False
2023-07-31 15:02:52,083:INFO:Fitting Model
2023-07-31 15:03:38,545:INFO:Initializing predict_model()
2023-07-31 15:03:38,545:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=44,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0af87ac10>)
2023-07-31 15:03:38,545:INFO:Checking exceptions
2023-07-31 15:03:38,545:INFO:Preloading libraries
2023-07-31 15:03:38,830:INFO:_display_container: 2
2023-07-31 15:03:38,930:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=44, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 15:03:38,930:INFO:create_model() successfully completed......................................
2023-07-31 15:03:39,054:INFO:SubProcess create_model() end ==================================
2023-07-31 15:03:39,055:INFO:Creating metrics dataframe
2023-07-31 15:03:39,069:INFO:Initializing Dummy Classifier
2023-07-31 15:03:39,069:INFO:Total runtime is 1.0106940348943074 minutes
2023-07-31 15:03:39,076:INFO:SubProcess create_model() called ==================================
2023-07-31 15:03:39,076:INFO:Initializing create_model()
2023-07-31 15:03:39,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f973f400>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:03:39,076:INFO:Checking exceptions
2023-07-31 15:03:39,076:INFO:Importing libraries
2023-07-31 15:03:39,077:INFO:Copying training dataset
2023-07-31 15:03:39,084:INFO:Defining folds
2023-07-31 15:03:39,084:INFO:Declaring metric variables
2023-07-31 15:03:39,087:INFO:Importing untrained model
2023-07-31 15:03:39,091:INFO:Dummy Classifier Imported successfully
2023-07-31 15:03:39,096:INFO:Cross validation set to False
2023-07-31 15:03:39,096:INFO:Fitting Model
2023-07-31 15:03:39,136:INFO:Initializing predict_model()
2023-07-31 15:03:39,137:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DummyClassifier(constant=None, random_state=44,
                                 strategy='prior'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0bc15a940>)
2023-07-31 15:03:39,137:INFO:Checking exceptions
2023-07-31 15:03:39,137:INFO:Preloading libraries
2023-07-31 15:03:39,356:INFO:_display_container: 2
2023-07-31 15:03:39,460:INFO:DummyClassifier(constant=None, random_state=44, strategy='prior')
2023-07-31 15:03:39,460:INFO:create_model() successfully completed......................................
2023-07-31 15:03:39,591:INFO:SubProcess create_model() end ==================================
2023-07-31 15:03:39,591:INFO:Creating metrics dataframe
2023-07-31 15:03:39,620:INFO:Initializing create_model()
2023-07-31 15:03:39,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:03:39,620:INFO:Checking exceptions
2023-07-31 15:03:39,622:INFO:Importing libraries
2023-07-31 15:03:39,622:INFO:Copying training dataset
2023-07-31 15:03:39,628:INFO:Defining folds
2023-07-31 15:03:39,628:INFO:Declaring metric variables
2023-07-31 15:03:39,628:INFO:Importing untrained model
2023-07-31 15:03:39,629:INFO:Declaring custom model
2023-07-31 15:03:39,629:INFO:Logistic Regression Imported successfully
2023-07-31 15:03:39,630:INFO:Cross validation set to False
2023-07-31 15:03:39,631:INFO:Fitting Model
2023-07-31 15:03:40,190:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 15:03:40,190:INFO:create_model() successfully completed......................................
2023-07-31 15:03:40,343:INFO:_master_model_container: 0
2023-07-31 15:03:40,344:INFO:_display_container: 2
2023-07-31 15:03:40,344:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 15:03:40,344:INFO:compare_models() successfully completed......................................
2023-07-31 16:34:53,326:INFO:Initializing compare_models()
2023-07-31 16:34:53,326:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, include=None, fold=None, round=4, cross_validation=False, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': False, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 16:34:53,326:INFO:Checking exceptions
2023-07-31 16:34:53,332:INFO:Preparing display monitor
2023-07-31 16:34:53,360:INFO:Initializing Logistic Regression
2023-07-31 16:34:53,360:INFO:Total runtime is 3.266334533691406e-06 minutes
2023-07-31 16:34:53,364:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:53,365:INFO:Initializing create_model()
2023-07-31 16:34:53,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=lr, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:53,365:INFO:Checking exceptions
2023-07-31 16:34:53,365:INFO:Importing libraries
2023-07-31 16:34:53,365:INFO:Copying training dataset
2023-07-31 16:34:53,372:INFO:Defining folds
2023-07-31 16:34:53,372:INFO:Declaring metric variables
2023-07-31 16:34:53,376:INFO:Importing untrained model
2023-07-31 16:34:53,380:INFO:Logistic Regression Imported successfully
2023-07-31 16:34:53,386:INFO:Cross validation set to False
2023-07-31 16:34:53,386:INFO:Fitting Model
2023-07-31 16:34:53,438:INFO:Initializing predict_model()
2023-07-31 16:34:53,438:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=44,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0faab6430>)
2023-07-31 16:34:53,438:INFO:Checking exceptions
2023-07-31 16:34:53,438:INFO:Preloading libraries
2023-07-31 16:34:53,693:INFO:_display_container: 3
2023-07-31 16:34:53,786:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 16:34:53,786:INFO:create_model() successfully completed......................................
2023-07-31 16:34:53,900:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:53,900:INFO:Creating metrics dataframe
2023-07-31 16:34:53,909:INFO:Initializing K Neighbors Classifier
2023-07-31 16:34:53,909:INFO:Total runtime is 0.009152897198994954 minutes
2023-07-31 16:34:53,913:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:53,913:INFO:Initializing create_model()
2023-07-31 16:34:53,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=knn, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:53,913:INFO:Checking exceptions
2023-07-31 16:34:53,913:INFO:Importing libraries
2023-07-31 16:34:53,913:INFO:Copying training dataset
2023-07-31 16:34:53,919:INFO:Defining folds
2023-07-31 16:34:53,919:INFO:Declaring metric variables
2023-07-31 16:34:53,922:INFO:Importing untrained model
2023-07-31 16:34:53,925:INFO:K Neighbors Classifier Imported successfully
2023-07-31 16:34:53,930:INFO:Cross validation set to False
2023-07-31 16:34:53,930:INFO:Fitting Model
2023-07-31 16:34:53,969:INFO:Initializing predict_model()
2023-07-31 16:34:53,969:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 KNeighborsClassifier(algorithm='auto', leaf_size=30,
                                      metric='minkowski', metric_params=None,
                                      n_jobs=-1, n_neighbors=5, p=2,
                                      weights='uniform'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f95b7a60>)
2023-07-31 16:34:53,969:INFO:Checking exceptions
2023-07-31 16:34:53,969:INFO:Preloading libraries
2023-07-31 16:34:54,296:INFO:_display_container: 3
2023-07-31 16:34:54,391:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 16:34:54,391:INFO:create_model() successfully completed......................................
2023-07-31 16:34:54,511:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:54,511:INFO:Creating metrics dataframe
2023-07-31 16:34:54,522:INFO:Initializing Naive Bayes
2023-07-31 16:34:54,523:INFO:Total runtime is 0.019374171892801918 minutes
2023-07-31 16:34:54,526:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:54,526:INFO:Initializing create_model()
2023-07-31 16:34:54,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=nb, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:54,527:INFO:Checking exceptions
2023-07-31 16:34:54,527:INFO:Importing libraries
2023-07-31 16:34:54,527:INFO:Copying training dataset
2023-07-31 16:34:54,532:INFO:Defining folds
2023-07-31 16:34:54,533:INFO:Declaring metric variables
2023-07-31 16:34:54,536:INFO:Importing untrained model
2023-07-31 16:34:54,539:INFO:Naive Bayes Imported successfully
2023-07-31 16:34:54,544:INFO:Cross validation set to False
2023-07-31 16:34:54,544:INFO:Fitting Model
2023-07-31 16:34:54,585:INFO:Initializing predict_model()
2023-07-31 16:34:54,585:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 GaussianNB(priors=None, var_smoothing=1e-09))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b1b55f70>)
2023-07-31 16:34:54,585:INFO:Checking exceptions
2023-07-31 16:34:54,585:INFO:Preloading libraries
2023-07-31 16:34:54,777:INFO:_display_container: 3
2023-07-31 16:34:54,872:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 16:34:54,872:INFO:create_model() successfully completed......................................
2023-07-31 16:34:54,991:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:54,991:INFO:Creating metrics dataframe
2023-07-31 16:34:55,002:INFO:Initializing Decision Tree Classifier
2023-07-31 16:34:55,002:INFO:Total runtime is 0.027362966537475584 minutes
2023-07-31 16:34:55,005:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:55,006:INFO:Initializing create_model()
2023-07-31 16:34:55,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=dt, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:55,006:INFO:Checking exceptions
2023-07-31 16:34:55,006:INFO:Importing libraries
2023-07-31 16:34:55,006:INFO:Copying training dataset
2023-07-31 16:34:55,013:INFO:Defining folds
2023-07-31 16:34:55,013:INFO:Declaring metric variables
2023-07-31 16:34:55,016:INFO:Importing untrained model
2023-07-31 16:34:55,019:INFO:Decision Tree Classifier Imported successfully
2023-07-31 16:34:55,024:INFO:Cross validation set to False
2023-07-31 16:34:55,024:INFO:Fitting Model
2023-07-31 16:34:55,096:INFO:Initializing predict_model()
2023-07-31 16:34:55,096:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=44, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f95b7a60>)
2023-07-31 16:34:55,096:INFO:Checking exceptions
2023-07-31 16:34:55,096:INFO:Preloading libraries
2023-07-31 16:34:55,311:INFO:_display_container: 3
2023-07-31 16:34:55,407:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=44, splitter='best')
2023-07-31 16:34:55,407:INFO:create_model() successfully completed......................................
2023-07-31 16:34:55,553:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:55,553:INFO:Creating metrics dataframe
2023-07-31 16:34:55,564:INFO:Initializing SVM - Linear Kernel
2023-07-31 16:34:55,565:INFO:Total runtime is 0.03673993746439616 minutes
2023-07-31 16:34:55,568:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:55,568:INFO:Initializing create_model()
2023-07-31 16:34:55,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=svm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:55,568:INFO:Checking exceptions
2023-07-31 16:34:55,568:INFO:Importing libraries
2023-07-31 16:34:55,569:INFO:Copying training dataset
2023-07-31 16:34:55,575:INFO:Defining folds
2023-07-31 16:34:55,575:INFO:Declaring metric variables
2023-07-31 16:34:55,579:INFO:Importing untrained model
2023-07-31 16:34:55,582:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 16:34:55,587:INFO:Cross validation set to False
2023-07-31 16:34:55,587:INFO:Fitting Model
2023-07-31 16:34:55,642:INFO:Initializing predict_model()
2023-07-31 16:34:55,642:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('actual_estimator',
                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,
                               early_stopping=False, epsilon=0.1, eta0=0.001,
                               fit_intercept=True, l1_ratio=0.15,
                               learning_rate='optimal', loss='hinge',
                               max_iter=1000, n_iter_no_change=5, n_jobs=-1,
                               penalty='l2', power_t=0.5, random_state=44,
                               shuffle=True, tol=0.001, validation_fraction=0.1,
                               verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0b1b55f70>)
2023-07-31 16:34:55,642:INFO:Checking exceptions
2023-07-31 16:34:55,642:INFO:Preloading libraries
2023-07-31 16:34:55,855:INFO:_display_container: 3
2023-07-31 16:34:55,954:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=44, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 16:34:55,954:INFO:create_model() successfully completed......................................
2023-07-31 16:34:56,082:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:56,082:INFO:Creating metrics dataframe
2023-07-31 16:34:56,094:INFO:Initializing Ridge Classifier
2023-07-31 16:34:56,094:INFO:Total runtime is 0.04556717872619629 minutes
2023-07-31 16:34:56,098:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:56,098:INFO:Initializing create_model()
2023-07-31 16:34:56,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=ridge, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:56,098:INFO:Checking exceptions
2023-07-31 16:34:56,098:INFO:Importing libraries
2023-07-31 16:34:56,098:INFO:Copying training dataset
2023-07-31 16:34:56,104:INFO:Defining folds
2023-07-31 16:34:56,104:INFO:Declaring metric variables
2023-07-31 16:34:56,108:INFO:Importing untrained model
2023-07-31 16:34:56,111:INFO:Ridge Classifier Imported successfully
2023-07-31 16:34:56,115:INFO:Cross validation set to False
2023-07-31 16:34:56,116:INFO:Fitting Model
2023-07-31 16:34:56,213:INFO:Initializing predict_model()
2023-07-31 16:34:56,213:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=44, solver='auto',
                                 tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f95b7a60>)
2023-07-31 16:34:56,213:INFO:Checking exceptions
2023-07-31 16:34:56,214:INFO:Preloading libraries
2023-07-31 16:34:56,457:INFO:_display_container: 3
2023-07-31 16:34:56,553:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=44, solver='auto',
                tol=0.0001)
2023-07-31 16:34:56,553:INFO:create_model() successfully completed......................................
2023-07-31 16:34:56,671:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:56,671:INFO:Creating metrics dataframe
2023-07-31 16:34:56,683:INFO:Initializing Random Forest Classifier
2023-07-31 16:34:56,683:INFO:Total runtime is 0.055387580394744874 minutes
2023-07-31 16:34:56,687:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:56,687:INFO:Initializing create_model()
2023-07-31 16:34:56,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=rf, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:56,687:INFO:Checking exceptions
2023-07-31 16:34:56,687:INFO:Importing libraries
2023-07-31 16:34:56,687:INFO:Copying training dataset
2023-07-31 16:34:56,693:INFO:Defining folds
2023-07-31 16:34:56,693:INFO:Declaring metric variables
2023-07-31 16:34:56,696:INFO:Importing untrained model
2023-07-31 16:34:56,700:INFO:Random Forest Classifier Imported successfully
2023-07-31 16:34:56,704:INFO:Cross validation set to False
2023-07-31 16:34:56,704:INFO:Fitting Model
2023-07-31 16:34:56,770:INFO:Initializing predict_model()
2023-07-31 16:34:56,770:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=44,
                                        verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd1378f70>)
2023-07-31 16:34:56,770:INFO:Checking exceptions
2023-07-31 16:34:56,770:INFO:Preloading libraries
2023-07-31 16:34:57,038:INFO:_display_container: 3
2023-07-31 16:34:57,133:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=44, verbose=0, warm_start=False)
2023-07-31 16:34:57,134:INFO:create_model() successfully completed......................................
2023-07-31 16:34:57,249:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:57,250:INFO:Creating metrics dataframe
2023-07-31 16:34:57,261:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 16:34:57,262:INFO:Total runtime is 0.06502425273259481 minutes
2023-07-31 16:34:57,265:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:57,265:INFO:Initializing create_model()
2023-07-31 16:34:57,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=qda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:57,265:INFO:Checking exceptions
2023-07-31 16:34:57,265:INFO:Importing libraries
2023-07-31 16:34:57,266:INFO:Copying training dataset
2023-07-31 16:34:57,272:INFO:Defining folds
2023-07-31 16:34:57,272:INFO:Declaring metric variables
2023-07-31 16:34:57,275:INFO:Importing untrained model
2023-07-31 16:34:57,278:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 16:34:57,283:INFO:Cross validation set to False
2023-07-31 16:34:57,283:INFO:Fitting Model
2023-07-31 16:34:57,321:INFO:Initializing predict_model()
2023-07-31 16:34:57,321:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                                               store_covariance=False,
                                               tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f9df2280>)
2023-07-31 16:34:57,321:INFO:Checking exceptions
2023-07-31 16:34:57,321:INFO:Preloading libraries
2023-07-31 16:34:57,580:INFO:_display_container: 3
2023-07-31 16:34:57,676:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 16:34:57,676:INFO:create_model() successfully completed......................................
2023-07-31 16:34:57,793:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:57,793:INFO:Creating metrics dataframe
2023-07-31 16:34:57,805:INFO:Initializing Ada Boost Classifier
2023-07-31 16:34:57,805:INFO:Total runtime is 0.07408193747202556 minutes
2023-07-31 16:34:57,808:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:57,809:INFO:Initializing create_model()
2023-07-31 16:34:57,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=ada, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:57,809:INFO:Checking exceptions
2023-07-31 16:34:57,809:INFO:Importing libraries
2023-07-31 16:34:57,809:INFO:Copying training dataset
2023-07-31 16:34:57,815:INFO:Defining folds
2023-07-31 16:34:57,815:INFO:Declaring metric variables
2023-07-31 16:34:57,818:INFO:Importing untrained model
2023-07-31 16:34:57,822:INFO:Ada Boost Classifier Imported successfully
2023-07-31 16:34:57,826:INFO:Cross validation set to False
2023-07-31 16:34:57,826:INFO:Fitting Model
2023-07-31 16:34:57,876:INFO:Initializing predict_model()
2023-07-31 16:34:57,876:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=44))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd1378f70>)
2023-07-31 16:34:57,876:INFO:Checking exceptions
2023-07-31 16:34:57,876:INFO:Preloading libraries
2023-07-31 16:34:58,082:INFO:_display_container: 3
2023-07-31 16:34:58,180:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=44)
2023-07-31 16:34:58,180:INFO:create_model() successfully completed......................................
2023-07-31 16:34:58,298:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:58,298:INFO:Creating metrics dataframe
2023-07-31 16:34:58,311:INFO:Initializing Gradient Boosting Classifier
2023-07-31 16:34:58,311:INFO:Total runtime is 0.08250994682312013 minutes
2023-07-31 16:34:58,314:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:58,315:INFO:Initializing create_model()
2023-07-31 16:34:58,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=gbc, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:58,315:INFO:Checking exceptions
2023-07-31 16:34:58,315:INFO:Importing libraries
2023-07-31 16:34:58,315:INFO:Copying training dataset
2023-07-31 16:34:58,321:INFO:Defining folds
2023-07-31 16:34:58,321:INFO:Declaring metric variables
2023-07-31 16:34:58,325:INFO:Importing untrained model
2023-07-31 16:34:58,328:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 16:34:58,333:INFO:Cross validation set to False
2023-07-31 16:34:58,333:INFO:Fitting Model
2023-07-31 16:34:58,377:INFO:Initializing predict_model()
2023-07-31 16:34:58,377:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=44, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0f95b7a60>)
2023-07-31 16:34:58,377:INFO:Checking exceptions
2023-07-31 16:34:58,377:INFO:Preloading libraries
2023-07-31 16:34:58,603:INFO:_display_container: 3
2023-07-31 16:34:58,701:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=44, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 16:34:58,701:INFO:create_model() successfully completed......................................
2023-07-31 16:34:58,832:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:58,832:INFO:Creating metrics dataframe
2023-07-31 16:34:58,847:INFO:Initializing Linear Discriminant Analysis
2023-07-31 16:34:58,847:INFO:Total runtime is 0.09144519567489626 minutes
2023-07-31 16:34:58,850:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:58,851:INFO:Initializing create_model()
2023-07-31 16:34:58,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=lda, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:58,851:INFO:Checking exceptions
2023-07-31 16:34:58,851:INFO:Importing libraries
2023-07-31 16:34:58,851:INFO:Copying training dataset
2023-07-31 16:34:58,857:INFO:Defining folds
2023-07-31 16:34:58,857:INFO:Declaring metric variables
2023-07-31 16:34:58,861:INFO:Importing untrained model
2023-07-31 16:34:58,864:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 16:34:58,868:INFO:Cross validation set to False
2023-07-31 16:34:58,868:INFO:Fitting Model
2023-07-31 16:34:58,906:INFO:Initializing predict_model()
2023-07-31 16:34:58,906:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0fbc828b0>)
2023-07-31 16:34:58,906:INFO:Checking exceptions
2023-07-31 16:34:58,906:INFO:Preloading libraries
2023-07-31 16:34:59,149:INFO:_display_container: 3
2023-07-31 16:34:59,246:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 16:34:59,246:INFO:create_model() successfully completed......................................
2023-07-31 16:34:59,371:INFO:SubProcess create_model() end ==================================
2023-07-31 16:34:59,372:INFO:Creating metrics dataframe
2023-07-31 16:34:59,385:INFO:Initializing Extra Trees Classifier
2023-07-31 16:34:59,385:INFO:Total runtime is 0.1004180391629537 minutes
2023-07-31 16:34:59,389:INFO:SubProcess create_model() called ==================================
2023-07-31 16:34:59,389:INFO:Initializing create_model()
2023-07-31 16:34:59,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=et, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:34:59,389:INFO:Checking exceptions
2023-07-31 16:34:59,389:INFO:Importing libraries
2023-07-31 16:34:59,390:INFO:Copying training dataset
2023-07-31 16:34:59,396:INFO:Defining folds
2023-07-31 16:34:59,396:INFO:Declaring metric variables
2023-07-31 16:34:59,400:INFO:Importing untrained model
2023-07-31 16:34:59,404:INFO:Extra Trees Classifier Imported successfully
2023-07-31 16:34:59,408:INFO:Cross validation set to False
2023-07-31 16:34:59,408:INFO:Fitting Model
2023-07-31 16:34:59,476:INFO:Initializing predict_model()
2023-07-31 16:34:59,476:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=44,
                                      verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd1378f70>)
2023-07-31 16:34:59,476:INFO:Checking exceptions
2023-07-31 16:34:59,476:INFO:Preloading libraries
2023-07-31 16:34:59,780:INFO:_display_container: 3
2023-07-31 16:34:59,878:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=44, verbose=0, warm_start=False)
2023-07-31 16:34:59,879:INFO:create_model() successfully completed......................................
2023-07-31 16:35:00,005:INFO:SubProcess create_model() end ==================================
2023-07-31 16:35:00,005:INFO:Creating metrics dataframe
2023-07-31 16:35:00,018:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 16:35:00,018:INFO:Total runtime is 0.11097122033437094 minutes
2023-07-31 16:35:00,022:INFO:SubProcess create_model() called ==================================
2023-07-31 16:35:00,022:INFO:Initializing create_model()
2023-07-31 16:35:00,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=lightgbm, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:35:00,022:INFO:Checking exceptions
2023-07-31 16:35:00,022:INFO:Importing libraries
2023-07-31 16:35:00,022:INFO:Copying training dataset
2023-07-31 16:35:00,028:INFO:Defining folds
2023-07-31 16:35:00,029:INFO:Declaring metric variables
2023-07-31 16:35:00,032:INFO:Importing untrained model
2023-07-31 16:35:00,035:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 16:35:00,040:INFO:Cross validation set to False
2023-07-31 16:35:00,040:INFO:Fitting Model
2023-07-31 16:35:00,098:INFO:Initializing predict_model()
2023-07-31 16:35:00,099:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=44,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9fd1378f70>)
2023-07-31 16:35:00,099:INFO:Checking exceptions
2023-07-31 16:35:00,099:INFO:Preloading libraries
2023-07-31 16:35:00,391:INFO:_display_container: 3
2023-07-31 16:35:00,487:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=44, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 16:35:00,487:INFO:create_model() successfully completed......................................
2023-07-31 16:35:00,651:INFO:SubProcess create_model() end ==================================
2023-07-31 16:35:00,651:INFO:Creating metrics dataframe
2023-07-31 16:35:00,666:INFO:Initializing Dummy Classifier
2023-07-31 16:35:00,666:INFO:Total runtime is 0.12176158825556438 minutes
2023-07-31 16:35:00,669:INFO:SubProcess create_model() called ==================================
2023-07-31 16:35:00,670:INFO:Initializing create_model()
2023-07-31 16:35:00,670:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=dummy, fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0f9076f10>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:35:00,670:INFO:Checking exceptions
2023-07-31 16:35:00,670:INFO:Importing libraries
2023-07-31 16:35:00,670:INFO:Copying training dataset
2023-07-31 16:35:00,676:INFO:Defining folds
2023-07-31 16:35:00,676:INFO:Declaring metric variables
2023-07-31 16:35:00,680:INFO:Importing untrained model
2023-07-31 16:35:00,683:INFO:Dummy Classifier Imported successfully
2023-07-31 16:35:00,688:INFO:Cross validation set to False
2023-07-31 16:35:00,688:INFO:Fitting Model
2023-07-31 16:35:00,723:INFO:Initializing predict_model()
2023-07-31 16:35:00,723:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['P1', 'P2', 'P3', 'P4', 'P5', 'P6',
                                             'P7', 'P8', 'P9', 'P10', 'P11',
                                             'P12', 'P13', 'P14', 'P15', 'P16',
                                             'P17', 'P18', 'P19', 'P20', 'P21',
                                             'P22', 'P23', 'P24', 'P25', 'P26',
                                             'P27', 'P28', 'P29', 'P30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,...
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 DummyClassifier(constant=None, random_state=44,
                                 strategy='prior'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa0af87ae50>)
2023-07-31 16:35:00,723:INFO:Checking exceptions
2023-07-31 16:35:00,723:INFO:Preloading libraries
2023-07-31 16:35:00,958:INFO:_display_container: 3
2023-07-31 16:35:01,055:INFO:DummyClassifier(constant=None, random_state=44, strategy='prior')
2023-07-31 16:35:01,055:INFO:create_model() successfully completed......................................
2023-07-31 16:35:01,216:INFO:SubProcess create_model() end ==================================
2023-07-31 16:35:01,216:INFO:Creating metrics dataframe
2023-07-31 16:35:01,240:INFO:Initializing create_model()
2023-07-31 16:35:01,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa0f8a20fa0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=KFold(n_splits=8, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 16:35:01,240:INFO:Checking exceptions
2023-07-31 16:35:01,242:INFO:Importing libraries
2023-07-31 16:35:01,242:INFO:Copying training dataset
2023-07-31 16:35:01,247:INFO:Defining folds
2023-07-31 16:35:01,247:INFO:Declaring metric variables
2023-07-31 16:35:01,248:INFO:Importing untrained model
2023-07-31 16:35:01,248:INFO:Declaring custom model
2023-07-31 16:35:01,248:INFO:Logistic Regression Imported successfully
2023-07-31 16:35:01,250:INFO:Cross validation set to False
2023-07-31 16:35:01,250:INFO:Fitting Model
2023-07-31 16:35:01,377:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 16:35:01,377:INFO:create_model() successfully completed......................................
2023-07-31 16:35:01,569:INFO:_master_model_container: 0
2023-07-31 16:35:01,569:INFO:_display_container: 3
2023-07-31 16:35:01,569:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 16:35:01,569:INFO:compare_models() successfully completed......................................
