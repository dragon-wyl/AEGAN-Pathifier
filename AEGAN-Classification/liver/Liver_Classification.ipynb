{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d195f2-dcf3-4c6e-bef7-0a6a3cb161db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefb3dda-f134-4afc-83ac-2398ecc89fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Liver_merge.csv')\n",
    "y = np.array(data.pop(\"group\"))\n",
    "# y = np.expand_dims(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0406c8f4-79eb-49b5-b63f-b089f177d434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_X = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86be3a98-5d18-47ee-9fa8-5fab9048faf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 计算每个指标的平均值\n",
    "\n",
    "def train(X, y, n_splits=8, test=0.2, random_state=42, n_estimators=200):\n",
    "    # 创建一个随机森林分类器\n",
    "    rf_classifier = RandomForestClassifier(random_state=random_state, n_estimators=n_estimators)\n",
    "    \n",
    "    # 设置K-fold交叉验证策略\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    X_len = len(X)\n",
    "    t = int((1-test)*X_len)\n",
    "    print(f'n_splits:{n_splits},test_data:{test},random_state:{random_state},n_estimators:{n_estimators}')\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # 生成随机排列索引\n",
    "    np.random.seed(random_state)\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, stratify=y, random_state=random_state)\n",
    "    # 定义要计算的分类指标\n",
    "    scoring = {\n",
    "        'Accuracy': 'accuracy',\n",
    "        'Recall': 'recall',\n",
    "        'Precision': 'precision',\n",
    "        'F1': 'f1',\n",
    "        'Auc': 'roc_auc'\n",
    "    }\n",
    "    score_train = {}\n",
    "    score_test = {}\n",
    "    print(X.shape,X_train.shape,X_test.shape)\n",
    "    for metric_name, metric_func in scoring.items():\n",
    "        metric_scores = cross_val_score(rf_classifier, X_train, y_train, cv=cv, scoring=metric_func, n_jobs=-1)\n",
    "        avg_metric_score = metric_scores.mean()\n",
    "        score_train[metric_name] = round(avg_metric_score, 3)\n",
    "        print(f'validation: {metric_name}: {avg_metric_score:.3f}')\n",
    "    # 选择最佳模型参数设置\n",
    "    best_model_params = rf_classifier.get_params() \n",
    "    # 使用最佳参数设置重新训练模型\n",
    "    best_model = RandomForestClassifier(**best_model_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    score_test['Accuracy'] = round(accuracy_score(y_test, y_pred),3)\n",
    "    score_test['Recall'] = round(recall_score(y_test, y_pred),3 )\n",
    "    score_test['Precision'] = round(precision_score(y_test, y_pred),3)\n",
    "    score_test['F1'] = round(f1_score(y_test, y_pred), 3)\n",
    "    score_test['Auc'] = round(roc_auc_score(y_test, y_pred), 3)\n",
    "    print('***********test*************')\n",
    "    print(score_test)\n",
    "    # for metric_name, metric_func in scoring.items():\n",
    "    #     metric_scores = cross_val_score(rf_classifier, X_test, y_test, scoring=metric_func, n_jobs=-1)\n",
    "    #     avg_metric_score = metric_scores.mean()\n",
    "    #     score_test[metric_name] = round(avg_metric_score, 3)\n",
    "    #     print(f'test: {metric_name}: {avg_metric_score:.3f}')\n",
    "    return score_train, score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0020f6-297d-4118-8525-aa22664fa658",
   "metadata": {},
   "source": [
    "# Origin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b169c40-58f7-4dc3-8384-8984e6e4a698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_splits:8,test_data:0.1,random_state:42,n_estimators:100\n",
      "(488, 13236) (439, 13236) (49, 13236)\n",
      "validation: Accuracy: 0.793\n",
      "validation: Recall: 0.991\n",
      "validation: Precision: 0.798\n",
      "validation: F1: 0.883\n",
      "validation: Auc: 0.732\n",
      "***********test*************\n",
      "{'Accuracy': 0.796, 'Recall': 0.974, 'Precision': 0.809, 'F1': 0.884, 'Auc': 0.537}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.796,\n",
       " 'Recall': 0.974,\n",
       " 'Precision': 0.809,\n",
       " 'F1': 0.884,\n",
       " 'Auc': 0.537}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,origin_score = train(origin_X, y, 8, test=0.1, n_estimators=100)\n",
    "origin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd2bbb1-38e9-4103-b087-86fe5a9aab0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集中各类别样本的数量：Counter({1: 389, 0: 99})\n",
      "生成对抗网络生成之后各类别样本的数量：Counter({0.0: 389, 1.0: 389})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "# 获取gan生成的数据\n",
    "gan_df_X = pd.read_csv('gan_GSE25066.csv')\n",
    "gan_df_y = np.array(gan_df_X.pop(\"group\"))\n",
    "print(f'数据集中各类别样本的数量：{Counter(y)}')\n",
    "print(f'生成对抗网络生成之后各类别样本的数量：{Counter(gan_df_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c49cc8f2-4160-4710-af05-0446d27acc56",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[11.82870044,  9.52387729,  7.90726305, ...,  8.57323034,\n",
       "          5.53536047,  7.36465953],\n",
       "        [13.24126192,  8.54328879,  8.43569974, ...,  9.0119576 ,\n",
       "          4.7177315 ,  9.32327107],\n",
       "        [12.99361145,  8.00497705,  8.74166074, ...,  7.88724543,\n",
       "          7.18095724,  8.75889929],\n",
       "        ...,\n",
       "        [10.4430933 ,  8.88611412,  8.76195145, ...,  9.15136433,\n",
       "          8.26241016,  8.97298622],\n",
       "        [10.32757378,  8.88632011,  8.73100567, ...,  8.95202637,\n",
       "          8.44435501,  9.00190163],\n",
       "        [10.28937626,  8.82092571,  8.68940258, ...,  9.00303173,\n",
       "          8.23552799,  8.75537682]]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_X  = np.array(gan_df_X)\n",
    "gan_X, gan_df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5fefe-83a4-4568-a57e-1e03fa108fed",
   "metadata": {},
   "source": [
    "# Gan_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ca7c2c-522e-46fd-bb74-a7722c021e00",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_splits:8,test_data:0.1,random_state:42,n_estimators:100\n",
      "(778, 13236) (700, 13236) (78, 13236)\n",
      "validation: Accuracy: 0.881\n",
      "validation: Recall: 0.991\n",
      "validation: Precision: 0.816\n",
      "validation: F1: 0.894\n",
      "validation: Auc: 0.929\n",
      "***********test*************\n",
      "{'Accuracy': 0.897, 'Recall': 1.0, 'Precision': 0.83, 'F1': 0.907, 'Auc': 0.897}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.897,\n",
       " 'Recall': 1.0,\n",
       " 'Precision': 0.83,\n",
       " 'F1': 0.907,\n",
       " 'Auc': 0.897}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, gan_score = train(gan_X, gan_df_y, 8, test=0.1, n_estimators=100, random_state=42)\n",
    "gan_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f617420-ba67-42b8-b061-0d51908dfa2b",
   "metadata": {},
   "source": [
    "# 读取pathways特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a655d49b-17b9-404a-a1d5-81ca19623730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ptways = pd.read_csv('GSE25066_Pathways.csv')\n",
    "ptways_y = np.array(ptways.pop(\"group\"))\n",
    "ptways_X = np.array(ptways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02238ed6-3d1b-4e9b-a4a4-511e55cfc6be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 389, 1: 389})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(ptways_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3276f880-38af-4330-8f65-900f87204d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_splits:8,test_data:0.2,random_state:42,n_estimators:200\n",
      "(778, 295) (622, 295) (156, 295)\n",
      "validation: Accuracy: 0.849\n",
      "validation: Recall: 0.815\n",
      "validation: Precision: 0.876\n",
      "validation: F1: 0.842\n",
      "validation: Auc: 0.947\n",
      "***********test*************\n",
      "{'Accuracy': 0.891, 'Recall': 0.846, 'Precision': 0.93, 'F1': 0.886, 'Auc': 0.891}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.849,\n",
       "  'Recall': 0.815,\n",
       "  'Precision': 0.876,\n",
       "  'F1': 0.842,\n",
       "  'Auc': 0.947},\n",
       " {'Accuracy': 0.891,\n",
       "  'Recall': 0.846,\n",
       "  'Precision': 0.93,\n",
       "  'F1': 0.886,\n",
       "  'Auc': 0.891})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(ptways_X, ptways_y, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc0ce40-eba7-461f-a308-24c227bf8841",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/wyl/miniconda3/envs/dl/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 创建一个递归特征消除器\n",
    "estimator = LogisticRegression()\n",
    "selector = RFE(estimator, n_features_to_select=245, step=1)\n",
    "\n",
    "# 使用选择器对特征进行选择\n",
    "X_selected = selector.fit_transform(ptways_X, ptways_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "399b73a5-dba3-4ddb-a436-150de5839934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# # 创建一个方差阈值特征选择器\n",
    "# selector = VarianceThreshold(threshold=0.070)\n",
    "\n",
    "# # 使用选择器对特征进行选择\n",
    "# X_selected = selector.fit_transform(ptways_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "798ec933-32dd-44f4-84a0-cb6368ad4381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(778, 245)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f33486-c5e8-45df-99da-c55d5cf2f36c",
   "metadata": {},
   "source": [
    "# Gan_pathifier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3687739-598f-45ee-8e8d-5bcc53a676e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_splits:8,test_data:0.1,random_state:42,n_estimators:100\n",
      "(778, 245) (700, 245) (78, 245)\n",
      "validation: Accuracy: 0.860\n",
      "validation: Recall: 0.810\n",
      "validation: Precision: 0.899\n",
      "validation: F1: 0.851\n",
      "validation: Auc: 0.946\n",
      "***********test*************\n",
      "{'Accuracy': 0.949, 'Recall': 0.897, 'Precision': 1.0, 'F1': 0.946, 'Auc': 0.949}\n"
     ]
    }
   ],
   "source": [
    "_, gan_pathifier_score = train(X_selected, ptways_y, n_splits=8, test=0.1, n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd1dfcb-afde-4f7a-a109-6f087fcff3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.796,\n",
       "  'Recall': 0.974,\n",
       "  'Precision': 0.809,\n",
       "  'F1': 0.884,\n",
       "  'Auc': 0.537},\n",
       " {'Accuracy': 0.897,\n",
       "  'Recall': 1.0,\n",
       "  'Precision': 0.83,\n",
       "  'F1': 0.907,\n",
       "  'Auc': 0.897},\n",
       " {'Accuracy': 0.949,\n",
       "  'Recall': 0.897,\n",
       "  'Precision': 1.0,\n",
       "  'F1': 0.946,\n",
       "  'Auc': 0.949})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_score,gan_score, gan_pathifier_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "283af9bb-4cdd-451f-989c-436d5676e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制性能指标对比图像\n",
    "import matplotlib.pyplot as plt\n",
    "X = ['Accuracy','Recall', 'Precision', 'F1', 'AUC']\n",
    "X_labels = ['ORIGIN_RF','GAN_RF', 'GAN_PATHIFIER_RF' ]\n",
    "ORIGIN_RF_score_bar = [origin_score['Accuracy'], origin_score['Recall'], origin_score['Precision'],origin_score['F1'],origin_score['Auc']]\n",
    "GAN_RF_score_bar = [gan_score['Accuracy'], gan_score['Recall'], gan_score['Precision'],gan_score['F1'],gan_score['Auc']]\n",
    "GAN_PATHIFIER_RF_score_bar = [gan_pathifier_score['Accuracy'], gan_pathifier_score['Recall'], gan_pathifier_score['Precision'],gan_pathifier_score['F1'],gan_pathifier_score['Auc']]\n",
    "\n",
    "def plot_preference(X, X_labels, origin_score, gan_score, gan_pathifier_score, save_fig='GSE25066_Classification.png', title='GSE25066 Classification'):\n",
    "    plt.figure(figsize=(13,8))\n",
    "    # 设置柱状图的宽度\n",
    "    bar_width = 0.25\n",
    "    # 生成X轴上的位置\n",
    "    index = np.arange(len(X))\n",
    "    plt.bar(index, ORIGIN_RF_score_bar, bar_width, label=X_labels[0])\n",
    "    \n",
    "    plt.bar(index + bar_width, GAN_RF_score_bar, bar_width, label=X_labels[1])\n",
    "    \n",
    "    plt.bar(index + 2 * bar_width, GAN_PATHIFIER_RF_score_bar, bar_width, label=X_labels[2])\n",
    "    \n",
    "    # 添加标题和标签\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Performance')\n",
    "    plt.ylabel('Score(%)')\n",
    "    \n",
    "    # 添加方法名称到图例中\n",
    "    plt.legend(fontsize=7, loc='upper left')\n",
    "    \n",
    "    # 调整X轴刻度标签\n",
    "    plt.xticks(index + 1.5 * bar_width, X)\n",
    "    for i, v in enumerate(ORIGIN_RF_score_bar):\n",
    "        plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "    for i, v in enumerate(GAN_RF_score_bar):\n",
    "        plt.text(i + bar_width, v, str(v), ha='center', va='bottom')\n",
    "    for i, v in enumerate(GAN_PATHIFIER_RF_score_bar):\n",
    "        plt.text(i + 2 * bar_width, v, str(v), ha='center', va='bottom')\n",
    "    plt.savefig(save_fig)\n",
    "    # 展示图形\n",
    "    plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de6936eb-4edd-4847-ae45-ccd4e92c6fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_preference(X=X, \n",
    "                X_labels=X_labels,\n",
    "                origin_score=origin_score,\n",
    "                gan_score=gan_score,\n",
    "                gan_pathifier_score=gan_pathifier_score,\n",
    "                title='GSE25066 Classification'\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcab87c-d811-48f4-8ab3-e78556c36c80",
   "metadata": {},
   "source": [
    "# 使用其他分类器对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dbf0219-9370-4d48-871e-8320bff9ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_model(X, y, n_splits=8, test=0.2, random_state=42, n_estimators=200, model='rf'):\n",
    "    # 创建一个随机森林分类器\n",
    "    rf_classifier = RandomForestClassifier(random_state=random_state, n_estimators=n_estimators)\n",
    "    \n",
    "    # 设置K-fold交叉验证策略\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    X_len = len(X)\n",
    "    t = int((1-test)*X_len)\n",
    "    print(f'n_splits:{n_splits},test_data:{test},random_state:{random_state},n_estimators:{n_estimators}')\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # 生成随机排列索引\n",
    "    np.random.seed(random_state)\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, stratify=y, random_state=random_state)\n",
    "    # 定义要计算的分类指标\n",
    "    scoring = {\n",
    "        'Accuracy': 'accuracy',\n",
    "        'Recall': 'recall',\n",
    "        'Precision': 'precision',\n",
    "        'F1': 'f1',\n",
    "        'Auc': 'roc_auc'\n",
    "    }\n",
    "    score_train = {}\n",
    "    score_test = {}\n",
    "    print(X.shape,X_train.shape,X_test.shape)\n",
    "    for metric_name, metric_func in scoring.items():\n",
    "        metric_scores = cross_val_score(rf_classifier, X_train, y_train, cv=cv, scoring=metric_func, n_jobs=-1)\n",
    "        avg_metric_score = metric_scores.mean()\n",
    "        score_train[metric_name] = round(avg_metric_score, 3)\n",
    "        print(f'validation: {metric_name}: {avg_metric_score:.3f}')\n",
    "    # 选择最佳模型参数设置\n",
    "    best_model_params = rf_classifier.get_params() \n",
    "    # 使用最佳参数设置重新训练模型\n",
    "    best_model = RandomForestClassifier(**best_model_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    score_test['Accuracy'] = round(accuracy_score(y_test, y_pred),3)\n",
    "    score_test['Recall'] = round(recall_score(y_test, y_pred),3 )\n",
    "    score_test['Precision'] = round(precision_score(y_test, y_pred),3)\n",
    "    score_test['F1'] = round(f1_score(y_test, y_pred), 3)\n",
    "    score_test['Auc'] = round(roc_auc_score(y_test, y_pred), 3)\n",
    "    print('***********test*************')\n",
    "    print(score_test)\n",
    "    # for metric_name, metric_func in scoring.items():\n",
    "    #     metric_scores = cross_val_score(rf_classifier, X_test, y_test, scoring=metric_func, n_jobs=-1)\n",
    "    #     avg_metric_score = metric_scores.mean()\n",
    "    #     score_test[metric_name] = round(avg_metric_score, 3)\n",
    "    #     print(f'test: {metric_name}: {avg_metric_score:.3f}')\n",
    "    return score_train, score_test\n",
    "def select_model(model):\n",
    "    models = {\n",
    "        \"rf\": RandomForestClassifier(),\n",
    "        \"svm\": SVC()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c286021-df59-43de-bf69-80f3ebe19263",
   "metadata": {},
   "source": [
    "# 使用pycaret训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee8ac6-cf1b-4dd8-9ee6-ceb5636f5ddf",
   "metadata": {},
   "source": [
    "## 读取原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93dde540-92c9-43d7-9158-f6f42b3c9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_size = 0.9\n",
    "fold = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69502574-cc18-44d4-9548-51268a1a3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data = pd.read_csv('Liver_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42d0f6bf-9780-47d9-91a1-6f81b9ea9fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b7e02_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b7e02\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b7e02_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_b7e02_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b7e02_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_b7e02_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b7e02_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_b7e02_row1_col1\" class=\"data row1 col1\" >group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b7e02_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_b7e02_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b7e02_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_b7e02_row3_col1\" class=\"data row3 col1\" >(421, 11886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b7e02_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_b7e02_row4_col1\" class=\"data row4 col1\" >(421, 11886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b7e02_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_b7e02_row5_col1\" class=\"data row5 col1\" >(378, 11886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b7e02_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_b7e02_row6_col1\" class=\"data row6 col1\" >(43, 11886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b7e02_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_b7e02_row7_col1\" class=\"data row7 col1\" >11885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b7e02_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_b7e02_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b7e02_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_b7e02_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b7e02_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_b7e02_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b7e02_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_b7e02_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b7e02_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_b7e02_row12_col1\" class=\"data row12 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b7e02_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_b7e02_row13_col1\" class=\"data row13 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b7e02_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_b7e02_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b7e02_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_b7e02_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b7e02_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_b7e02_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b7e02_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_b7e02_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b7e02_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b7e02_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_b7e02_row18_col1\" class=\"data row18 col1\" >c897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa0f8a2c370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7fa0f9b840d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycaret.classification import ClassificationExperiment\n",
    "s = ClassificationExperiment()\n",
    "s.set_config('seed', 42)\n",
    "s.setup(origin_data,\n",
    "        target = 'group', \n",
    "        session_id = 42, \n",
    "        train_size=train_size,\n",
    "        fold_strategy='kfold',\n",
    "        fold=fold\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3059ad9-01bf-48a1-aa09-ec822cb63416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_61af6 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_61af6_row0_col0, #T_61af6_row0_col3, #T_61af6_row1_col0, #T_61af6_row1_col1, #T_61af6_row1_col2, #T_61af6_row1_col3, #T_61af6_row1_col6, #T_61af6_row1_col7, #T_61af6_row2_col0, #T_61af6_row2_col1, #T_61af6_row2_col2, #T_61af6_row2_col3, #T_61af6_row2_col6, #T_61af6_row2_col7, #T_61af6_row3_col0, #T_61af6_row3_col1, #T_61af6_row3_col2, #T_61af6_row3_col3, #T_61af6_row3_col4, #T_61af6_row3_col5, #T_61af6_row3_col6, #T_61af6_row3_col7, #T_61af6_row4_col0, #T_61af6_row4_col1, #T_61af6_row4_col2, #T_61af6_row4_col3, #T_61af6_row4_col5, #T_61af6_row4_col6, #T_61af6_row4_col7, #T_61af6_row5_col0, #T_61af6_row5_col1, #T_61af6_row5_col2, #T_61af6_row5_col3, #T_61af6_row5_col4, #T_61af6_row5_col5, #T_61af6_row5_col6, #T_61af6_row5_col7, #T_61af6_row6_col0, #T_61af6_row6_col1, #T_61af6_row6_col2, #T_61af6_row6_col3, #T_61af6_row6_col4, #T_61af6_row6_col5, #T_61af6_row6_col6, #T_61af6_row6_col7, #T_61af6_row7_col0, #T_61af6_row7_col1, #T_61af6_row7_col2, #T_61af6_row7_col3, #T_61af6_row7_col4, #T_61af6_row7_col5, #T_61af6_row7_col6, #T_61af6_row7_col7, #T_61af6_row8_col0, #T_61af6_row8_col1, #T_61af6_row8_col2, #T_61af6_row8_col3, #T_61af6_row8_col4, #T_61af6_row8_col5, #T_61af6_row8_col6, #T_61af6_row8_col7, #T_61af6_row9_col0, #T_61af6_row9_col1, #T_61af6_row9_col2, #T_61af6_row9_col3, #T_61af6_row9_col4, #T_61af6_row9_col5, #T_61af6_row9_col6, #T_61af6_row9_col7, #T_61af6_row10_col0, #T_61af6_row10_col1, #T_61af6_row10_col2, #T_61af6_row10_col3, #T_61af6_row10_col4, #T_61af6_row10_col5, #T_61af6_row10_col6, #T_61af6_row10_col7, #T_61af6_row11_col0, #T_61af6_row11_col1, #T_61af6_row11_col2, #T_61af6_row11_col3, #T_61af6_row11_col4, #T_61af6_row11_col5, #T_61af6_row11_col6, #T_61af6_row11_col7, #T_61af6_row12_col0, #T_61af6_row12_col1, #T_61af6_row12_col2, #T_61af6_row12_col4, #T_61af6_row12_col5, #T_61af6_row12_col6, #T_61af6_row12_col7, #T_61af6_row13_col0, #T_61af6_row13_col1, #T_61af6_row13_col2, #T_61af6_row13_col3, #T_61af6_row13_col4, #T_61af6_row13_col5, #T_61af6_row13_col6, #T_61af6_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_61af6_row0_col1, #T_61af6_row0_col2, #T_61af6_row0_col4, #T_61af6_row0_col5, #T_61af6_row0_col6, #T_61af6_row0_col7, #T_61af6_row1_col4, #T_61af6_row1_col5, #T_61af6_row2_col4, #T_61af6_row2_col5, #T_61af6_row4_col4, #T_61af6_row12_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_61af6_row0_col8, #T_61af6_row1_col8, #T_61af6_row2_col8, #T_61af6_row3_col8, #T_61af6_row4_col8, #T_61af6_row5_col8, #T_61af6_row6_col8, #T_61af6_row7_col8, #T_61af6_row8_col8, #T_61af6_row9_col8, #T_61af6_row10_col8, #T_61af6_row11_col8, #T_61af6_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_61af6_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_61af6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_61af6_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_61af6_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_61af6_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_61af6_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_61af6_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_61af6_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_61af6_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_61af6_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_61af6_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row0\" class=\"row_heading level0 row0\" >lda</th>\n",
       "      <td id=\"T_61af6_row0_col0\" class=\"data row0 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_61af6_row0_col1\" class=\"data row0 col1\" >0.9895</td>\n",
       "      <td id=\"T_61af6_row0_col2\" class=\"data row0 col2\" >0.9988</td>\n",
       "      <td id=\"T_61af6_row0_col3\" class=\"data row0 col3\" >0.9882</td>\n",
       "      <td id=\"T_61af6_row0_col4\" class=\"data row0 col4\" >1.0000</td>\n",
       "      <td id=\"T_61af6_row0_col5\" class=\"data row0 col5\" >0.9940</td>\n",
       "      <td id=\"T_61af6_row0_col6\" class=\"data row0 col6\" >0.9483</td>\n",
       "      <td id=\"T_61af6_row0_col7\" class=\"data row0 col7\" >0.9508</td>\n",
       "      <td id=\"T_61af6_row0_col8\" class=\"data row0 col8\" >0.6738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_61af6_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_61af6_row1_col1\" class=\"data row1 col1\" >0.9894</td>\n",
       "      <td id=\"T_61af6_row1_col2\" class=\"data row1 col2\" >0.9976</td>\n",
       "      <td id=\"T_61af6_row1_col3\" class=\"data row1 col3\" >0.9882</td>\n",
       "      <td id=\"T_61af6_row1_col4\" class=\"data row1 col4\" >1.0000</td>\n",
       "      <td id=\"T_61af6_row1_col5\" class=\"data row1 col5\" >0.9940</td>\n",
       "      <td id=\"T_61af6_row1_col6\" class=\"data row1 col6\" >0.9466</td>\n",
       "      <td id=\"T_61af6_row1_col7\" class=\"data row1 col7\" >0.9492</td>\n",
       "      <td id=\"T_61af6_row1_col8\" class=\"data row1 col8\" >1.2638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_61af6_row2_col0\" class=\"data row2 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_61af6_row2_col1\" class=\"data row2 col1\" >0.9894</td>\n",
       "      <td id=\"T_61af6_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_61af6_row2_col3\" class=\"data row2 col3\" >0.9882</td>\n",
       "      <td id=\"T_61af6_row2_col4\" class=\"data row2 col4\" >1.0000</td>\n",
       "      <td id=\"T_61af6_row2_col5\" class=\"data row2 col5\" >0.9940</td>\n",
       "      <td id=\"T_61af6_row2_col6\" class=\"data row2 col6\" >0.9466</td>\n",
       "      <td id=\"T_61af6_row2_col7\" class=\"data row2 col7\" >0.9492</td>\n",
       "      <td id=\"T_61af6_row2_col8\" class=\"data row2 col8\" >0.6025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row3\" class=\"row_heading level0 row3\" >ada</th>\n",
       "      <td id=\"T_61af6_row3_col0\" class=\"data row3 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_61af6_row3_col1\" class=\"data row3 col1\" >0.9868</td>\n",
       "      <td id=\"T_61af6_row3_col2\" class=\"data row3 col2\" >0.9924</td>\n",
       "      <td id=\"T_61af6_row3_col3\" class=\"data row3 col3\" >0.9911</td>\n",
       "      <td id=\"T_61af6_row3_col4\" class=\"data row3 col4\" >0.9940</td>\n",
       "      <td id=\"T_61af6_row3_col5\" class=\"data row3 col5\" >0.9925</td>\n",
       "      <td id=\"T_61af6_row3_col6\" class=\"data row3 col6\" >0.9330</td>\n",
       "      <td id=\"T_61af6_row3_col7\" class=\"data row3 col7\" >0.9355</td>\n",
       "      <td id=\"T_61af6_row3_col8\" class=\"data row3 col8\" >3.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row4\" class=\"row_heading level0 row4\" >knn</th>\n",
       "      <td id=\"T_61af6_row4_col0\" class=\"data row4 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_61af6_row4_col1\" class=\"data row4 col1\" >0.9842</td>\n",
       "      <td id=\"T_61af6_row4_col2\" class=\"data row4 col2\" >0.9936</td>\n",
       "      <td id=\"T_61af6_row4_col3\" class=\"data row4 col3\" >0.9822</td>\n",
       "      <td id=\"T_61af6_row4_col4\" class=\"data row4 col4\" >1.0000</td>\n",
       "      <td id=\"T_61af6_row4_col5\" class=\"data row4 col5\" >0.9910</td>\n",
       "      <td id=\"T_61af6_row4_col6\" class=\"data row4 col6\" >0.9258</td>\n",
       "      <td id=\"T_61af6_row4_col7\" class=\"data row4 col7\" >0.9299</td>\n",
       "      <td id=\"T_61af6_row4_col8\" class=\"data row4 col8\" >0.5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_61af6_row5_col0\" class=\"data row5 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_61af6_row5_col1\" class=\"data row5 col1\" >0.9841</td>\n",
       "      <td id=\"T_61af6_row5_col2\" class=\"data row5 col2\" >0.9981</td>\n",
       "      <td id=\"T_61af6_row5_col3\" class=\"data row5 col3\" >0.9911</td>\n",
       "      <td id=\"T_61af6_row5_col4\" class=\"data row5 col4\" >0.9911</td>\n",
       "      <td id=\"T_61af6_row5_col5\" class=\"data row5 col5\" >0.9910</td>\n",
       "      <td id=\"T_61af6_row5_col6\" class=\"data row5 col6\" >0.9189</td>\n",
       "      <td id=\"T_61af6_row5_col7\" class=\"data row5 col7\" >0.9229</td>\n",
       "      <td id=\"T_61af6_row5_col8\" class=\"data row5 col8\" >0.4938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row6\" class=\"row_heading level0 row6\" >svm</th>\n",
       "      <td id=\"T_61af6_row6_col0\" class=\"data row6 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_61af6_row6_col1\" class=\"data row6 col1\" >0.9814</td>\n",
       "      <td id=\"T_61af6_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_61af6_row6_col3\" class=\"data row6 col3\" >0.9852</td>\n",
       "      <td id=\"T_61af6_row6_col4\" class=\"data row6 col4\" >0.9938</td>\n",
       "      <td id=\"T_61af6_row6_col5\" class=\"data row6 col5\" >0.9894</td>\n",
       "      <td id=\"T_61af6_row6_col6\" class=\"data row6 col6\" >0.9128</td>\n",
       "      <td id=\"T_61af6_row6_col7\" class=\"data row6 col7\" >0.9160</td>\n",
       "      <td id=\"T_61af6_row6_col8\" class=\"data row6 col8\" >0.5775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row7\" class=\"row_heading level0 row7\" >rf</th>\n",
       "      <td id=\"T_61af6_row7_col0\" class=\"data row7 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_61af6_row7_col1\" class=\"data row7 col1\" >0.9814</td>\n",
       "      <td id=\"T_61af6_row7_col2\" class=\"data row7 col2\" >0.9985</td>\n",
       "      <td id=\"T_61af6_row7_col3\" class=\"data row7 col3\" >0.9943</td>\n",
       "      <td id=\"T_61af6_row7_col4\" class=\"data row7 col4\" >0.9850</td>\n",
       "      <td id=\"T_61af6_row7_col5\" class=\"data row7 col5\" >0.9895</td>\n",
       "      <td id=\"T_61af6_row7_col6\" class=\"data row7 col6\" >0.9048</td>\n",
       "      <td id=\"T_61af6_row7_col7\" class=\"data row7 col7\" >0.9095</td>\n",
       "      <td id=\"T_61af6_row7_col8\" class=\"data row7 col8\" >0.6762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row8\" class=\"row_heading level0 row8\" >gbc</th>\n",
       "      <td id=\"T_61af6_row8_col0\" class=\"data row8 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_61af6_row8_col1\" class=\"data row8 col1\" >0.9736</td>\n",
       "      <td id=\"T_61af6_row8_col2\" class=\"data row8 col2\" >0.9941</td>\n",
       "      <td id=\"T_61af6_row8_col3\" class=\"data row8 col3\" >0.9852</td>\n",
       "      <td id=\"T_61af6_row8_col4\" class=\"data row8 col4\" >0.9853</td>\n",
       "      <td id=\"T_61af6_row8_col5\" class=\"data row8 col5\" >0.9851</td>\n",
       "      <td id=\"T_61af6_row8_col6\" class=\"data row8 col6\" >0.8640</td>\n",
       "      <td id=\"T_61af6_row8_col7\" class=\"data row8 col7\" >0.8710</td>\n",
       "      <td id=\"T_61af6_row8_col8\" class=\"data row8 col8\" >9.9825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row9\" class=\"row_heading level0 row9\" >lightgbm</th>\n",
       "      <td id=\"T_61af6_row9_col0\" class=\"data row9 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_61af6_row9_col1\" class=\"data row9 col1\" >0.9735</td>\n",
       "      <td id=\"T_61af6_row9_col2\" class=\"data row9 col2\" >0.9971</td>\n",
       "      <td id=\"T_61af6_row9_col3\" class=\"data row9 col3\" >0.9882</td>\n",
       "      <td id=\"T_61af6_row9_col4\" class=\"data row9 col4\" >0.9822</td>\n",
       "      <td id=\"T_61af6_row9_col5\" class=\"data row9 col5\" >0.9850</td>\n",
       "      <td id=\"T_61af6_row9_col6\" class=\"data row9 col6\" >0.8586</td>\n",
       "      <td id=\"T_61af6_row9_col7\" class=\"data row9 col7\" >0.8630</td>\n",
       "      <td id=\"T_61af6_row9_col8\" class=\"data row9 col8\" >5.9462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row10\" class=\"row_heading level0 row10\" >nb</th>\n",
       "      <td id=\"T_61af6_row10_col0\" class=\"data row10 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_61af6_row10_col1\" class=\"data row10 col1\" >0.9710</td>\n",
       "      <td id=\"T_61af6_row10_col2\" class=\"data row10 col2\" >0.9667</td>\n",
       "      <td id=\"T_61af6_row10_col3\" class=\"data row10 col3\" >0.9731</td>\n",
       "      <td id=\"T_61af6_row10_col4\" class=\"data row10 col4\" >0.9940</td>\n",
       "      <td id=\"T_61af6_row10_col5\" class=\"data row10 col5\" >0.9833</td>\n",
       "      <td id=\"T_61af6_row10_col6\" class=\"data row10 col6\" >0.8655</td>\n",
       "      <td id=\"T_61af6_row10_col7\" class=\"data row10 col7\" >0.8718</td>\n",
       "      <td id=\"T_61af6_row10_col8\" class=\"data row10 col8\" >0.5863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n",
       "      <td id=\"T_61af6_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_61af6_row11_col1\" class=\"data row11 col1\" >0.9683</td>\n",
       "      <td id=\"T_61af6_row11_col2\" class=\"data row11 col2\" >0.9082</td>\n",
       "      <td id=\"T_61af6_row11_col3\" class=\"data row11 col3\" >0.9852</td>\n",
       "      <td id=\"T_61af6_row11_col4\" class=\"data row11 col4\" >0.9793</td>\n",
       "      <td id=\"T_61af6_row11_col5\" class=\"data row11 col5\" >0.9822</td>\n",
       "      <td id=\"T_61af6_row11_col6\" class=\"data row11 col6\" >0.8278</td>\n",
       "      <td id=\"T_61af6_row11_col7\" class=\"data row11 col7\" >0.8311</td>\n",
       "      <td id=\"T_61af6_row11_col8\" class=\"data row11 col8\" >0.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row12\" class=\"row_heading level0 row12\" >dummy</th>\n",
       "      <td id=\"T_61af6_row12_col0\" class=\"data row12 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_61af6_row12_col1\" class=\"data row12 col1\" >0.8809</td>\n",
       "      <td id=\"T_61af6_row12_col2\" class=\"data row12 col2\" >0.5000</td>\n",
       "      <td id=\"T_61af6_row12_col3\" class=\"data row12 col3\" >1.0000</td>\n",
       "      <td id=\"T_61af6_row12_col4\" class=\"data row12 col4\" >0.8809</td>\n",
       "      <td id=\"T_61af6_row12_col5\" class=\"data row12 col5\" >0.9364</td>\n",
       "      <td id=\"T_61af6_row12_col6\" class=\"data row12 col6\" >0.0000</td>\n",
       "      <td id=\"T_61af6_row12_col7\" class=\"data row12 col7\" >0.0000</td>\n",
       "      <td id=\"T_61af6_row12_col8\" class=\"data row12 col8\" >0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_61af6_level0_row13\" class=\"row_heading level0 row13\" >qda</th>\n",
       "      <td id=\"T_61af6_row13_col0\" class=\"data row13 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_61af6_row13_col1\" class=\"data row13 col1\" >0.8093</td>\n",
       "      <td id=\"T_61af6_row13_col2\" class=\"data row13 col2\" >0.5285</td>\n",
       "      <td id=\"T_61af6_row13_col3\" class=\"data row13 col3\" >0.8954</td>\n",
       "      <td id=\"T_61af6_row13_col4\" class=\"data row13 col4\" >0.8894</td>\n",
       "      <td id=\"T_61af6_row13_col5\" class=\"data row13 col5\" >0.8914</td>\n",
       "      <td id=\"T_61af6_row13_col6\" class=\"data row13 col6\" >0.0737</td>\n",
       "      <td id=\"T_61af6_row13_col7\" class=\"data row13 col7\" >0.0793</td>\n",
       "      <td id=\"T_61af6_row13_col8\" class=\"data row13 col8\" >0.6488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9fd14e6940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,\n",
       "                           priors=None, shrinkage=None, solver=&#x27;svd&#x27;,\n",
       "                           store_covariance=False, tol=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,\n",
       "                           priors=None, shrinkage=None, solver=&#x27;svd&#x27;,\n",
       "                           store_covariance=False, tol=0.0001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,\n",
       "                           priors=None, shrinkage=None, solver='svd',\n",
       "                           store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754d6d7-1f35-4294-ae31-62cabf069c8e",
   "metadata": {},
   "source": [
    "## 使用gan生成的平衡数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a141efe-0ed6-492f-b22a-308d7deb00f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A2LD1</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AAGAB</th>\n",
       "      <th>AAK1</th>\n",
       "      <th>AAMP</th>\n",
       "      <th>AARS2</th>\n",
       "      <th>...</th>\n",
       "      <th>ZW10</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.903097</td>\n",
       "      <td>8.715260</td>\n",
       "      <td>16.837369</td>\n",
       "      <td>6.064562</td>\n",
       "      <td>9.365117</td>\n",
       "      <td>7.352139</td>\n",
       "      <td>9.069857</td>\n",
       "      <td>8.784455</td>\n",
       "      <td>11.415891</td>\n",
       "      <td>8.267119</td>\n",
       "      <td>...</td>\n",
       "      <td>8.452833</td>\n",
       "      <td>6.605290</td>\n",
       "      <td>6.043189</td>\n",
       "      <td>9.375843</td>\n",
       "      <td>9.384367</td>\n",
       "      <td>10.900427</td>\n",
       "      <td>11.427795</td>\n",
       "      <td>8.922543</td>\n",
       "      <td>8.901912</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.042797</td>\n",
       "      <td>8.713328</td>\n",
       "      <td>16.932478</td>\n",
       "      <td>6.033643</td>\n",
       "      <td>8.947604</td>\n",
       "      <td>6.721176</td>\n",
       "      <td>8.890053</td>\n",
       "      <td>9.139745</td>\n",
       "      <td>11.211142</td>\n",
       "      <td>7.529446</td>\n",
       "      <td>...</td>\n",
       "      <td>8.423790</td>\n",
       "      <td>6.757122</td>\n",
       "      <td>4.821338</td>\n",
       "      <td>9.254951</td>\n",
       "      <td>10.339537</td>\n",
       "      <td>11.014054</td>\n",
       "      <td>11.993706</td>\n",
       "      <td>9.710529</td>\n",
       "      <td>8.799178</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.251136</td>\n",
       "      <td>8.012606</td>\n",
       "      <td>17.869616</td>\n",
       "      <td>7.463284</td>\n",
       "      <td>9.140778</td>\n",
       "      <td>7.108619</td>\n",
       "      <td>9.200250</td>\n",
       "      <td>8.637313</td>\n",
       "      <td>11.241951</td>\n",
       "      <td>7.660811</td>\n",
       "      <td>...</td>\n",
       "      <td>8.608334</td>\n",
       "      <td>6.459951</td>\n",
       "      <td>4.762843</td>\n",
       "      <td>9.205788</td>\n",
       "      <td>9.931098</td>\n",
       "      <td>10.065102</td>\n",
       "      <td>10.875718</td>\n",
       "      <td>8.499810</td>\n",
       "      <td>9.616674</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.501291</td>\n",
       "      <td>8.284755</td>\n",
       "      <td>16.812427</td>\n",
       "      <td>7.136263</td>\n",
       "      <td>8.996256</td>\n",
       "      <td>7.515416</td>\n",
       "      <td>9.152846</td>\n",
       "      <td>9.349093</td>\n",
       "      <td>11.335538</td>\n",
       "      <td>8.014518</td>\n",
       "      <td>...</td>\n",
       "      <td>8.320020</td>\n",
       "      <td>6.429556</td>\n",
       "      <td>5.402074</td>\n",
       "      <td>10.358953</td>\n",
       "      <td>9.778451</td>\n",
       "      <td>10.949562</td>\n",
       "      <td>12.253583</td>\n",
       "      <td>8.632372</td>\n",
       "      <td>9.000843</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.399463</td>\n",
       "      <td>8.103829</td>\n",
       "      <td>16.814177</td>\n",
       "      <td>6.535796</td>\n",
       "      <td>9.308386</td>\n",
       "      <td>7.769594</td>\n",
       "      <td>9.242388</td>\n",
       "      <td>8.917900</td>\n",
       "      <td>11.452892</td>\n",
       "      <td>8.181746</td>\n",
       "      <td>...</td>\n",
       "      <td>8.066311</td>\n",
       "      <td>6.134584</td>\n",
       "      <td>6.066311</td>\n",
       "      <td>9.753889</td>\n",
       "      <td>9.655890</td>\n",
       "      <td>10.635777</td>\n",
       "      <td>12.043885</td>\n",
       "      <td>9.098322</td>\n",
       "      <td>8.693798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>13.589894</td>\n",
       "      <td>9.337051</td>\n",
       "      <td>13.183481</td>\n",
       "      <td>9.305174</td>\n",
       "      <td>10.659041</td>\n",
       "      <td>9.728997</td>\n",
       "      <td>10.384562</td>\n",
       "      <td>9.720572</td>\n",
       "      <td>11.029023</td>\n",
       "      <td>10.304235</td>\n",
       "      <td>...</td>\n",
       "      <td>10.181251</td>\n",
       "      <td>9.838455</td>\n",
       "      <td>9.166183</td>\n",
       "      <td>10.178794</td>\n",
       "      <td>10.458627</td>\n",
       "      <td>10.703332</td>\n",
       "      <td>10.828924</td>\n",
       "      <td>10.247210</td>\n",
       "      <td>10.225082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>13.536341</td>\n",
       "      <td>9.479577</td>\n",
       "      <td>13.422260</td>\n",
       "      <td>9.424850</td>\n",
       "      <td>10.784612</td>\n",
       "      <td>9.865892</td>\n",
       "      <td>10.314266</td>\n",
       "      <td>9.595171</td>\n",
       "      <td>11.174696</td>\n",
       "      <td>10.166624</td>\n",
       "      <td>...</td>\n",
       "      <td>9.809552</td>\n",
       "      <td>9.701748</td>\n",
       "      <td>9.010886</td>\n",
       "      <td>10.438852</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>10.950298</td>\n",
       "      <td>10.860692</td>\n",
       "      <td>10.031444</td>\n",
       "      <td>10.284664</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>13.817484</td>\n",
       "      <td>9.286361</td>\n",
       "      <td>13.532031</td>\n",
       "      <td>9.504230</td>\n",
       "      <td>10.724981</td>\n",
       "      <td>9.793881</td>\n",
       "      <td>10.305278</td>\n",
       "      <td>9.672647</td>\n",
       "      <td>11.165280</td>\n",
       "      <td>9.935654</td>\n",
       "      <td>...</td>\n",
       "      <td>9.956368</td>\n",
       "      <td>9.557275</td>\n",
       "      <td>9.108200</td>\n",
       "      <td>10.264177</td>\n",
       "      <td>10.510122</td>\n",
       "      <td>10.744174</td>\n",
       "      <td>10.643708</td>\n",
       "      <td>10.204868</td>\n",
       "      <td>10.150307</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>13.716986</td>\n",
       "      <td>9.194677</td>\n",
       "      <td>13.604954</td>\n",
       "      <td>9.556050</td>\n",
       "      <td>10.762415</td>\n",
       "      <td>9.846568</td>\n",
       "      <td>10.137026</td>\n",
       "      <td>9.632738</td>\n",
       "      <td>11.145919</td>\n",
       "      <td>10.388307</td>\n",
       "      <td>...</td>\n",
       "      <td>9.792408</td>\n",
       "      <td>9.586435</td>\n",
       "      <td>9.159556</td>\n",
       "      <td>10.084065</td>\n",
       "      <td>10.493257</td>\n",
       "      <td>11.020835</td>\n",
       "      <td>10.758987</td>\n",
       "      <td>9.908797</td>\n",
       "      <td>10.192752</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>14.130010</td>\n",
       "      <td>9.100125</td>\n",
       "      <td>13.693156</td>\n",
       "      <td>9.361629</td>\n",
       "      <td>10.680064</td>\n",
       "      <td>9.577984</td>\n",
       "      <td>10.053623</td>\n",
       "      <td>9.411928</td>\n",
       "      <td>11.058311</td>\n",
       "      <td>10.267684</td>\n",
       "      <td>...</td>\n",
       "      <td>9.566732</td>\n",
       "      <td>9.654101</td>\n",
       "      <td>8.598922</td>\n",
       "      <td>10.439372</td>\n",
       "      <td>10.447108</td>\n",
       "      <td>10.491642</td>\n",
       "      <td>10.562060</td>\n",
       "      <td>10.093728</td>\n",
       "      <td>10.078860</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 11886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          A1BG     A2LD1        A2M    A4GALT       AAAS      AACS      AAGAB  \\\n",
       "0    16.903097  8.715260  16.837369  6.064562   9.365117  7.352139   9.069857   \n",
       "1    16.042797  8.713328  16.932478  6.033643   8.947604  6.721176   8.890053   \n",
       "2    16.251136  8.012606  17.869616  7.463284   9.140778  7.108619   9.200250   \n",
       "3    16.501291  8.284755  16.812427  7.136263   8.996256  7.515416   9.152846   \n",
       "4    16.399463  8.103829  16.814177  6.535796   9.308386  7.769594   9.242388   \n",
       "..         ...       ...        ...       ...        ...       ...        ...   \n",
       "737  13.589894  9.337051  13.183481  9.305174  10.659041  9.728997  10.384562   \n",
       "738  13.536341  9.479577  13.422260  9.424850  10.784612  9.865892  10.314266   \n",
       "739  13.817484  9.286361  13.532031  9.504230  10.724981  9.793881  10.305278   \n",
       "740  13.716986  9.194677  13.604954  9.556050  10.762415  9.846568  10.137026   \n",
       "741  14.130010  9.100125  13.693156  9.361629  10.680064  9.577984  10.053623   \n",
       "\n",
       "         AAK1       AAMP      AARS2  ...       ZW10    ZWILCH     ZWINT  \\\n",
       "0    8.784455  11.415891   8.267119  ...   8.452833  6.605290  6.043189   \n",
       "1    9.139745  11.211142   7.529446  ...   8.423790  6.757122  4.821338   \n",
       "2    8.637313  11.241951   7.660811  ...   8.608334  6.459951  4.762843   \n",
       "3    9.349093  11.335538   8.014518  ...   8.320020  6.429556  5.402074   \n",
       "4    8.917900  11.452892   8.181746  ...   8.066311  6.134584  6.066311   \n",
       "..        ...        ...        ...  ...        ...       ...       ...   \n",
       "737  9.720572  11.029023  10.304235  ...  10.181251  9.838455  9.166183   \n",
       "738  9.595171  11.174696  10.166624  ...   9.809552  9.701748  9.010886   \n",
       "739  9.672647  11.165280   9.935654  ...   9.956368  9.557275  9.108200   \n",
       "740  9.632738  11.145919  10.388307  ...   9.792408  9.586435  9.159556   \n",
       "741  9.411928  11.058311  10.267684  ...   9.566732  9.654101  8.598922   \n",
       "\n",
       "          ZXDB       ZXDC     ZYG11B        ZYX      ZZEF1       ZZZ3  group  \n",
       "0     9.375843   9.384367  10.900427  11.427795   8.922543   8.901912    0.0  \n",
       "1     9.254951  10.339537  11.014054  11.993706   9.710529   8.799178    0.0  \n",
       "2     9.205788   9.931098  10.065102  10.875718   8.499810   9.616674    0.0  \n",
       "3    10.358953   9.778451  10.949562  12.253583   8.632372   9.000843    0.0  \n",
       "4     9.753889   9.655890  10.635777  12.043885   9.098322   8.693798    0.0  \n",
       "..         ...        ...        ...        ...        ...        ...    ...  \n",
       "737  10.178794  10.458627  10.703332  10.828924  10.247210  10.225082    0.0  \n",
       "738  10.438852  10.428571  10.950298  10.860692  10.031444  10.284664    0.0  \n",
       "739  10.264177  10.510122  10.744174  10.643708  10.204868  10.150307    0.0  \n",
       "740  10.084065  10.493257  11.020835  10.758987   9.908797  10.192752    0.0  \n",
       "741  10.439372  10.447108  10.491642  10.562060  10.093728  10.078860    0.0  \n",
       "\n",
       "[742 rows x 11886 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_data = pd.read_csv('gan_Liver.csv')\n",
    "gan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebbe8ec0-ccfe-448a-a68c-01119215e04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ddc26_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ddc26\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ddc26_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_ddc26_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ddc26_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_ddc26_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ddc26_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_ddc26_row1_col1\" class=\"data row1 col1\" >group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ddc26_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_ddc26_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ddc26_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_ddc26_row3_col1\" class=\"data row3 col1\" >(742, 11886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ddc26_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_ddc26_row4_col1\" class=\"data row4 col1\" >(742, 11886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ddc26_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_ddc26_row5_col1\" class=\"data row5 col1\" >(667, 11886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ddc26_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_ddc26_row6_col1\" class=\"data row6 col1\" >(75, 11886)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ddc26_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_ddc26_row7_col1\" class=\"data row7 col1\" >11885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ddc26_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_ddc26_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ddc26_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_ddc26_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ddc26_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_ddc26_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ddc26_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_ddc26_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ddc26_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_ddc26_row12_col1\" class=\"data row12 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ddc26_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_ddc26_row13_col1\" class=\"data row13 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ddc26_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_ddc26_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ddc26_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_ddc26_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ddc26_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_ddc26_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ddc26_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_ddc26_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ddc26_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ddc26_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_ddc26_row18_col1\" class=\"data row18 col1\" >9ea4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa0b19d37c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7fa0f968baf0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = ClassificationExperiment()\n",
    "s2.set_config('seed', 42)\n",
    "s2.setup(gan_data, \n",
    "         target = 'group', \n",
    "         session_id = 42, \n",
    "         train_size=train_size, \n",
    "         fold_strategy='kfold',\n",
    "         fold=fold\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f49313b-7228-4496-aa19-ef2b7409bd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0cb89 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0cb89_row0_col0, #T_0cb89_row0_col3, #T_0cb89_row1_col0, #T_0cb89_row1_col2, #T_0cb89_row1_col3, #T_0cb89_row2_col0, #T_0cb89_row2_col1, #T_0cb89_row2_col2, #T_0cb89_row2_col3, #T_0cb89_row2_col4, #T_0cb89_row2_col5, #T_0cb89_row2_col6, #T_0cb89_row2_col7, #T_0cb89_row3_col0, #T_0cb89_row3_col1, #T_0cb89_row3_col2, #T_0cb89_row3_col3, #T_0cb89_row3_col4, #T_0cb89_row3_col5, #T_0cb89_row3_col6, #T_0cb89_row3_col7, #T_0cb89_row4_col0, #T_0cb89_row4_col1, #T_0cb89_row4_col2, #T_0cb89_row4_col3, #T_0cb89_row4_col4, #T_0cb89_row4_col5, #T_0cb89_row4_col6, #T_0cb89_row4_col7, #T_0cb89_row5_col0, #T_0cb89_row5_col1, #T_0cb89_row5_col2, #T_0cb89_row5_col3, #T_0cb89_row5_col4, #T_0cb89_row5_col5, #T_0cb89_row5_col6, #T_0cb89_row5_col7, #T_0cb89_row6_col0, #T_0cb89_row6_col1, #T_0cb89_row6_col2, #T_0cb89_row6_col3, #T_0cb89_row6_col4, #T_0cb89_row6_col5, #T_0cb89_row6_col6, #T_0cb89_row6_col7, #T_0cb89_row7_col0, #T_0cb89_row7_col1, #T_0cb89_row7_col2, #T_0cb89_row7_col3, #T_0cb89_row7_col4, #T_0cb89_row7_col5, #T_0cb89_row7_col6, #T_0cb89_row7_col7, #T_0cb89_row8_col0, #T_0cb89_row8_col1, #T_0cb89_row8_col2, #T_0cb89_row8_col3, #T_0cb89_row8_col4, #T_0cb89_row8_col5, #T_0cb89_row8_col6, #T_0cb89_row8_col7, #T_0cb89_row9_col0, #T_0cb89_row9_col1, #T_0cb89_row9_col2, #T_0cb89_row9_col3, #T_0cb89_row9_col4, #T_0cb89_row9_col5, #T_0cb89_row9_col6, #T_0cb89_row9_col7, #T_0cb89_row10_col0, #T_0cb89_row10_col1, #T_0cb89_row10_col2, #T_0cb89_row10_col3, #T_0cb89_row10_col4, #T_0cb89_row10_col5, #T_0cb89_row10_col6, #T_0cb89_row10_col7, #T_0cb89_row11_col0, #T_0cb89_row11_col1, #T_0cb89_row11_col2, #T_0cb89_row11_col4, #T_0cb89_row11_col5, #T_0cb89_row11_col6, #T_0cb89_row11_col7, #T_0cb89_row12_col0, #T_0cb89_row12_col1, #T_0cb89_row12_col2, #T_0cb89_row12_col3, #T_0cb89_row12_col4, #T_0cb89_row12_col5, #T_0cb89_row12_col6, #T_0cb89_row12_col7, #T_0cb89_row13_col0, #T_0cb89_row13_col1, #T_0cb89_row13_col2, #T_0cb89_row13_col3, #T_0cb89_row13_col4, #T_0cb89_row13_col5, #T_0cb89_row13_col6, #T_0cb89_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_0cb89_row0_col1, #T_0cb89_row0_col2, #T_0cb89_row0_col4, #T_0cb89_row0_col5, #T_0cb89_row0_col6, #T_0cb89_row0_col7, #T_0cb89_row1_col1, #T_0cb89_row1_col4, #T_0cb89_row1_col5, #T_0cb89_row1_col6, #T_0cb89_row1_col7, #T_0cb89_row11_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_0cb89_row0_col8, #T_0cb89_row2_col8, #T_0cb89_row3_col8, #T_0cb89_row4_col8, #T_0cb89_row5_col8, #T_0cb89_row6_col8, #T_0cb89_row7_col8, #T_0cb89_row8_col8, #T_0cb89_row9_col8, #T_0cb89_row10_col8, #T_0cb89_row11_col8, #T_0cb89_row12_col8, #T_0cb89_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_0cb89_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0cb89\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0cb89_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_0cb89_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_0cb89_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_0cb89_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_0cb89_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_0cb89_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_0cb89_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_0cb89_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_0cb89_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_0cb89_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_0cb89_row0_col1\" class=\"data row0 col1\" >0.9940</td>\n",
       "      <td id=\"T_0cb89_row0_col2\" class=\"data row0 col2\" >0.9999</td>\n",
       "      <td id=\"T_0cb89_row0_col3\" class=\"data row0 col3\" >0.9878</td>\n",
       "      <td id=\"T_0cb89_row0_col4\" class=\"data row0 col4\" >1.0000</td>\n",
       "      <td id=\"T_0cb89_row0_col5\" class=\"data row0 col5\" >0.9938</td>\n",
       "      <td id=\"T_0cb89_row0_col6\" class=\"data row0 col6\" >0.9878</td>\n",
       "      <td id=\"T_0cb89_row0_col7\" class=\"data row0 col7\" >0.9879</td>\n",
       "      <td id=\"T_0cb89_row0_col8\" class=\"data row0 col8\" >1.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row1\" class=\"row_heading level0 row1\" >ridge</th>\n",
       "      <td id=\"T_0cb89_row1_col0\" class=\"data row1 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_0cb89_row1_col1\" class=\"data row1 col1\" >0.9940</td>\n",
       "      <td id=\"T_0cb89_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_0cb89_row1_col3\" class=\"data row1 col3\" >0.9878</td>\n",
       "      <td id=\"T_0cb89_row1_col4\" class=\"data row1 col4\" >1.0000</td>\n",
       "      <td id=\"T_0cb89_row1_col5\" class=\"data row1 col5\" >0.9938</td>\n",
       "      <td id=\"T_0cb89_row1_col6\" class=\"data row1 col6\" >0.9878</td>\n",
       "      <td id=\"T_0cb89_row1_col7\" class=\"data row1 col7\" >0.9879</td>\n",
       "      <td id=\"T_0cb89_row1_col8\" class=\"data row1 col8\" >0.3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row2\" class=\"row_heading level0 row2\" >et</th>\n",
       "      <td id=\"T_0cb89_row2_col0\" class=\"data row2 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_0cb89_row2_col1\" class=\"data row2 col1\" >0.9880</td>\n",
       "      <td id=\"T_0cb89_row2_col2\" class=\"data row2 col2\" >0.9998</td>\n",
       "      <td id=\"T_0cb89_row2_col3\" class=\"data row2 col3\" >0.9878</td>\n",
       "      <td id=\"T_0cb89_row2_col4\" class=\"data row2 col4\" >0.9878</td>\n",
       "      <td id=\"T_0cb89_row2_col5\" class=\"data row2 col5\" >0.9878</td>\n",
       "      <td id=\"T_0cb89_row2_col6\" class=\"data row2 col6\" >0.9757</td>\n",
       "      <td id=\"T_0cb89_row2_col7\" class=\"data row2 col7\" >0.9759</td>\n",
       "      <td id=\"T_0cb89_row2_col8\" class=\"data row2 col8\" >0.4888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_0cb89_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_0cb89_row3_col1\" class=\"data row3 col1\" >0.9865</td>\n",
       "      <td id=\"T_0cb89_row3_col2\" class=\"data row3 col2\" >0.9997</td>\n",
       "      <td id=\"T_0cb89_row3_col3\" class=\"data row3 col3\" >0.9878</td>\n",
       "      <td id=\"T_0cb89_row3_col4\" class=\"data row3 col4\" >0.9853</td>\n",
       "      <td id=\"T_0cb89_row3_col5\" class=\"data row3 col5\" >0.9865</td>\n",
       "      <td id=\"T_0cb89_row3_col6\" class=\"data row3 col6\" >0.9726</td>\n",
       "      <td id=\"T_0cb89_row3_col7\" class=\"data row3 col7\" >0.9727</td>\n",
       "      <td id=\"T_0cb89_row3_col8\" class=\"data row3 col8\" >0.5362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_0cb89_row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_0cb89_row4_col1\" class=\"data row4 col1\" >0.9865</td>\n",
       "      <td id=\"T_0cb89_row4_col2\" class=\"data row4 col2\" >0.9998</td>\n",
       "      <td id=\"T_0cb89_row4_col3\" class=\"data row4 col3\" >0.9815</td>\n",
       "      <td id=\"T_0cb89_row4_col4\" class=\"data row4 col4\" >0.9909</td>\n",
       "      <td id=\"T_0cb89_row4_col5\" class=\"data row4 col5\" >0.9860</td>\n",
       "      <td id=\"T_0cb89_row4_col6\" class=\"data row4 col6\" >0.9727</td>\n",
       "      <td id=\"T_0cb89_row4_col7\" class=\"data row4 col7\" >0.9730</td>\n",
       "      <td id=\"T_0cb89_row4_col8\" class=\"data row4 col8\" >5.1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row5\" class=\"row_heading level0 row5\" >knn</th>\n",
       "      <td id=\"T_0cb89_row5_col0\" class=\"data row5 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_0cb89_row5_col1\" class=\"data row5 col1\" >0.9850</td>\n",
       "      <td id=\"T_0cb89_row5_col2\" class=\"data row5 col2\" >0.9967</td>\n",
       "      <td id=\"T_0cb89_row5_col3\" class=\"data row5 col3\" >0.9727</td>\n",
       "      <td id=\"T_0cb89_row5_col4\" class=\"data row5 col4\" >0.9972</td>\n",
       "      <td id=\"T_0cb89_row5_col5\" class=\"data row5 col5\" >0.9846</td>\n",
       "      <td id=\"T_0cb89_row5_col6\" class=\"data row5 col6\" >0.9695</td>\n",
       "      <td id=\"T_0cb89_row5_col7\" class=\"data row5 col7\" >0.9701</td>\n",
       "      <td id=\"T_0cb89_row5_col8\" class=\"data row5 col8\" >0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row6\" class=\"row_heading level0 row6\" >gbc</th>\n",
       "      <td id=\"T_0cb89_row6_col0\" class=\"data row6 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_0cb89_row6_col1\" class=\"data row6 col1\" >0.9835</td>\n",
       "      <td id=\"T_0cb89_row6_col2\" class=\"data row6 col2\" >0.9979</td>\n",
       "      <td id=\"T_0cb89_row6_col3\" class=\"data row6 col3\" >0.9823</td>\n",
       "      <td id=\"T_0cb89_row6_col4\" class=\"data row6 col4\" >0.9848</td>\n",
       "      <td id=\"T_0cb89_row6_col5\" class=\"data row6 col5\" >0.9834</td>\n",
       "      <td id=\"T_0cb89_row6_col6\" class=\"data row6 col6\" >0.9666</td>\n",
       "      <td id=\"T_0cb89_row6_col7\" class=\"data row6 col7\" >0.9670</td>\n",
       "      <td id=\"T_0cb89_row6_col8\" class=\"data row6 col8\" >21.5088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row7\" class=\"row_heading level0 row7\" >lightgbm</th>\n",
       "      <td id=\"T_0cb89_row7_col0\" class=\"data row7 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_0cb89_row7_col1\" class=\"data row7 col1\" >0.9820</td>\n",
       "      <td id=\"T_0cb89_row7_col2\" class=\"data row7 col2\" >0.9992</td>\n",
       "      <td id=\"T_0cb89_row7_col3\" class=\"data row7 col3\" >0.9831</td>\n",
       "      <td id=\"T_0cb89_row7_col4\" class=\"data row7 col4\" >0.9818</td>\n",
       "      <td id=\"T_0cb89_row7_col5\" class=\"data row7 col5\" >0.9823</td>\n",
       "      <td id=\"T_0cb89_row7_col6\" class=\"data row7 col6\" >0.9637</td>\n",
       "      <td id=\"T_0cb89_row7_col7\" class=\"data row7 col7\" >0.9641</td>\n",
       "      <td id=\"T_0cb89_row7_col8\" class=\"data row7 col8\" >14.3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row8\" class=\"row_heading level0 row8\" >dt</th>\n",
       "      <td id=\"T_0cb89_row8_col0\" class=\"data row8 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_0cb89_row8_col1\" class=\"data row8 col1\" >0.9805</td>\n",
       "      <td id=\"T_0cb89_row8_col2\" class=\"data row8 col2\" >0.9811</td>\n",
       "      <td id=\"T_0cb89_row8_col3\" class=\"data row8 col3\" >0.9888</td>\n",
       "      <td id=\"T_0cb89_row8_col4\" class=\"data row8 col4\" >0.9737</td>\n",
       "      <td id=\"T_0cb89_row8_col5\" class=\"data row8 col5\" >0.9809</td>\n",
       "      <td id=\"T_0cb89_row8_col6\" class=\"data row8 col6\" >0.9608</td>\n",
       "      <td id=\"T_0cb89_row8_col7\" class=\"data row8 col7\" >0.9614</td>\n",
       "      <td id=\"T_0cb89_row8_col8\" class=\"data row8 col8\" >0.5913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row9\" class=\"row_heading level0 row9\" >lda</th>\n",
       "      <td id=\"T_0cb89_row9_col0\" class=\"data row9 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_0cb89_row9_col1\" class=\"data row9 col1\" >0.9580</td>\n",
       "      <td id=\"T_0cb89_row9_col2\" class=\"data row9 col2\" >0.9782</td>\n",
       "      <td id=\"T_0cb89_row9_col3\" class=\"data row9 col3\" >0.9618</td>\n",
       "      <td id=\"T_0cb89_row9_col4\" class=\"data row9 col4\" >0.9560</td>\n",
       "      <td id=\"T_0cb89_row9_col5\" class=\"data row9 col5\" >0.9585</td>\n",
       "      <td id=\"T_0cb89_row9_col6\" class=\"data row9 col6\" >0.9151</td>\n",
       "      <td id=\"T_0cb89_row9_col7\" class=\"data row9 col7\" >0.9159</td>\n",
       "      <td id=\"T_0cb89_row9_col8\" class=\"data row9 col8\" >1.1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n",
       "      <td id=\"T_0cb89_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_0cb89_row10_col1\" class=\"data row10 col1\" >0.9355</td>\n",
       "      <td id=\"T_0cb89_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_0cb89_row10_col3\" class=\"data row10 col3\" >0.9236</td>\n",
       "      <td id=\"T_0cb89_row10_col4\" class=\"data row10 col4\" >0.9503</td>\n",
       "      <td id=\"T_0cb89_row10_col5\" class=\"data row10 col5\" >0.9313</td>\n",
       "      <td id=\"T_0cb89_row10_col6\" class=\"data row10 col6\" >0.8688</td>\n",
       "      <td id=\"T_0cb89_row10_col7\" class=\"data row10 col7\" >0.8777</td>\n",
       "      <td id=\"T_0cb89_row10_col8\" class=\"data row10 col8\" >0.4288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row11\" class=\"row_heading level0 row11\" >nb</th>\n",
       "      <td id=\"T_0cb89_row11_col0\" class=\"data row11 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_0cb89_row11_col1\" class=\"data row11 col1\" >0.9297</td>\n",
       "      <td id=\"T_0cb89_row11_col2\" class=\"data row11 col2\" >0.9298</td>\n",
       "      <td id=\"T_0cb89_row11_col3\" class=\"data row11 col3\" >1.0000</td>\n",
       "      <td id=\"T_0cb89_row11_col4\" class=\"data row11 col4\" >0.8781</td>\n",
       "      <td id=\"T_0cb89_row11_col5\" class=\"data row11 col5\" >0.9342</td>\n",
       "      <td id=\"T_0cb89_row11_col6\" class=\"data row11 col6\" >0.8584</td>\n",
       "      <td id=\"T_0cb89_row11_col7\" class=\"data row11 col7\" >0.8687</td>\n",
       "      <td id=\"T_0cb89_row11_col8\" class=\"data row11 col8\" >0.4188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n",
       "      <td id=\"T_0cb89_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_0cb89_row12_col1\" class=\"data row12 col1\" >0.8936</td>\n",
       "      <td id=\"T_0cb89_row12_col2\" class=\"data row12 col2\" >0.8903</td>\n",
       "      <td id=\"T_0cb89_row12_col3\" class=\"data row12 col3\" >0.8692</td>\n",
       "      <td id=\"T_0cb89_row12_col4\" class=\"data row12 col4\" >0.9154</td>\n",
       "      <td id=\"T_0cb89_row12_col5\" class=\"data row12 col5\" >0.8900</td>\n",
       "      <td id=\"T_0cb89_row12_col6\" class=\"data row12 col6\" >0.7835</td>\n",
       "      <td id=\"T_0cb89_row12_col7\" class=\"data row12 col7\" >0.7864</td>\n",
       "      <td id=\"T_0cb89_row12_col8\" class=\"data row12 col8\" >0.6788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cb89_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_0cb89_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_0cb89_row13_col1\" class=\"data row13 col1\" >0.4572</td>\n",
       "      <td id=\"T_0cb89_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_0cb89_row13_col3\" class=\"data row13 col3\" >0.5000</td>\n",
       "      <td id=\"T_0cb89_row13_col4\" class=\"data row13 col4\" >0.2290</td>\n",
       "      <td id=\"T_0cb89_row13_col5\" class=\"data row13 col5\" >0.3140</td>\n",
       "      <td id=\"T_0cb89_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_0cb89_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_0cb89_row13_col8\" class=\"data row13 col8\" >0.4375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa0f9065fa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=42, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba0da4-3d35-4b4b-8de6-72207bf69257",
   "metadata": {},
   "source": [
    "## 读取pathways score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e94ec9f8-6858-4788-9420-714a88bdb574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>P10</th>\n",
       "      <th>...</th>\n",
       "      <th>P285</th>\n",
       "      <th>P286</th>\n",
       "      <th>P287</th>\n",
       "      <th>P288</th>\n",
       "      <th>P289</th>\n",
       "      <th>P290</th>\n",
       "      <th>P291</th>\n",
       "      <th>P292</th>\n",
       "      <th>P293</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.580165</td>\n",
       "      <td>0.410830</td>\n",
       "      <td>0.674069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420832</td>\n",
       "      <td>0.402185</td>\n",
       "      <td>0.329498</td>\n",
       "      <td>0.610798</td>\n",
       "      <td>0.640273</td>\n",
       "      <td>0.690960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378230</td>\n",
       "      <td>0.510120</td>\n",
       "      <td>0.435090</td>\n",
       "      <td>0.439994</td>\n",
       "      <td>0.362262</td>\n",
       "      <td>0.473969</td>\n",
       "      <td>0.371231</td>\n",
       "      <td>0.373564</td>\n",
       "      <td>0.282004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.580456</td>\n",
       "      <td>0.403640</td>\n",
       "      <td>0.669764</td>\n",
       "      <td>0.062544</td>\n",
       "      <td>0.453088</td>\n",
       "      <td>0.412050</td>\n",
       "      <td>0.330564</td>\n",
       "      <td>0.684060</td>\n",
       "      <td>0.629187</td>\n",
       "      <td>0.684810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458395</td>\n",
       "      <td>0.564218</td>\n",
       "      <td>0.545280</td>\n",
       "      <td>0.549961</td>\n",
       "      <td>0.458955</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.361657</td>\n",
       "      <td>0.371335</td>\n",
       "      <td>0.383963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.581873</td>\n",
       "      <td>0.430934</td>\n",
       "      <td>0.694590</td>\n",
       "      <td>0.070355</td>\n",
       "      <td>0.450293</td>\n",
       "      <td>0.417977</td>\n",
       "      <td>0.312309</td>\n",
       "      <td>0.742605</td>\n",
       "      <td>0.613431</td>\n",
       "      <td>0.683769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434171</td>\n",
       "      <td>0.541537</td>\n",
       "      <td>0.489683</td>\n",
       "      <td>0.497449</td>\n",
       "      <td>0.432156</td>\n",
       "      <td>0.477621</td>\n",
       "      <td>0.362418</td>\n",
       "      <td>0.365382</td>\n",
       "      <td>0.332537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571632</td>\n",
       "      <td>0.408460</td>\n",
       "      <td>0.686018</td>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.471856</td>\n",
       "      <td>0.425381</td>\n",
       "      <td>0.327418</td>\n",
       "      <td>0.750423</td>\n",
       "      <td>0.625285</td>\n",
       "      <td>0.684474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399935</td>\n",
       "      <td>0.531839</td>\n",
       "      <td>0.430862</td>\n",
       "      <td>0.437929</td>\n",
       "      <td>0.396525</td>\n",
       "      <td>0.526101</td>\n",
       "      <td>0.423873</td>\n",
       "      <td>0.423795</td>\n",
       "      <td>0.281571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567762</td>\n",
       "      <td>0.389851</td>\n",
       "      <td>0.660240</td>\n",
       "      <td>0.064660</td>\n",
       "      <td>0.430836</td>\n",
       "      <td>0.408004</td>\n",
       "      <td>0.319520</td>\n",
       "      <td>0.743095</td>\n",
       "      <td>0.636739</td>\n",
       "      <td>0.684810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456845</td>\n",
       "      <td>0.552649</td>\n",
       "      <td>0.539070</td>\n",
       "      <td>0.543880</td>\n",
       "      <td>0.471590</td>\n",
       "      <td>0.489791</td>\n",
       "      <td>0.369913</td>\n",
       "      <td>0.380522</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.653290</td>\n",
       "      <td>0.590181</td>\n",
       "      <td>0.608644</td>\n",
       "      <td>0.123855</td>\n",
       "      <td>0.418895</td>\n",
       "      <td>0.305014</td>\n",
       "      <td>0.307693</td>\n",
       "      <td>0.595838</td>\n",
       "      <td>0.531199</td>\n",
       "      <td>0.590671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280125</td>\n",
       "      <td>0.279717</td>\n",
       "      <td>0.345660</td>\n",
       "      <td>0.359623</td>\n",
       "      <td>0.217504</td>\n",
       "      <td>0.439548</td>\n",
       "      <td>0.345195</td>\n",
       "      <td>0.350671</td>\n",
       "      <td>0.190925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0.482727</td>\n",
       "      <td>0.514109</td>\n",
       "      <td>0.486381</td>\n",
       "      <td>0.182614</td>\n",
       "      <td>0.273718</td>\n",
       "      <td>0.279008</td>\n",
       "      <td>0.177301</td>\n",
       "      <td>0.530906</td>\n",
       "      <td>0.723537</td>\n",
       "      <td>0.522119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460993</td>\n",
       "      <td>0.460845</td>\n",
       "      <td>0.563451</td>\n",
       "      <td>0.573607</td>\n",
       "      <td>0.391574</td>\n",
       "      <td>0.292604</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>0.479464</td>\n",
       "      <td>0.391648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.564962</td>\n",
       "      <td>0.443016</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.391081</td>\n",
       "      <td>0.388466</td>\n",
       "      <td>0.381591</td>\n",
       "      <td>0.613906</td>\n",
       "      <td>0.659894</td>\n",
       "      <td>0.769128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249018</td>\n",
       "      <td>0.157924</td>\n",
       "      <td>0.256978</td>\n",
       "      <td>0.272135</td>\n",
       "      <td>0.173823</td>\n",
       "      <td>0.421144</td>\n",
       "      <td>0.266048</td>\n",
       "      <td>0.328435</td>\n",
       "      <td>0.082833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.636767</td>\n",
       "      <td>0.562377</td>\n",
       "      <td>0.645551</td>\n",
       "      <td>0.166691</td>\n",
       "      <td>0.419554</td>\n",
       "      <td>0.371418</td>\n",
       "      <td>0.360586</td>\n",
       "      <td>0.600800</td>\n",
       "      <td>0.411877</td>\n",
       "      <td>0.566469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318477</td>\n",
       "      <td>0.501299</td>\n",
       "      <td>0.555568</td>\n",
       "      <td>0.556741</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.465358</td>\n",
       "      <td>0.373740</td>\n",
       "      <td>0.371315</td>\n",
       "      <td>0.371254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.603229</td>\n",
       "      <td>0.414074</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>0.097266</td>\n",
       "      <td>0.388268</td>\n",
       "      <td>0.478666</td>\n",
       "      <td>0.340478</td>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.615853</td>\n",
       "      <td>0.666731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264323</td>\n",
       "      <td>0.396082</td>\n",
       "      <td>0.445385</td>\n",
       "      <td>0.457583</td>\n",
       "      <td>0.277854</td>\n",
       "      <td>0.442158</td>\n",
       "      <td>0.340266</td>\n",
       "      <td>0.351376</td>\n",
       "      <td>0.266065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           P1        P2        P3        P4        P5        P6        P7  \\\n",
       "0    0.580165  0.410830  0.674069  0.000000  0.420832  0.402185  0.329498   \n",
       "1    0.580456  0.403640  0.669764  0.062544  0.453088  0.412050  0.330564   \n",
       "2    0.581873  0.430934  0.694590  0.070355  0.450293  0.417977  0.312309   \n",
       "3    0.571632  0.408460  0.686018  0.069721  0.471856  0.425381  0.327418   \n",
       "4    0.567762  0.389851  0.660240  0.064660  0.430836  0.408004  0.319520   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "737  0.653290  0.590181  0.608644  0.123855  0.418895  0.305014  0.307693   \n",
       "738  0.482727  0.514109  0.486381  0.182614  0.273718  0.279008  0.177301   \n",
       "739  0.564962  0.443016  0.661255  0.002343  0.391081  0.388466  0.381591   \n",
       "740  0.636767  0.562377  0.645551  0.166691  0.419554  0.371418  0.360586   \n",
       "741  0.603229  0.414074  0.619000  0.097266  0.388268  0.478666  0.340478   \n",
       "\n",
       "           P8        P9       P10  ...      P285      P286      P287  \\\n",
       "0    0.610798  0.640273  0.690960  ...  0.378230  0.510120  0.435090   \n",
       "1    0.684060  0.629187  0.684810  ...  0.458395  0.564218  0.545280   \n",
       "2    0.742605  0.613431  0.683769  ...  0.434171  0.541537  0.489683   \n",
       "3    0.750423  0.625285  0.684474  ...  0.399935  0.531839  0.430862   \n",
       "4    0.743095  0.636739  0.684810  ...  0.456845  0.552649  0.539070   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "737  0.595838  0.531199  0.590671  ...  0.280125  0.279717  0.345660   \n",
       "738  0.530906  0.723537  0.522119  ...  0.460993  0.460845  0.563451   \n",
       "739  0.613906  0.659894  0.769128  ...  0.249018  0.157924  0.256978   \n",
       "740  0.600800  0.411877  0.566469  ...  0.318477  0.501299  0.555568   \n",
       "741  0.703030  0.615853  0.666731  ...  0.264323  0.396082  0.445385   \n",
       "\n",
       "         P288      P289      P290      P291      P292      P293  group  \n",
       "0    0.439994  0.362262  0.473969  0.371231  0.373564  0.282004      0  \n",
       "1    0.549961  0.458955  0.474219  0.361657  0.371335  0.383963      0  \n",
       "2    0.497449  0.432156  0.477621  0.362418  0.365382  0.332537      0  \n",
       "3    0.437929  0.396525  0.526101  0.423873  0.423795  0.281571      0  \n",
       "4    0.543880  0.471590  0.489791  0.369913  0.380522  0.373096      0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "737  0.359623  0.217504  0.439548  0.345195  0.350671  0.190925      1  \n",
       "738  0.573607  0.391574  0.292604  0.442300  0.479464  0.391648      1  \n",
       "739  0.272135  0.173823  0.421144  0.266048  0.328435  0.082833      1  \n",
       "740  0.556741  0.457843  0.465358  0.373740  0.371315  0.371254      1  \n",
       "741  0.457583  0.277854  0.442158  0.340266  0.351376  0.266065      1  \n",
       "\n",
       "[742 rows x 294 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptways_data = pd.read_csv('Liver_Pathways.csv')\n",
    "ptways_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47121a43-7113-42a5-8e8a-cb7cffdb7033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9844e_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9844e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9844e_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_9844e_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9844e_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_9844e_row0_col1\" class=\"data row0 col1\" >44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9844e_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_9844e_row1_col1\" class=\"data row1 col1\" >group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9844e_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_9844e_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9844e_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_9844e_row3_col1\" class=\"data row3 col1\" >(742, 294)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9844e_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_9844e_row4_col1\" class=\"data row4 col1\" >(742, 294)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_9844e_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_9844e_row5_col1\" class=\"data row5 col1\" >(667, 294)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_9844e_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_9844e_row6_col1\" class=\"data row6 col1\" >(75, 294)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_9844e_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_9844e_row7_col1\" class=\"data row7 col1\" >293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_9844e_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_9844e_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_9844e_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_9844e_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_9844e_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_9844e_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_9844e_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_9844e_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_9844e_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_9844e_row12_col1\" class=\"data row12 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_9844e_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_9844e_row13_col1\" class=\"data row13 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_9844e_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_9844e_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_9844e_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_9844e_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_9844e_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_9844e_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_9844e_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_9844e_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9844e_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_9844e_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_9844e_row18_col1\" class=\"data row18 col1\" >74ce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa0f8bc7b20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7fa0f8a20fa0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = ClassificationExperiment()\n",
    "s3.set_config('seed', 42)\n",
    "s3.setup(ptways_data, \n",
    "         target = 'group', \n",
    "         session_id = 44, \n",
    "         train_size=train_size, \n",
    "         fold_strategy='kfold',\n",
    "         fold=fold\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2e87a6c-c4a4-4aec-aac5-6bfb2e5a4849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_330d8 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_330d8_row0_col0, #T_330d8_row1_col0, #T_330d8_row2_col0, #T_330d8_row3_col0, #T_330d8_row4_col0, #T_330d8_row5_col0, #T_330d8_row6_col0, #T_330d8_row7_col0, #T_330d8_row8_col0, #T_330d8_row9_col0, #T_330d8_row10_col0, #T_330d8_row10_col1, #T_330d8_row10_col2, #T_330d8_row10_col3, #T_330d8_row10_col5, #T_330d8_row10_col6, #T_330d8_row10_col7, #T_330d8_row11_col0, #T_330d8_row11_col1, #T_330d8_row11_col2, #T_330d8_row11_col4, #T_330d8_row11_col5, #T_330d8_row11_col6, #T_330d8_row11_col7, #T_330d8_row12_col0, #T_330d8_row12_col1, #T_330d8_row12_col2, #T_330d8_row12_col4, #T_330d8_row12_col5, #T_330d8_row12_col6, #T_330d8_row12_col7, #T_330d8_row13_col0, #T_330d8_row13_col1, #T_330d8_row13_col2, #T_330d8_row13_col4, #T_330d8_row13_col5, #T_330d8_row13_col6, #T_330d8_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_330d8_row0_col1, #T_330d8_row0_col2, #T_330d8_row0_col3, #T_330d8_row0_col4, #T_330d8_row0_col5, #T_330d8_row0_col6, #T_330d8_row0_col7, #T_330d8_row1_col1, #T_330d8_row1_col2, #T_330d8_row1_col3, #T_330d8_row1_col4, #T_330d8_row1_col5, #T_330d8_row1_col6, #T_330d8_row1_col7, #T_330d8_row2_col1, #T_330d8_row2_col2, #T_330d8_row2_col3, #T_330d8_row2_col4, #T_330d8_row2_col5, #T_330d8_row2_col6, #T_330d8_row2_col7, #T_330d8_row3_col1, #T_330d8_row3_col2, #T_330d8_row3_col3, #T_330d8_row3_col4, #T_330d8_row3_col5, #T_330d8_row3_col6, #T_330d8_row3_col7, #T_330d8_row4_col1, #T_330d8_row4_col2, #T_330d8_row4_col3, #T_330d8_row4_col4, #T_330d8_row4_col5, #T_330d8_row4_col6, #T_330d8_row4_col7, #T_330d8_row5_col1, #T_330d8_row5_col2, #T_330d8_row5_col3, #T_330d8_row5_col4, #T_330d8_row5_col5, #T_330d8_row5_col6, #T_330d8_row5_col7, #T_330d8_row6_col1, #T_330d8_row6_col2, #T_330d8_row6_col3, #T_330d8_row6_col4, #T_330d8_row6_col5, #T_330d8_row6_col6, #T_330d8_row6_col7, #T_330d8_row7_col1, #T_330d8_row7_col2, #T_330d8_row7_col3, #T_330d8_row7_col4, #T_330d8_row7_col5, #T_330d8_row7_col6, #T_330d8_row7_col7, #T_330d8_row8_col1, #T_330d8_row8_col2, #T_330d8_row8_col3, #T_330d8_row8_col4, #T_330d8_row8_col5, #T_330d8_row8_col6, #T_330d8_row8_col7, #T_330d8_row9_col1, #T_330d8_row9_col2, #T_330d8_row9_col3, #T_330d8_row9_col4, #T_330d8_row9_col5, #T_330d8_row9_col6, #T_330d8_row9_col7, #T_330d8_row10_col4, #T_330d8_row11_col3, #T_330d8_row12_col3, #T_330d8_row13_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_330d8_row0_col8, #T_330d8_row2_col8, #T_330d8_row3_col8, #T_330d8_row4_col8, #T_330d8_row5_col8, #T_330d8_row6_col8, #T_330d8_row7_col8, #T_330d8_row8_col8, #T_330d8_row9_col8, #T_330d8_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_330d8_row1_col8, #T_330d8_row10_col8, #T_330d8_row12_col8, #T_330d8_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_330d8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_330d8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_330d8_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_330d8_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_330d8_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_330d8_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_330d8_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_330d8_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_330d8_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_330d8_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_330d8_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_330d8_row0_col1\" class=\"data row0 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row0_col2\" class=\"data row0 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row0_col4\" class=\"data row0 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row0_col5\" class=\"data row0 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row0_col6\" class=\"data row0 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row0_col7\" class=\"data row0 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row0_col8\" class=\"data row0 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row1\" class=\"row_heading level0 row1\" >knn</th>\n",
       "      <td id=\"T_330d8_row1_col0\" class=\"data row1 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_330d8_row1_col1\" class=\"data row1 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row1_col2\" class=\"data row1 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row1_col3\" class=\"data row1 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row1_col4\" class=\"data row1 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row1_col5\" class=\"data row1 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row1_col6\" class=\"data row1 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row1_col7\" class=\"data row1 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row1_col8\" class=\"data row1 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row2\" class=\"row_heading level0 row2\" >dt</th>\n",
       "      <td id=\"T_330d8_row2_col0\" class=\"data row2 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_330d8_row2_col1\" class=\"data row2 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row2_col2\" class=\"data row2 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row2_col3\" class=\"data row2 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row2_col4\" class=\"data row2 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row2_col5\" class=\"data row2 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row2_col6\" class=\"data row2 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row2_col7\" class=\"data row2 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row2_col8\" class=\"data row2 col8\" >0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row3\" class=\"row_heading level0 row3\" >svm</th>\n",
       "      <td id=\"T_330d8_row3_col0\" class=\"data row3 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_330d8_row3_col1\" class=\"data row3 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row3_col2\" class=\"data row3 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row3_col3\" class=\"data row3 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row3_col4\" class=\"data row3 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row3_col5\" class=\"data row3 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row3_col6\" class=\"data row3 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row3_col7\" class=\"data row3 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row3_col8\" class=\"data row3 col8\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row4\" class=\"row_heading level0 row4\" >ridge</th>\n",
       "      <td id=\"T_330d8_row4_col0\" class=\"data row4 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_330d8_row4_col1\" class=\"data row4 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row4_col2\" class=\"data row4 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row4_col3\" class=\"data row4 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row4_col4\" class=\"data row4 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row4_col5\" class=\"data row4 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row4_col6\" class=\"data row4 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row4_col7\" class=\"data row4 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row4_col8\" class=\"data row4 col8\" >0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row5\" class=\"row_heading level0 row5\" >rf</th>\n",
       "      <td id=\"T_330d8_row5_col0\" class=\"data row5 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_330d8_row5_col1\" class=\"data row5 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row5_col2\" class=\"data row5 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row5_col3\" class=\"data row5 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row5_col4\" class=\"data row5 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row5_col5\" class=\"data row5 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row5_col6\" class=\"data row5 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row5_col7\" class=\"data row5 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row5_col8\" class=\"data row5 col8\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_330d8_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_330d8_row6_col1\" class=\"data row6 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row6_col2\" class=\"data row6 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row6_col4\" class=\"data row6 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row6_col5\" class=\"data row6 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row6_col6\" class=\"data row6 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row6_col7\" class=\"data row6 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row6_col8\" class=\"data row6 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row7\" class=\"row_heading level0 row7\" >gbc</th>\n",
       "      <td id=\"T_330d8_row7_col0\" class=\"data row7 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_330d8_row7_col1\" class=\"data row7 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row7_col2\" class=\"data row7 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row7_col4\" class=\"data row7 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row7_col5\" class=\"data row7 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row7_col6\" class=\"data row7 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row7_col7\" class=\"data row7 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row7_col8\" class=\"data row7 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row8\" class=\"row_heading level0 row8\" >et</th>\n",
       "      <td id=\"T_330d8_row8_col0\" class=\"data row8 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_330d8_row8_col1\" class=\"data row8 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row8_col2\" class=\"data row8 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row8_col4\" class=\"data row8 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row8_col5\" class=\"data row8 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row8_col6\" class=\"data row8 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row8_col7\" class=\"data row8 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row8_col8\" class=\"data row8 col8\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row9\" class=\"row_heading level0 row9\" >lightgbm</th>\n",
       "      <td id=\"T_330d8_row9_col0\" class=\"data row9 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_330d8_row9_col1\" class=\"data row9 col1\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row9_col2\" class=\"data row9 col2\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row9_col4\" class=\"data row9 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row9_col5\" class=\"data row9 col5\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row9_col6\" class=\"data row9 col6\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row9_col7\" class=\"data row9 col7\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row9_col8\" class=\"data row9 col8\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row10\" class=\"row_heading level0 row10\" >lda</th>\n",
       "      <td id=\"T_330d8_row10_col0\" class=\"data row10 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_330d8_row10_col1\" class=\"data row10 col1\" >0.9867</td>\n",
       "      <td id=\"T_330d8_row10_col2\" class=\"data row10 col2\" >0.9993</td>\n",
       "      <td id=\"T_330d8_row10_col3\" class=\"data row10 col3\" >0.9730</td>\n",
       "      <td id=\"T_330d8_row10_col4\" class=\"data row10 col4\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row10_col5\" class=\"data row10 col5\" >0.9863</td>\n",
       "      <td id=\"T_330d8_row10_col6\" class=\"data row10 col6\" >0.9733</td>\n",
       "      <td id=\"T_330d8_row10_col7\" class=\"data row10 col7\" >0.9737</td>\n",
       "      <td id=\"T_330d8_row10_col8\" class=\"data row10 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row11\" class=\"row_heading level0 row11\" >nb</th>\n",
       "      <td id=\"T_330d8_row11_col0\" class=\"data row11 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_330d8_row11_col1\" class=\"data row11 col1\" >0.9733</td>\n",
       "      <td id=\"T_330d8_row11_col2\" class=\"data row11 col2\" >0.9737</td>\n",
       "      <td id=\"T_330d8_row11_col3\" class=\"data row11 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row11_col4\" class=\"data row11 col4\" >0.9487</td>\n",
       "      <td id=\"T_330d8_row11_col5\" class=\"data row11 col5\" >0.9737</td>\n",
       "      <td id=\"T_330d8_row11_col6\" class=\"data row11 col6\" >0.9467</td>\n",
       "      <td id=\"T_330d8_row11_col7\" class=\"data row11 col7\" >0.9480</td>\n",
       "      <td id=\"T_330d8_row11_col8\" class=\"data row11 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row12\" class=\"row_heading level0 row12\" >qda</th>\n",
       "      <td id=\"T_330d8_row12_col0\" class=\"data row12 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_330d8_row12_col1\" class=\"data row12 col1\" >0.4933</td>\n",
       "      <td id=\"T_330d8_row12_col2\" class=\"data row12 col2\" >0.5000</td>\n",
       "      <td id=\"T_330d8_row12_col3\" class=\"data row12 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row12_col4\" class=\"data row12 col4\" >0.4933</td>\n",
       "      <td id=\"T_330d8_row12_col5\" class=\"data row12 col5\" >0.6607</td>\n",
       "      <td id=\"T_330d8_row12_col6\" class=\"data row12 col6\" >0.0000</td>\n",
       "      <td id=\"T_330d8_row12_col7\" class=\"data row12 col7\" >0.0000</td>\n",
       "      <td id=\"T_330d8_row12_col8\" class=\"data row12 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_330d8_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_330d8_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_330d8_row13_col1\" class=\"data row13 col1\" >0.4933</td>\n",
       "      <td id=\"T_330d8_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_330d8_row13_col3\" class=\"data row13 col3\" >1.0000</td>\n",
       "      <td id=\"T_330d8_row13_col4\" class=\"data row13 col4\" >0.4933</td>\n",
       "      <td id=\"T_330d8_row13_col5\" class=\"data row13 col5\" >0.6607</td>\n",
       "      <td id=\"T_330d8_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_330d8_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_330d8_row13_col8\" class=\"data row13 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa0f976f1f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=44, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=44, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=44, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.compare_models(cross_validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055c8a7-cf81-4b3d-bae0-5d88fb2dfae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
